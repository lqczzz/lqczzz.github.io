<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://lqczzz.github.io/"/>
  <updated>2019-08-17T02:37:03.000Z</updated>
  <id>http://lqczzz.github.io/</id>
  
  <author>
    <name>lqczzz</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>一个入行两年的菜鸟程序员的思考</title>
    <link href="http://lqczzz.github.io/2019/08/17/%E4%B8%80%E4%B8%AA%E5%85%A5%E8%A1%8C%E4%B8%A4%E5%B9%B4%E7%9A%84%E8%8F%9C%E9%B8%9F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%80%9D%E8%80%83%20/"/>
    <id>http://lqczzz.github.io/2019/08/17/一个入行两年的菜鸟程序员的思考 /</id>
    <published>2019-08-16T17:45:32.000Z</published>
    <updated>2019-08-17T02:37:03.000Z</updated>
    
    <content type="html"><![CDATA[<h2>前面的话</h2><p>从6月到8月，feed着手timeline的优化和新需求开发。从开始的轻松从容，到后来的逐渐失控。实际上，一个仿造的“人月神话”悄悄来到了我的身边。其中有很多值得反思和总结的地方。希望趁现在处于羞耻，自责和焦虑中，思考和总结点东西，一方面希望能够总结出一些自己受用的一些规则和教训，对以后成长更有帮助。另一方面，希望能借此透过现象看本质，穿越流于表面的情绪看到问题的本质，真正的获得成长。</p><h2>需求之坑</h2><p>在做feed之前，我也曾经被需求弄的很头疼，但是当时自己并没有很重视，而是单纯的归因到团队里去。在华为正式工作的时候，因为在预研部门，项目流程不是很规范，直接leader是项目管理和人员管理的，需求是由另一个领导直接提的。</p><blockquote><p>需求不是架构，需求不是设计也不是用户界面，需求是需要 —— 《程序员修炼之道》</p></blockquote><p>在华为的时候，我们得到的并不是真正的需求，只是用户(leader)的模糊的需要。这种需要没有形成需求文档，产品设计文档，没有ui去描绘用户界面。还是初入职场的菜鸟的我那时候也不懂得《程序员修炼之道》里面的真知灼见，单纯的归因为团队的不规范，却又说不出具体怎么的不规范，归因为自己的技术水平但事实上，导致项目失败的原因，技术水平只占了不到1%。</p><p>来到shopee，leader是在微信和产品经理斗智斗勇多年的老司机，他用他的经验告诉我们，开发要站在用户的角度思考问题，要评估需求的合理性.另一方面，这边的产品经理也显得更加正规靠谱，毕竟是阿里头条挖过来的。</p><blockquote><p>与用户一同工作，以像用户一样思考 —— 《程序员修炼之道》</p></blockquote><p>正是这些，导致我再一次忽略了对需求的思考。也许我用leader那拾人牙慧的学习到了一点需求的经验。但是并没有形成自己的一套方法。</p><p>先抛出我作为一个开发者对需求评估的工作流总结：</p><h3>不要搜集需求，要挖掘需求</h3><p>《程序员修炼之道》里给了一个典型的例子：&quot;只有员工的上级和人事部们可以查看员工的档案&quot;是需求吗。转换一下：只有获得授权的用户才可以访问员工档案。两种陈述对于实现来说是截然不同的。</p><p>这一点通常主要是产品的工作，但是开发从产品和用户角度去思考需求产生的原因，往往更能把控实现这件事情的方式。典型的例子是对于这一次开放用户白名单给非kol的商家的需求，PM提出来之后我马上就思考现有的实现细节，没有先分析需求提出来的原因，或者说思考的不够认真，只是流于表面的认为这个只是为了紧急支持local的99促销活动。如果我再进一步的思考，我应该去思考为什么现有的系统不能做，怎么做更佳合理。最终导致自己加班加点的去做需求。</p><h3>需求文档的坑</h3><p>同上，这个也主要是PM的工作，但是需求文档是PM和开发的接口文档，对于开发来说，分析需求文档，建立用例图，然后通过沟通和PM澄清需求，是开发前期最重要的一个阶段。</p><p>在我们的系统中，需求文档主要有两个问题：</p><ol><li>需求文档变更，我们经常抱怨需求文档变化，一方面是需求下来的时候可能比较紧急，文档确实不够详细，另一方面，这是需求文档本来的&quot;原罪&quot;，我们只是没有认识到这一点而已。</li></ol><blockquote><p>制作需求文档的一大危险是太过具体，好的需求文档会保持抽象，需求文档能准确反映商业需求 — 《程序员修炼之道》</p></blockquote><p>在multitabs的需求中，我承认自己对需求文档不够重视，没有仔细斟酌里面的描述，缺少在写代码前和PM的交流，澄清需求，为了逃避交流自己做了太多假设。交流产生的结果也没有准确写入到PRD或者自己的需求规约汇中。这是自己给自己埋下的第一个坑。</p><h3></h3><h2>进度管理</h2><p>人月神话在&quot;系统测试&quot;一节给出了一个软件任务进度安排的经验法则：</p><ul><li><p>1/3 计划</p></li><li><p>1/6 编码</p></li><li><p>1/4 构建测试和早期系统测试</p></li><li><p>1/4 系统测试，所有构件完成</p></li></ul><p>在我看来，这些比例也并非一成不变的，但是更多的东西我没有足够的重视，或者没有足够的经验去思考出自己的一套需求开发进度安排和任务工作量估算的方式。经过一年多的踩坑，我终于认识到，进度管理真的不仅仅是leader的事情，也许我们只需要管理好一部分进度，但是进度管理的基本方法论是不变的。</p><h3>计划</h3><p>计划这一阶段应该在需求评审会的时候，明确好以下的一些东西。</p><ol><li>任务</li><li>责任人</li><li>进度</li><li>接口定义</li></ol><h3>设计和编码的分离</h3><p>首先一点我没有清晰的认识的是，计划和编码是具有清晰明确的边界的。而且计划的时间一定比编码长。在feed项目之初或者至今，我都没有很好的平衡这两点。系统时序图对于思考编码的实现，业务流程是很好的工具，可以当作设计阶段的一个很好的形式化工具，类似于vscode之于编码，系统时序图就是设计阶段的工作。</p><p>设计工作量永远大于编码，除非是一个需求很清晰，实现很清晰，代码量不足50行的需求，否则我都应该在编码之前，在草稿纸上，画出一个简单的设计。更加复杂的需求，就要借助startuml工具(puml)来完成了。</p><h3>外部依赖管理</h3><p>一个0.5天工作量的需求，往往具有的特点是：</p><ol><li>不存在外部依赖</li><li>代码修改量少于50行</li></ol><p>存在外部依赖的时候，即使条件2满足了，也不能乐观的认为工作量只有0.5天完事，《人月神话》里，对于职业的苦恼，有一点正是说的——</p><blockquote><p>&quot;苦恼来自由他人设定目标，供给资源和提供信息&quot;</p></blockquote><p>推荐团队是我见过的最恶劣的合作团队，不仅仅无限延期对接的接口，给出的接口竟然能不按照穿进去的分页参数去返回结果。这也让我认识到，外部依赖永远都是不可靠的。</p><p>不仅仅是团队，内部的依赖往往也不可靠，比如你永远不清楚，一个别人定义的delexxx方法，究竟在实现里面会不会带有副作用。</p><p>在有外部依赖的情况下，工作量都需要按照1天起估算，主要是因为，对于外部依赖，需要有充足的系统测试时间。另外，当一个需求实现的工作量时间大于两天，往往需要再细分到更小的粒度，不然很容易导致失控，或者在遇到困难的时候，没办法让别人更好的参与进来一起解决。</p><h2>设计之坑</h2><h3>初级设计之坑</h3><p>用华为的等级来看，能不能掌握避开初级设计之坑的方法，是13级和14级的区别。13级基本不需要设计，按照既定的规范来做就好，14级开始要做初级设计，接口文档，系统设计之类的。不再埋头编码，是一个准备入行的菜鸟和已入行的弱鸡的区别。</p><p>设计阶段，有两个坑：</p><ol><li>不知道抓重点</li><li>不知道使用什么工具／流程图表达</li></ol><p>第1点在去年的时候我也没有清晰的认识，但是今年看完《DDIA》，结合一些实践上的思考，得出一些自己的经验规律。</p><p>比如对于接口，或者系统设计，我们首先要明确好负载，负载可能是一个高并发场景下的QPS这个指标，也可能是feed关注关系的读写扩散导致的读写放大。之后要明确好性能，性能主要是响应时间等一些我们期望达到的目标。抓重点首先要简化需求模型，脑海里有一个MVP（最小可行性）模型，方便我们对症下药。</p><p>不知道使用什么工具，一方面可能是我们对于软件开发的众多UML工具没有一个系统的了解。但是在学习完《软件方法》课程之后，其实就不太应该了。我觉得，最应该熟悉的是：</p><ol><li><p>用例图</p></li><li><p>系统时序图</p></li></ol><p>其他的都是用的时候再去思考哪种合适就好，永远都不要做工具的奴隶，拿起锤子，看到什么都是钉子。</p><h3>高级设计之坑</h3><p>在华为我见过最厉害的14级的设计，也很少去很好的思考以下的一些问题：</p><ol><li><p>责任是否得到了良好的定义</p></li><li><p>协作是否得到了良好的定义</p></li><li><p>耦合是否得以最小化</p></li><li><p>接口定义和各项约束是否可接受</p></li></ol><p>这些都涉及一定的经验和一定的技术直觉。经验有得到需要的是3年／5年，对于善于思考的人，往往更短。</p><blockquote><p>实践是最好的老师，但智者还能从其他的地方有所收获 — 《穷查理年鉴》</p></blockquote><p>我们可以在自己的设计和别人的设计中不断思考反思上面的4点是如何迭代实现的。在学习开源框架中学习如何抽象对象和结构，在业务开发中，更佳灵活的根据各种需求来进行设计，把阅读开源代码学习到设计灵活应用起来，这样才能真正转化为自己的东西。</p><p>技术直觉需要源源不断的学习，保持好奇心，保持兴趣。</p><p>比如通过DDIA对数据系统的高屋建瓴般的总结，从而对常用的中间件建立一定的技术直觉。</p><p>当然，好奇心和兴趣往往因为压力打压变小，这种时候就该反思自己最近一段时间的状态了。而不是把这种状态视为理所当然。不要逃避问题，否则只能遭致更大的问题。</p><h2>总结和勉励</h2><p>有时候，心里总会有这样的一个声音反复问自己：&quot;为什么要总结这些东西，再怎么总结，以自己的经验，都是做不到比书本更完美的&quot;。我想，有了两年的工作经验之后的今年，我终于找到了原因：</p><blockquote><p>不把信息当知识，不把收藏当学习，不把阅读当思考，不把存储当掌握</p></blockquote><p>当我们生搬硬套教科书的知识／别人的经验，那是永远都没有真正去掌握并转化为自己的能力的。</p><ul><li>比如网络5层协议没有生搬硬套OSI7层网络模型</li><li>比如东施效颦</li></ul><p>编码工作是理性的，枯燥和创造性并存，让其成为近百年来改变世界最明显的工作的原因，正是千百年来无数数学家思考的结晶。很多东西和生活也是相通的，比如生活中怎么管理好大大小小的事情，和项目管理也没啥区别。</p><p>愿我能继续拥有感性的精神世界，理性的生活方式。继续矫情下去，但是也能理性的去掌控好自己的生活。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2&gt;前面的话&lt;/h2&gt;
&lt;p&gt;从6月到8月，feed着手timeline的优化和新需求开发。从开始的轻松从容，到后来的逐渐失控。实际上，一个仿造的“人月神话”悄悄来到了我的身边。其中有很多值得反思和总结的地方。希望趁现在处于羞耻，自责和焦虑中，思考和总结点东西，一方面希望能够
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>分布式系统入门</title>
    <link href="http://lqczzz.github.io/2019/01/06/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%85%A5%E9%97%A8/"/>
    <id>http://lqczzz.github.io/2019/01/06/分布式系统入门/</id>
    <published>2019-01-06T12:26:51.000Z</published>
    <updated>2019-03-15T17:32:40.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式基础"><a href="#分布式基础" class="headerlink" title="分布式基础"></a>分布式基础</h1><p>本文主要是<a href="http://book.mixu.net/distsys/ebook.html#abstractions" target="_blank" rel="noopener">《Distributed systems for fun and profit》</a>的笔记</p><h2 id="一-基础"><a href="#一-基础" class="headerlink" title="一.基础"></a>一.基础</h2><p>计算机主要做两个事情：</p><ol><li>计算</li><li>存储</li></ol><h3 id="1-为什么要用分布式系统"><a href="#1-为什么要用分布式系统" class="headerlink" title="1. 为什么要用分布式系统"></a>1. 为什么要用分布式系统</h3><p>当单台机器的硬件升级也没法解决问题的时候，就需要分布式系统。理论上来说，添加一个服务节点可以线性提升性能，但是现实中，多台机器还涉及到数据拷贝，任务合作等问题。</p><h4 id="1-1-目标"><a href="#1-1-目标" class="headerlink" title="1.1 目标"></a>1.1 目标</h4><p>分布式系统，我们想要：<strong>可扩展性</strong>——数据或者问题规模变大，可以单纯的通过增加节点解决。</p><p>扩展性，就要求规模，节点规模从小到大，就会遇到以下问题：</p><ol><li><p>性能</p><ul><li>低时延</li><li>高吞吐</li><li>资源消耗低</li></ul></li><li><p>可用</p><ul><li>容错性：允许某些节点失败</li><li>延时不能过高</li><li><code>Availability = uptime / (uptime + downtime)</code></li></ul><p>| Availability %         | How much downtime is allowed per year? |<br>| ———————- | ————————————– |<br>| 90% (“one nine”)       | More than a month                      |<br>| 99% (“two nines”)      | Less than 4 days                       |<br>| 99.9% (“three nines”)  | Less than 9 hours                      |<br>| 99.99% (“four nines”)  | Less than an hour                      |<br>| 99.999% (“five nines”) | ~ 5 minutes                            |<br>| 99.9999% (“six nines”) | ~ 31 seconds                           |</p></li></ol><h4 id="1-2-阻碍"><a href="#1-2-阻碍" class="headerlink" title="1.2 阻碍"></a>1.2 阻碍</h4><ol><li>节点数量</li><li>节点的距离</li></ol><p>光速传播速度和cpu频率决定了最低时延</p><h3 id="2-如何研究分布式系统"><a href="#2-如何研究分布式系统" class="headerlink" title="2. 如何研究分布式系统"></a>2. 如何研究分布式系统</h3><h4 id="2-1-抽象和模型"><a href="#2-1-抽象和模型" class="headerlink" title="2.1 抽象和模型"></a>2.1 抽象和模型</h4><p><strong>抽象</strong>可以从现实世界的复杂中得到本质的东西，这种本质就是<strong>模型</strong></p><p>分布式系统的本质可以归纳为三个模型：</p><ol><li>系统模型（同步／异步）</li><li>容错模型（crash-fail/partition/拜占庭问题）</li><li>一致性模型（强一致／弱一致）</li></ol><p>抽象的目的就是为了让这个系统对外看起来像是一个节点。这里有一个矛盾，过分强调一致，会使得使用者容易理解，但是会导致性能不好，可用性降低，适当暴露一些细节会提高性能，但是增加了系统的理解成本。</p><h3 id="3-分布式实现"><a href="#3-分布式实现" class="headerlink" title="3 分布式实现"></a>3 分布式实现</h3><p>本质上只有两种手段：</p><ol><li>数据分区（partition）</li><li>数据复制（replication）</li></ol><p><img src="http://book.mixu.net/distsys/images/part-repl.png" alt="partition/replication"></p><p><strong>partition</strong>可以把数据分成几块，解决了单一节点的存储限制</p><p><strong>replication</strong>允许我们实现可扩展，容错，但是涉及到数据的同步，是很多问题的源泉，<strong>一致性模型</strong>就是为了描述这个问题而存在的</p><h2 id="二-理论"><a href="#二-理论" class="headerlink" title="二.理论"></a>二.理论</h2><p>抽象可以提取实物的本质，再通过这个本质可以推导出某种公理性的东西</p><p>系统模型就是分布式系统的抽象</p><h3 id="1-系统模型"><a href="#1-系统模型" class="headerlink" title="1. 系统模型"></a>1. 系统模型</h3><p>分布式系统模型的抽象取决于假设的多少，一般来说，假设越少越好，系统模型有三个基本的假设</p><ol><li>节点独立运行</li><li>节点通过网络连接</li><li>节点之间的内存和时钟不共享</li></ol><p>假设越少，推演出来的理论和算法的适用范围越广，如增加假设：<code>节点从来不会失灵</code>，则推演出来的算法会忽略掉节点失灵的错误处理，系统就会变得不健壮。</p><p>关于节点——节点提供了：</p><ul><li>可执行程序</li><li>数据存储到内存和磁盘</li><li>本地时钟</li></ul><p>节点的状态：</p><ul><li>失灵（fail）</li><li>crash</li><li>拜占庭将军问题：(叛徒)</li></ul><p>节点通信的两种异常：左边是节点失灵，右边是网络</p><p><img src="http://book.mixu.net/distsys/images/system-of-2.png" alt="node"></p><h3 id="2-公理"><a href="#2-公理" class="headerlink" title="2. 公理"></a>2. 公理</h3><p>有了系统模型，我们推演出了一些公理</p><h4 id="2-1-FLP理论"><a href="#2-1-FLP理论" class="headerlink" title="2.1 FLP理论"></a>2.1 FLP理论</h4><p>假设：</p><ul><li>节点 Fail by crash （不会出现拜占庭将军问题）</li><li>网络可靠</li><li>异步系统模型 消息可能无限delay</li></ul><p>结论</p><p>​    在异步通信场景，即使只有一个进程失败，也没有任何算法能保证非失败进程达到一致性</p><blockquote><p>证明见参考</p></blockquote><h4 id="2-2-CAP理论"><a href="#2-2-CAP理论" class="headerlink" title="2.2 CAP理论"></a>2.2 CAP理论</h4><p><img src="http://book.mixu.net/distsys/images/CAP.png" alt="cap"></p><ul><li>consistency:  所有节点在同一时刻看到同样的值</li><li>availability：某些节点失效并不影响剩余节点运行</li><li>Partition tolerance：即使因为网络分割或者节点失效造成的消息丢失，系统正常运行</li></ul><p>同时满足三个性质的系统是不存在的。</p><p>比如你要强一致，并且保证高可用性，任何节点失效系统都不失效，那么对网络分割就没办法容忍了，每条消息都不能丢失。</p><ul><li>CA（Consistency + Availability）如two-phase commit</li><li>CP（Consistency + Partition tolerance）如Paxos，raft</li><li>AP (Availibity + Partition tolerance) 弱一致系统，如gossip</li></ul><p>通常，分布式系统我们需要保证P，所以要在CA作取舍</p><blockquote><p>实践中我们大多已经采取了弱一致性的异步延时同步方案，以提高可用性</p></blockquote><h5 id="2-2-1-一致性的扩展"><a href="#2-2-1-一致性的扩展" class="headerlink" title="2.2.1 一致性的扩展"></a>2.2.1 一致性的扩展</h5><p>这里，CAP的C理解为多个数据副本的读写一致性问题，其实C可以在很多场景拓展</p><ul><li>多个数据副本的读写</li><li>事务</li><li>关联</li></ul><p>关系数据库关于事务操作，必须遵循ACID原则：原子性（Atomicity，或称不可分割性）、一致性（Consistency）、隔离性（Isolation，又称独立性）和持久性（Durability）</p><p>这里的C表示一个事务中多个操作成功失败是一致的。</p><blockquote><p>众所周知，分布式事务一般采用两阶段提交策略来实现，这是一个非常耗时的复杂过程，会严重影响系统效率，在实践中我们尽量避免使用它。在实践过程中，如果我们为了扩展数据容量将数据分布式存储，而事务的要求又完全不能降低。那么，系统的可用性一定会大大降低，在现实中我们一般都采用对这些数据不分散存储的策略。</p></blockquote><p>nosql数据库为了实现P，牺牲了C，也即牺牲了事务，事务遵循<em>BASE</em>而不是<em>ACID</em></p><h2 id="三-时间和顺序"><a href="#三-时间和顺序" class="headerlink" title="三.时间和顺序"></a>三.时间和顺序</h2><h4 id="3-1-全序和偏序"><a href="#3-1-全序和偏序" class="headerlink" title="3.1 全序和偏序"></a>3.1 全序和偏序</h4><p>全序就是在集合里任何两个元素都可以比较，分出大小。偏序中，某些元素是没办法比较大小的。</p><p>在分布式的系统里，每个节点的指令运行顺序都取决于本地节点的时钟，所以分布式系统是偏序。</p><h4 id="3-2-时间匀速流逝"><a href="#3-2-时间匀速流逝" class="headerlink" title="3.2 时间匀速流逝"></a>3.2 时间匀速流逝</h4><p>时间是顺序的来源，分布式系统中每个节点都有独立的本地时间和时间戳，于是事件的发生有本地的顺序，但是该顺序和其他节点完全独立，很难做到全部节点有序。当然也不是做不到全序，维持一个全局时钟就是一种方法，只是这种方法的代价太大。</p><ul><li>全局时钟（Global Clock）</li><li>本地时钟（Local Clock）</li><li>没有时钟存在（No Clock）</li></ul><h5 id="3-2-1-全局时钟"><a href="#3-2-1-全局时钟" class="headerlink" title="3.2.1 全局时钟"></a>3.2.1 全局时钟</h5><p><img src="http://book.mixu.net/distsys/images/global-clock.png" alt="全局时钟"></p><p>完美的时钟，走时同步，存在于所有节点。这是分布式系统的理想假设。实际上，时钟同步只能保证有限的精度。用户可能随机地改变本机时间，新节点加入，都有可能破坏全局时钟的假设。</p><blockquote><p>现实系统也有做出这个假设的。FB的Cassandra，就是使用时间戳来解决write的冲突的</p></blockquote><h5 id="3-2-2-本地时钟"><a href="#3-2-2-本地时钟" class="headerlink" title="3.2.2 本地时钟"></a>3.2.2 本地时钟</h5><p><img src="http://book.mixu.net/distsys/images/local-clock.png" alt="local clock"></p><p>本地时钟无法保证全局有序</p><h5 id="3-2-3-没有时钟"><a href="#3-2-3-没有时钟" class="headerlink" title="3.2.3 没有时钟"></a>3.2.3 没有时钟</h5><p>完全不使用”时钟”这个概念，取而代之，“逻辑时间”。因为时间戳么，只不过是当前世界状态的一个快照，那我们用一个计数器（Counter），并和节点之间交流就可以做到了。</p><p>这样，我们可以在不同的节点之间决定事件顺序。不过有个坏处，因为缺乏时钟，没办法决定timeout。</p><p>“没有时钟”的假设的实现有：</p><ol><li><p>Lamport时钟</p></li><li><p>Vector clocks</p></li></ol><blockquote><p>Cassandra的cousin Riak 和 Vodemort（LinkedIn）是它的应用。这些系统避免了全局or本地时钟漂移带来的不确定性。</p></blockquote><h5 id="3-2-4-逻辑时钟"><a href="#3-2-4-逻辑时钟" class="headerlink" title="3.2.4 逻辑时钟"></a>3.2.4 逻辑时钟</h5><p><strong>Lamport时钟</strong>和<strong>向量时钟</strong>通过计数器和通信来决定分布式系统中事件发生顺序的。计数器可以在不同节点之前进行比较。</p><h6 id="3-2-4-1-Lamport时钟"><a href="#3-2-4-1-Lamport时钟" class="headerlink" title="3.2.4.1 Lamport时钟"></a>3.2.4.1 Lamport时钟</h6><p>每个进程都维护一个计时器。</p><ul><li>当进程做了任意一件事，增加计时器计数。</li><li>进程发送的消息中包含计时器计数。</li><li>当收到消息以后，计数器设置如下：max(local_counter, received_counter) + 1</li></ul><p>Lamport时钟定义了一个偏序，如果 timestamp(a) &lt; timestamp(b):</p><ul><li>a 可能发生在b之前</li><li>a和b压根没法比较</li></ul><p>第二种情况发生在a和b所在的Partition没有发送通信。</p><h6 id="3-2-4-2-Vector-clocks"><a href="#3-2-4-2-Vector-clocks" class="headerlink" title="3.2.4.2 Vector clocks"></a>3.2.4.2 Vector clocks</h6><p>向量时钟是Lamport时钟的一种扩展。它维护大小为N的数列[t1, t2, ….]，N为节点数。每个节点都更新自己的时钟。</p><ul><li>每当进程做了事情，更新该node的时钟。</li><li>进程发送的消息，包含上面提到的数组。</li><li>当收到消息以后，更新本地的数组里面的每个元素max(local, received)；为当前节点的counter加1</li></ul><p>如图：</p><p><img src="http://book.mixu.net/distsys/images/vector_clock.svg.png" alt=""></p><h4 id="3-3-失灵检测"><a href="#3-3-失灵检测" class="headerlink" title="3.3 失灵检测"></a>3.3 失灵检测</h4><p>对于一个节点上的程序，它怎么知道远程某个节点失效了呢？在缺乏有效准确的全局信息下，我们可以通过一个合理的timeout值来确定。但是合理的timeout值该怎么确定呢？</p><p>失灵检测器可以通过使用心跳消息来实现timeout。节点之间交换心跳消息。如果消息在timeout之前没有收到响应，就可以认为出现失效。这种检测要么太冲动(把正常的节点算成失效），要么太保守，很长时间才能检测出错误。            </p><p><a href="http://www.google.com/search?q=Unreliable%20Failure%20Detectors%20for%20Reliable%20Distributed%20Systems" target="_blank" rel="noopener">论文</a> 讨论了失灵检测在解决一致性问题中的两大属性：<strong>完整性</strong>和<strong>精准性</strong></p><h4 id="3-4-总结"><a href="#3-4-总结" class="headerlink" title="3.4 总结"></a>3.4 总结</h4><p>在分布式系统中应假设偏序而不是全序。而要承诺全序也是可能的，但是代价非常大。</p><p>时间，顺序和同步真的必要么？看情况。有时候可能你只不过需要最后的结果而不关系中间事件发生的顺序。</p><h2 id="四-replication"><a href="#四-replication" class="headerlink" title="四.replication"></a>四.replication</h2><p>拷贝其实是一组通信问题，为一些子问题，例如选举，失灵检测，一致性和原子广播提供了上下文</p><p>拷贝本质就只有两种：</p><ol><li>同步拷贝</li><li>异步拷贝</li></ol><h4 id="4-1-拷贝范式"><a href="#4-1-拷贝范式" class="headerlink" title="4.1 拷贝范式"></a>4.1 拷贝范式</h4><h5 id="4-1-1-同步拷贝"><a href="#4-1-1-同步拷贝" class="headerlink" title="4.1.1 同步拷贝"></a>4.1.1 同步拷贝</h5><p><img src="http://book.mixu.net/distsys/images/replication-sync.png" alt=""></p><p>首先client发送请求。然后同步拷贝，同步意味着这时候client还在等待着请求返回。最后，服务器返回。</p><p>这就是N-of-N write，只有等所有N个节点成功写，才返回写成功给client。系统不容忍任何服务器下线。从性能上说，最慢的服务器决定了写的速度</p><h5 id="4-1-2-异步拷贝"><a href="#4-1-2-异步拷贝" class="headerlink" title="4.1.2 异步拷贝"></a>4.1.2 异步拷贝</h5><p><img src="http://book.mixu.net/distsys/images/replication-async.png" alt=""></p><p>master节点立即返回。该节点可能在本地做了复制，但是不会向其他服务器发送拷贝。只有在返回以后，异步的任务在开始执行。</p><p>相对地，这是1-of-N write。性能上说，快。但是不能提供强一致性保证。</p><h4 id="4-2-拷贝算法"><a href="#4-2-拷贝算法" class="headerlink" title="4.2 拷贝算法"></a>4.2 拷贝算法</h4><h5 id="4-2-1-overview"><a href="#4-2-1-overview" class="headerlink" title="4.2.1 overview"></a>4.2.1 overview</h5><p>一致性的强弱可以用来区分拷贝算法</p><blockquote><p> 一致性就是所有的节点都同意某一个值，具体的说，一致性包括：</p><p>协议：每个正确的流程必须就相同的价值达成一致。<br>完整性：每个正确的过程最多决定一个值，如果它决定某个值，那么它必须由某个过程提出。<br>终止：所有流程最终都会做出决定。<br>有效性：如果所有正确的过程提出相同的值V，那么所有正确的过程决定V</p></blockquote><p>互斥，leader选举，多播和原子广播都是更普遍的一致性问题</p><p>单拷贝系统按照一次执行中传递的消息数目，可以做一下分类：</p><ul><li>1n messages（异步 主从备份）</li><li>2n messages（同步 主从备份）</li><li>4n messages（2-phase commit，Multi-Paxos)</li><li>6n messages （3-phase commit，Paxos with repeated leader election）</li></ul><p><img src="http://book.mixu.net/distsys/images/google-transact09.png" alt=""></p><p>上图列出的复制算法不难发现，一致性强的算法，相应的延时高，性能低，这是一种取舍，得此失彼。</p><h5 id="4-2-2-主从备份拷贝"><a href="#4-2-2-主从备份拷贝" class="headerlink" title="4.2.2 主从备份拷贝"></a>4.2.2 主从备份拷贝</h5><p>最常见最基本的拷贝方式。所有的update发生在primary，并且以log的形式拷贝到backup 服务器。主从备份也分同步和异步两种。</p><p>MySQL和MongoDB都使用异步主从备份。同步主从备份保证在返回给client之前，backup节点成功存储了拷贝（Replica）。不过即使这样，同步方式也仅能保证较弱的承诺。考虑下面的场景：</p><ul><li>主服务器收到write，发送到backup</li><li>backup 写成功。返回ACK</li><li>主服务器fail，client超时，认为写失败。</li></ul><p>client现在认为写失败，但是backup其实成功。如果backup promote成为primary，那么就不对了</p><h5 id="4-2-3-两阶段提交（2PC）"><a href="#4-2-3-两阶段提交（2PC）" class="headerlink" title="4.2.3 两阶段提交（2PC）"></a>4.2.3 两阶段提交（2PC）</h5><p>2PC在很多经典的关系型数据库中都使用到了。例如MySQL 集群使用2PC提供同步拷贝。下面是2PC的基本流程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[ Coordinator ] -&gt; OK to commit?     [ Peers ]</span><br><span class="line">                &lt;- Yes / No</span><br><span class="line"></span><br><span class="line">[ Coordinator ] -&gt; Commit / Rollback [ Peers ]</span><br><span class="line">                &lt;- ACK</span><br></pre></td></tr></table></figure><p>在第一阶段，<strong>投票</strong>，协调者（Coordinator）给所有参与者发送update。每个参与者投票决定是否commit。如果选择commit，结果首先存放在临时区域（the write-ahead log）。除非第二阶段完成，这部分都只算“临时”的update。</p><p>在第二阶段，<strong>决策</strong>，协调者决定结果，并通知参与者。如果所有参与者都选择commit，那结果从临时区域移除，而成为最终结果。</p><p>2PC在最后commit之前，有一个临时区域，就能够在节点失效的时候，从而允许回滚。</p><p>之前讨论过，2PC属于CA，所以它没有考虑网络分割，对网络分割并没有容错。同时由于是N-of-N write，所以性能上会有一些折扣</p><h5 id="4-2-4-对网络分割容错的一致性算法：gossip-raft和ZAB"><a href="#4-2-4-对网络分割容错的一致性算法：gossip-raft和ZAB" class="headerlink" title="4.2.4 对网络分割容错的一致性算法：gossip/raft和ZAB"></a>4.2.4 对网络分割容错的一致性算法：gossip/raft和ZAB</h5><p>对网络分割容错的一致性算法其实就是实现了CAP的CP，同时保重了一定的A。</p><h6 id="什么是网络分割（Network-Partition）"><a href="#什么是网络分割（Network-Partition）" class="headerlink" title="什么是网络分割（Network Partition）"></a>什么是网络分割（Network Partition）</h6><p>节点本身正常运行，但是网络链路发生问题。不同的Partition甚至还能接收client的请求。</p><p>2节点，节点失效 vs 网络分割</p><p><img src="http://book.mixu.net/distsys/images/system-of-2.png" alt=""></p><p>3节点，节点失效 vs网络分割</p><p><img src="http://book.mixu.net/distsys/images/system-of-3.png" alt=""></p><p><strong>对这类算法会在学习MIT6.824公开课深入学习，to be continues…</strong></p><h4 id="4-3-总结"><a href="#4-3-总结" class="headerlink" title="4.3 总结"></a>4.3 总结</h4><p>总结下各类算法的一些关键特征。</p><p><strong>主从备份</strong></p><ul><li>单独的，静态的master节点</li><li>复制日志，slaves节点并不参与执行具体操作</li><li>拷贝操作的延时没有上限</li><li>无法容错网络分割</li><li>在不一致和错误发生情况下，需要手工干涉</li></ul><p><strong>2PC</strong></p><ul><li>统一投票：提交或者放弃</li><li>静态的master节点</li><li>协调者和普通节点同时挂掉情况下无法保证一致性</li><li>无法容错网络分割</li></ul><p><strong>Paxos like</strong> </p><ul><li><p>多数投票</p></li><li><p>动态master节点</p></li><li><p>允许n/2-1节点挂</p></li><li><p>对延时并不太敏感</p></li></ul><h2 id="遗留的问题"><a href="#遗留的问题" class="headerlink" title="遗留的问题"></a>遗留的问题</h2><ol><li>拜占庭将军问题</li><li>2PC</li><li>flp实现</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://book.mixu.net/distsys/ebook.html#abstractions" target="_blank" rel="noopener">1. ebook</a></p><p><a href="https://zhuanlan.zhihu.com/p/41329283" target="_blank" rel="noopener">2. 区块链时代的拜占庭将军们</a></p><p><a href="https://blog.csdn.net/chen77716/article/details/27963079" target="_blank" rel="noopener">3. FLP impossible</a></p><p><a href="https://www.jdon.com/bigdata/how-to-understand-cap.html" target="_blank" rel="noopener">4. 如何正确理解CAP</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;分布式基础&quot;&gt;&lt;a href=&quot;#分布式基础&quot; class=&quot;headerlink&quot; title=&quot;分布式基础&quot;&gt;&lt;/a&gt;分布式基础&lt;/h1&gt;&lt;p&gt;本文主要是&lt;a href=&quot;http://book.mixu.net/distsys/ebook.html#abst
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>怎样设计golang友好的api</title>
    <link href="http://lqczzz.github.io/2018/12/24/%E6%80%8E%E6%A0%B7%E8%AE%BE%E8%AE%A1golang%E5%8F%8B%E5%A5%BD%E7%9A%84api/"/>
    <id>http://lqczzz.github.io/2018/12/24/怎样设计golang友好的api/</id>
    <published>2018-12-23T17:08:47.000Z</published>
    <updated>2018-12-23T17:13:28.000Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章是Dave Cheney在2014年发表的，我认为在go语言的接口设计上，这篇文章起到了指明灯的作用，包括Micro在内的框架，都使用了这种方式提供API。原文看这里</p><p>正文开始：</p><p>下面的内容是我的一次演示的文字版本，这是我在dotGo上演讲的『Functional options for friendly APIs』，在这里已经编辑的可读了。</p><p><img src="http://btfak.com/images/api-design1.png" alt=""><br>我想用一个故事作为开头。</p><p>在2014年的晚些时候，你的公司发布了一款革命性的分布式社交网络工具，很明智的，你选择了Go来开发你的产品。</p><p>你分配到的任务是编写极为重要的服务端组件，看起来可能像这样</p><p><img src="http://btfak.com/images/api-design2.png" alt=""></p><p>这里有一些不可导出的字段需要初始化，通过一个goroutine运行起来，响应请求。</p><p>这个包有很简单的API，非常容易使用。</p><p>但有一个问题，当你发布了你的第一个版本后，新的需求不断的被提出来。</p><p><img src="http://btfak.com/images/api-design3.png" alt=""></p><p>手机客户端经常是响应的很慢，甚至停止响应。你需要添加支持来对慢的客户端主动断开连接。</p><p>为了增加安全，新的需求是增加安全连接（TLS）。</p><p>然后，你的某些用户是在一个很小的服务器上运行服务，他们需要限制客户端数量的方式。</p><p>下面是想要对并发数进行限制。</p><p>不断的新需求…</p><p>限制你需要调整你的API来满足这一系列的新需求</p><p><img src="http://btfak.com/images/api-design4.png" alt=""></p><p>还需要考虑不同版本直接接口的兼容性问题。</p><p>实话说，谁用过这样的API？</p><p>谁编写过这样的API?</p><p>谁的代码以为依赖了这样的包，而不能正常使用了？</p><p>明显的这种解决方式是笨重而脆弱的，同时也不容易发现问题。</p><p>你的包的新用户，不知道哪些参数是可选的，哪些是必须的。</p><p>比如说，如果我想创建一个服务的实例作为测试，我需要提供一个真实的TLS证书吗，如果不需要，我需要在接口中提供什么？</p><p>如果我不关心最大连接数，或者最大并发数，我应该在参数中设置什么值，我应该使用0？0听起来是合理的，但这依赖于具体的接口是怎样实现的，这也许真的会导致并发数限制为0。</p><p>在我看来，这样写API是容易的，同时你把正确使用接口的责任抛给了使用者。</p><p>这个例子甚至代码写的很糟糕，文档也不友好，我想这示范了一个看起来华丽，其实很脆弱的API设计。</p><p>现在我们定位了问题，我们看看解决方案。</p><p><img src="http://btfak.com/images/api-design5.png" alt=""></p><p>与其提供一个单独的接口处理多种情况，一种解决方案是提供一系列的接口。</p><p>用户按需调用即可。</p><p>但你很快会发现，提供如此大量的接口，很快会让你不堪重负。</p><p>让我们看看另一种方式。</p><p><img src="http://btfak.com/images/api-design6.png" alt=""></p><p>一种非常简单的方式是提供一个配置结构体。</p><p>这有一些优势。</p><p>使用这种方式，如果有新的需求加入，在结构体中增加选项即可。对外的公共API仍然保持不变。这也能让文档更加友好、可读。</p><p>在结构体上注明这是NewServer的参数，文档上也很容易识别。</p><p>潜在的它也允许用户使用0作为参数的值。</p><p><img src="http://btfak.com/images/api-design7.png" alt=""></p><p>但是这种模式并不完美。</p><p>对于默认值是有歧义的，特别是0的值如果有特别的含义。</p><p>比如在这里的配置结构中，如果port没有被设置，NewServer会监听8080端口。</p><p>但是这有一个负面影响，你也许想设置为0，然后服务端默认分配一个随机端口，但你设置的0与默认值是相同的。</p><p><img src="http://btfak.com/images/api-design8.png" alt=""></p><p>大部分时候，你的API用户只是想使用你的默认值。</p><p>即使他们不想改变你的配置的任何内容，仍然不得不传入一些参数。</p><p>当你的用户读你的测试代码或者示例代码时，在想着怎样使用你的包，他们会看到这个魔幻的空字符串参数。</p><p>对我来说，这让我感觉很糟糕。</p><p>为什么你的API的用户需要传入一个空的值，只是简单的让你的函数满足声明需求？</p><p><img src="http://btfak.com/images/api-design9.png" alt=""></p><p>一个常见的解决办法是传入一个结构体指针，这让调用者可以传入nil，而不用考虑空值的问题。</p><p>在我看来，这个方案有前面的示例中的所有问题，甚至让问题更复杂了。</p><p>首先，我们仍然需要在第二个参数传入点什么，但目前，这个参数可以是nil了，而且大部分时候，对于默认的使用者，它就是nil。</p><p>使用指针的方式，包的作者和使用者都会担心的是，他们引用了同一份数据，随时有可能在运行中这份数据被修改而发生突变。</p><p>我想设计精良的API不应该要求用户传递这些额外的参数，只是为了应对一些罕见的情况。</p><p>我认为我们，Go程序员，应该努力确保不要求用户传递一个nil作为参数。</p><p>如果我们想要传递配置信息时，这应该是自解释的，尽量的有表达性。</p><p>现在，我们怀着这样的理念，我讨论一下我认为更好的解决方案。</p><p><img src="http://btfak.com/images/api-design10.png" alt=""></p><p>我们可以让API把不必须的参数作为一个变参。</p><p>不是传入nil，或者一些值为0的结构体，这种函数的设计发出了这样的信号：你不需要在config上传入任何参数。</p><p>在我看来这解决了两个问题。</p><p>首先，默认的调用方式变得简介命了。</p><p>其次，NewServer现在只接受config的值，不是指针，移除了nil和其他可能的参数，确保用户不会修改已经传入的参数。</p><p>我认为这个一个巨大的提升。</p><p>但我们深究一下，这仍然有问题。</p><p>明显对你的预期是提供最多一个config值，但这个参数是变参，实现的时候需要考虑用户传入多个参数的情况。</p><p>我们可以既能使用变参，同时也能提高我们的参数的表达性吗？</p><p>我认为这就是结局方案。</p><p><img src="http://btfak.com/images/api-design11.png" alt=""></p><p>在这里我想要说清楚，函数式参数的想法是来自于Rob Pike的这篇文章：<a href="http://commandcenter.blogspot.com/2014/01/self-referential-functions-and-design.html" target="_blank" rel="noopener">Self referential functions and design</a> ，我鼓励每个人都去看看。</p><p>这种方式与上面的例子关键的不同在于，服务的定制化并不是通过传递参数实现的，而是通过函数来直接修改server的配置本身。</p><p>正如前面看到的，不传递变参让我们使用默认的方式。</p><p>当需要进行配置时，我们传递一个操作server的配置的函数。</p><p>上面的代码中，timeout这个函数是用于改变server的配置中的timeout字段。</p><p>在NewServer的实现内部，直接应用这些函数即可。</p><p>在上面的代码中，我们调用了一个 net.Listener，在server的示例中，我们使用了这个默认的listener。</p><p>然后，对于每个传入的option，我们都调用它，把我们的配置传入进去。</p><p>很明显，如果没有option传递进来，我们就使用的是默认的server.</p><p>使用这种方式，我们可以让API有这样的特性</p><ul><li>默认情况是实用的</li><li>高度可配置</li><li>配置可以不断增长</li><li>自解释的文档</li><li>对新的使用者很安全</li><li>不会要求传入一个nil的或者空值（只是为了让编译通过）</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这篇文章是Dave Cheney在2014年发表的，我认为在go语言的接口设计上，这篇文章起到了指明灯的作用，包括Micro在内的框架，都使用了这种方式提供API。原文看这里&lt;/p&gt;
&lt;p&gt;正文开始：&lt;/p&gt;
&lt;p&gt;下面的内容是我的一次演示的文字版本，这是我在dotGo上演
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>可插拔式代码结构思考</title>
    <link href="http://lqczzz.github.io/2018/12/12/%E5%8F%AF%E6%8F%92%E6%8B%94%E5%BC%8F%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84%E6%80%9D%E8%80%83/"/>
    <id>http://lqczzz.github.io/2018/12/12/可插拔式代码结构思考/</id>
    <published>2018-12-12T11:10:36.000Z</published>
    <updated>2018-12-23T17:04:23.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是可插拔式框架"><a href="#什么是可插拔式框架" class="headerlink" title="什么是可插拔式框架"></a>什么是可插拔式框架</h2><p>最早接触可插拔式的框架是python的flask，当时觉得这玩意老牛逼了，任何组件都能替换，你可以用jinja2/mako来做模版引擎，你可以选择SQLAlchemy或者其他orm框架来操作数据库。</p><p>思考了很久，pluggable的本质在于可替换。可替换在软件开发处处都可以体现，比如mysql驱动和mysql驱动实现，orm框架和数据库连接池，同样的orm框架，可以使用不同的连接池。而这种可替换在于抽象，golang标准库给我们提供了一套标准的sql操作接口，不同数据库只要实现这个接口。</p><p>这样想，pluggable也是离不开抽象的。抽空研究了一下micro的代码，发现，确实如此。</p><h2 id="可默认，可替换"><a href="#可默认，可替换" class="headerlink" title="可默认，可替换"></a>可默认，可替换</h2><h3 id="1-默认参数"><a href="#1-默认参数" class="headerlink" title="1. 默认参数"></a>1. 默认参数</h3><p><code>pluggable</code>,最直观的理解大概就是“可以替换，不替换也行”。在编码中，很多语言天生有一项能力和这个类似——默认参数：</p><pre><code># pythondef test(name=&quot;lqczzz&quot;):    print(name)test()  # &quot;lqczzz&quot;test(&quot;jack&quot;)  # &quot;jack&quot;</code></pre><p>这里，name这个变量是可以替换的，某种意义上也可以说是“pluggable”</p><h3 id="2-可选参数-默认值"><a href="#2-可选参数-默认值" class="headerlink" title="2. 可选参数 + 默认值"></a>2. 可选参数 + 默认值</h3><p>默认参数很方便，<code>golang</code>没有默认参数,可以通过可选参数和默认值来实现</p><pre><code>const DefaultName = &quot;lqczzz&quot;func test(args ...string) {    name := DefaultName    if len(args) != 0 { name = args[0] }    fmt.Println(name)}// 不传参数test() // &quot;lqczzz&quot;// 传参数test(&quot;jack&quot;) // &quot;jack&quot;</code></pre><p>micro的可插拔式的实现本质上也是如此。</p><pre><code>// eg:type iBE interface {    FeatureImpl()}type beOption struct {    pm iPM}type qczzzl struct {    opts beOption}func (qc *qczzzl) FeatureImpl() {    qc.opts.pm.AddFeature()    fmt.Println(&quot;qczzzl will implement it!&quot;)}pm = &amp;defaultPM{}be = &amp;qczzzl{opts: beOption{pm: pm}}be.FeatureImpl()// output:// zhangiaolong add feature// qczzzl will implement it!// 换pmnewPm := &amp;pmLiyunlong{}be.opts.pm = newPm be.FeatureImpl()// output:// liyunlong add feature// qczzzl will implement it!</code></pre><h3 id="3-接口"><a href="#3-接口" class="headerlink" title="3. 接口"></a>3. 接口</h3><h2 id="函数式参数"><a href="#函数式参数" class="headerlink" title="函数式参数"></a>函数式参数</h2><h2 id="模块的抽象"><a href="#模块的抽象" class="headerlink" title="模块的抽象"></a>模块的抽象</h2><p>变化和不变</p><p>接口<br>契约不变<br>实现方式变化</p><p>struct<br>封装依赖的变化（不变的契约依赖）<br>封装通用数据（不变的数据依赖）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;什么是可插拔式框架&quot;&gt;&lt;a href=&quot;#什么是可插拔式框架&quot; class=&quot;headerlink&quot; title=&quot;什么是可插拔式框架&quot;&gt;&lt;/a&gt;什么是可插拔式框架&lt;/h2&gt;&lt;p&gt;最早接触可插拔式的框架是python的flask，当时觉得这玩意老牛逼了，任何组件都
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>[转]go服务监控指标(metric)上报open-falcon</title>
    <link href="http://lqczzz.github.io/2018/11/26/%E8%BD%AC-go%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87-metric-%E4%B8%8A%E6%8A%A5open-falcon/"/>
    <id>http://lqczzz.github.io/2018/11/26/转-go服务监控指标-metric-上报open-falcon/</id>
    <published>2018-11-26T05:20:30.000Z</published>
    <updated>2018-11-26T05:38:22.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://segmentfault.com/a/1190000014646203#articleHeader3" target="_blank" rel="noopener">出处</a></p></blockquote><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>指标统计是实现APM（Application performance management)的基础，通常通过一些指标的统计以及上报，我们可以了解程序的运行状况，及时发现程序的问题，提前预估系统瓶颈．<br>指标(metric)目前的实现有metrics,这是java的实现，可以直接引入程序作为库使用．go语言的实现见go-metrics.<br>另外，这里只是将指标在内存中进行处理及计算，如果我们想要展示，需要将数据抛出来，这里可以抛到日志里，也可以抛到时序数据库，最简单的做法就是直接抛到监控系统进行绘图或者报警．因此本文后面将讲解各指标的含义以及如何将计算好的数据抛到监控open-falcon</p><h2 id="2-指标统计方式"><a href="#2-指标统计方式" class="headerlink" title="2.指标统计方式"></a>2.指标统计方式</h2><h3 id="2-1-Meters"><a href="#2-1-Meters" class="headerlink" title="2.1 Meters"></a>2.1 Meters</h3><p>用于计算一段时间内的计量，通常用于计算接口调用频率，如QPS(每秒的次数)，主要分为rateMean,Rate1/Rate5/Rate15等指标．</p><p>RateMean<br>单位时间内发生的次数，如一分钟发送100次，则该值为100/60.</p><p>Rate1/Rate5/Rate15<br>1分钟/5分钟/15分钟内的滑动平均值(moving average),</p><h3 id="2-2-Gauges"><a href="#2-2-Gauges" class="headerlink" title="2.2 Gauges"></a>2.2 Gauges</h3><p>用于对瞬时值的测量，如我们可以过一段时间就对内存的使用量进行统计，并上报，那么所有的数据点集就是对应时间点的内存值，Gauges只有value指标．也就是上报的是什么就是什么．</p><h3 id="2-3-Counter"><a href="#2-3-Counter" class="headerlink" title="2.3 Counter"></a>2.3 Counter</h3><p>计数类统计，可以进行加或减，也可以进行归零操作，所有的操作都是在旧值的基础上进行的．这里可以通过每天归零，然后新增注册用户时加1来统计每天的注册用户．</p><h3 id="2-4-Histograms"><a href="#2-4-Histograms" class="headerlink" title="2.4 Histograms"></a>2.4 Histograms</h3><p>主要用于对数据集中的值分布情况进行统计，典型的应用场景为接口耗时，接口每次调用都会产生耗时，记录每次调用耗时来对接口耗时情况进行分析显然不现实．因此将接口一段时间内的耗时看做数据集，并采集Count，Min, Max, Mean, Median, 75%, 95%, 99%等指标．以相对较小的资源消耗，来尽可能反应数据集的真实情况．</p><p><code>Count</code><br>距离上次清理后产生的样本数量．</p><p><code>Min</code><br>样本中的最小值</p><p><code>Max</code><br>样本中的最大值</p><p><code>Mean</code><br>所有样本的求得的平均值</p><p><code>Median</code><br>样本中的中间位置的值．</p><p><code>75%</code><br>样本中的%75位置的值．</p><p><code>95%</code><br>样本中的%95位置的值．</p><p><code>99%</code><br>样本中的%99位置的值．</p><h3 id="2-5-Timers"><a href="#2-5-Timers" class="headerlink" title="2.5 Timers"></a>2.5 Timers</h3><p>对某个代码模块同时进行统计调用频率以及调用耗时统计．指标就是Histograms以及Meters两种统计方式的合集．</p><h2 id="3-使用方式"><a href="#3-使用方式" class="headerlink" title="3.使用方式"></a>3.使用方式</h2><p>更对详细用法见go-metric文档</p><h3 id="3-1-Counter"><a href="#3-1-Counter" class="headerlink" title="3.1 Counter"></a>3.1 Counter</h3><pre><code>c := metrics.NewCounter()metrics.Register(&quot;foo&quot;, c)//进行加操作c.Inc(47)//进行减操作c.Dec(1)//获取出值c.Count()</code></pre><h3 id="3-2-Gauge"><a href="#3-2-Gauge" class="headerlink" title="3.2 Gauge"></a>3.2 Gauge</h3><pre><code>g := metrics.NewGauge()metrics.Register(&quot;bar&quot;, g)//更新瞬时值g.Update(47)//获取出瞬时值g.Value()</code></pre><h3 id="3-3-Meters"><a href="#3-3-Meters" class="headerlink" title="3.3 Meters"></a>3.3 Meters</h3><pre><code>m := metrics.NewMeter()metrics.Register(&quot;quux&quot;, m)//写入数据集m.Mark(47)//获取数据集只读快照m := metric.Snapshot()//数据集大小m.Count()//1分钟滑动平均值m.Rate1()//5分钟滑动平均值m.Rate5()//15分钟滑动平均值m.Rate15()//平均值m.RateMean()3.4 Histogramsh := metrics.NewHistogram(s)metrics.Register(&quot;baz&quot;, h)//写入数据集h.Update(47)//获取数据集只读快照h := metric.Snapshot()//数据集大小h.Count()//最小值h.Min()//最大值h.Max()//平均值h.Mean()ps := h.Percentiles([]float64{0.5, 0.75, 0.95, 0.99})//中位数ps[0]//75%的数ps[1]//95%的数ps[2]//99%的数ps[3]3.5 Timert := metrics.NewTimer()metrics.Register(&quot;bang&quot;, t)t.Time(func() {    //do some thing})t.Update(47)//获取方式同meter以及Histograms</code></pre><h2 id="4-指标上报到open-falcon"><a href="#4-指标上报到open-falcon" class="headerlink" title="4. 指标上报到open-falcon"></a>4. 指标上报到open-falcon</h2><h3 id="4-1-上报方式"><a href="#4-1-上报方式" class="headerlink" title="4.1 上报方式"></a>4.1 上报方式</h3><p>代码及使用方式见 go-metrics-falcon</p><p>实现数据上报open-falcon，只需要将所有数据取出，按open-falcon格式上报即可，这里有涉及到上报json的定义，具体如下．</p><pre><code>{    &quot;endpoint&quot;: &quot;$endpoint&quot;,    &quot;metric&quot;: &quot;$name&quot;,    &quot;value&quot;: 2.2,    &quot;step&quot;: 60,    &quot;counterType&quot;: &quot;GAUGE&quot;,    &quot;tags&quot;: &quot;project=$projectName,metricType=meter,valueType=ratemean&quot;,    &quot;timestamp&quot;: 1524724608}</code></pre><ul><li>endpoint: 这一个一般是主机hostname，用于标注是哪台机器．</li><li>metric: 指标名，由用户定义</li><li>value: 指标的值</li><li>step: 上报的时间周期</li><li>counterType: 上报的类型,这里open-falcon只支持GAUGE以及COUNTER,因此统一使用GAUGE.</li><li>tags: 标签，用于却别指标，包含指标类型，值类型，项目名三项．</li><li>timestamp: 指标上报的时间戳，单位秒．</li></ul><h3 id="4-2-效果"><a href="#4-2-效果" class="headerlink" title="4.2 效果"></a>4.2 效果</h3><p>如图，输入endpoint, 然后在counter部分输入项目名就可以过滤出该项目上报的所有指标．<br><img src="https://segmentfault.com/img/remote/1460000014646208?w=1832&amp;h=501" alt=""><br>点击指标，进入查询该指标的大图．<br><img src="https://segmentfault.com/img/remote/1460000014646209" alt=""></p><p>同时我们可以对指标设置监控，具体见open-falcon文档．</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://segmentfault.com/a/1190000014646203#articleHeader3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;出处&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>linux查看日志常用命令</title>
    <link href="http://lqczzz.github.io/2018/11/11/linux%E6%9F%A5%E7%9C%8B%E6%97%A5%E5%BF%97%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>http://lqczzz.github.io/2018/11/11/linux查看日志常用命令/</id>
    <published>2018-11-11T07:45:27.000Z</published>
    <updated>2018-11-20T06:07:32.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h2><h3 id="必须掌握"><a href="#必须掌握" class="headerlink" title="必须掌握"></a>必须掌握</h3><ol><li>cat</li><li>grep</li><li>awk</li><li>tail</li><li>head </li><li>wc (word count)</li><li>less</li><li>sort[todo]</li><li>uniq[todo]</li></ol><h3 id="不太常用但是有用"><a href="#不太常用但是有用" class="headerlink" title="不太常用但是有用"></a>不太常用但是有用</h3><ol><li>sed</li><li>tac</li><li>nl</li></ol><h2 id="详细"><a href="#详细" class="headerlink" title="详细"></a>详细</h2><p>更详细用法可以 <code>man command</code></p><h3 id="1-cat"><a href="#1-cat" class="headerlink" title="1. cat"></a>1. cat</h3><ol><li>功能：<ol><li>查看一个文本所有信息（经常和grep结合）</li><li>黏合文件</li></ol></li><li>用法：<br> cat [-benstuv] [file …]</li><li>常用参数:<br> 共7个参数，常用的是-n<br> -n  带上行数</li><li>demo<ol><li>合并文件<br> cat test1 test2 &gt; test3 (&gt; 表示覆盖写，创建的意思)<br> cat test1 test2 &gt;&gt; test3 (&gt;&gt; 表示追加写)</li><li>带行数的查看文件<br> cat -n filename</li></ol></li></ol><h3 id="2-grep"><a href="#2-grep" class="headerlink" title="2. grep"></a>2. grep</h3><ol><li>功能：<br> 正则匹配的查找文件内容</li><li><p>用法：<br> grep </p><pre><code>[-abcdDEFGHhIiJLlmnOopqRSsUVvwxZ][-A num][-B num][-C[num]][-e pattern][-f file][--binary-files=value][--color[=when]][--colour[=when]][--context[=num]][--label][--line-buffered][--null][pattern]    [file ...]</code></pre></li><li><p>常用参数:<br> -a   –text   #不要忽略二进制的数据。<br> -A&lt;显示行数&gt;   –after-context=&lt;显示行数&gt;   #除了显示符合范本样式的那一列之外，并显示该行之后的内容。<br> -b   –byte-offset   #在显示符合样式的那一行之前，标示出该行第一个字符的编号。<br> -B&lt;显示行数&gt;   –before-context=&lt;显示行数&gt;   #除了显示符合样式的那一行之外，并显示该行之前的内容。<br> -c    –count   #计算符合样式的列数。<br> -C&lt;显示行数&gt;    –context=&lt;显示行数&gt;或-&lt;显示行数&gt;   #除了显示符合样式的那一行之外，并显示该行之前后的内容。<br> -d &lt;动作&gt;      –directories=&lt;动作&gt;   #当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。<br> -e&lt;范本样式&gt;  –regexp=&lt;范本样式&gt;   #指定字符串做为查找文件内容的样式。<br> -E      –extended-regexp   #将样式为延伸的普通表示法来使用。<br> -F   –fixed-regexp   #将样式视为固定字符串的列表。<br> -G   –basic-regexp   #将样式视为普通的表示法来使用。<br> -h   –no-filename   #在显示符合样式的那一行之前，不标示该行所属的文件名称。<br> -H   –with-filename   #在显示符合样式的那一行之前，表示该行所属的文件名称。<br> -i    –ignore-case   #忽略字符大小写的差别。<br> -l    –file-with-matches   #列出文件内容符合指定的样式的文件名称。<br> -L   –files-without-match   #列出文件内容不符合指定的样式的文件名称。<br> -n   –line-number   #在显示符合样式的那一行之前，标示出该行的列数编号。<br> -q   –quiet或–silent   #不显示任何信息。<br> -r   –recursive   #此参数的效果和指定“-d recurse”参数相同。<br> -s   –no-messages   #不显示错误信息。<br> -v   –revert-match   #显示不包含匹配文本的所有行。<br> -V   –version   #显示版本信息。<br> -w   –word-regexp   #只显示全字符合的列。<br> -x    –line-regexp   #只显示全列符合的列。<br> -y   #此参数的效果和指定“-i”参数相同。</p></li><li><p>正则匹配规则</p></li></ol><p>grep的规则表达式:</p><pre><code>^  #锚定行的开始 如：&apos;^grep&apos;匹配所有以grep开头的行。    $  #锚定行的结束 如：&apos;grep$&apos;匹配所有以grep结尾的行。    .  #匹配一个非换行符的字符 如：&apos;gr.p&apos;匹配gr后接一个任意字符，然后是p。    *  #匹配零个或多个先前字符 如：&apos;*grep&apos;匹配所有一个或多个空格后紧跟grep的行。    .*   #一起用代表任意字符。   []   #匹配一个指定范围内的字符，如&apos;[Gg]rep&apos;匹配Grep和grep。    [^]  #匹配一个不在指定范围内的字符，如：&apos;[^A-FH-Z]rep&apos;匹配不包含A-R和T-Z的一个字母开头，紧跟rep的行。    \(..\)  #标记匹配字符，如&apos;\(love\)&apos;，love被标记为1。    \&lt;      #锚定单词的开始，如:&apos;\&lt;grep&apos;匹配包含以grep开头的单词的行。    \&gt;      #锚定单词的结束，如&apos;grep\&gt;&apos;匹配包含以grep结尾的单词的行。    x\{m\}  #重复字符x，m次，如：&apos;0\{5\}&apos;匹配包含5个o的行。    x\{m,\}  #重复字符x,至少m次，如：&apos;o\{5,\}&apos;匹配至少有5个o的行。    x\{m,n\}  #重复字符x，至少m次，不多于n次，如：&apos;o\{5,10\}&apos;匹配5--10个o的行。   \w    #匹配文字和数字字符，也就是[A-Za-z0-9]，如：&apos;G\w*p&apos;匹配以G后跟零个或多个文字或数字字符，然后是p。   \W    #\w的反置形式，匹配一个或多个非单词字符，如点号句号等。   \b    #单词锁定符，如: &apos;\bgrep\b&apos;只匹配grep</code></pre><ol><li>demo<ol><li>查看进程 <code>ps -ef|grep svn</code></li><li>统计进程数 <code>ps -ef|grep svn -c</code></li><li>管道查看关键字的行 <code>cat test.txt | grep -F keyword</code></li><li>管道查看关键字的行并且打印行号<code>cat test.txt | grep -nf keyword</code></li><li>直接根据关键字查看行 <code>grep keyword filename</code></li><li>多文件 <code>grep keyword filename1 filename2</code></li><li>所有文件 <code>grep keyword *</code></li><li>查看以**开头的行 <code>cat test.txt |grep ^u</code></li><li>查看以**结尾的行 <code>cat test.txt |grep hat$</code></li><li>查看不以**开头的行 <code>cat test.txt |grep ^[^u]</code></li><li>查看有**或者**的行<code>cat test.txt |grep -E &quot;ed|at&quot;</code></li></ol></li></ol><h3 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h3><ol><li><p>功能：<br> awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。<br> 特别适合一行文本特别长的时候进行显示处理</p></li><li><p>用法：<br> awk ‘{pattern + action}’ {filenames}<br> 其中action支持多种操作，强大又复杂</p></li><li>常用参数:<br> -F：分割符</li><li>demo<ol><li>查看某一行的前面部分：<code>cat filename | awk -F &#39;|&#39; &#39;{print $1, $2}&#39;</code></li></ol></li></ol><h3 id="tail-head"><a href="#tail-head" class="headerlink" title="tail/head"></a>tail/head</h3><ol><li>功能：<br> tail 显示文件末尾/开始的内容</li><li>用法：<ul><li>tail [-F | -f | -r] [-q] [-b number | -c number | -n number] [file …]</li><li>head [-n count | -c bytes] [file …]</li></ul></li><li>常用参数:<br> -f：循环读取<br> -n&lt;行数&gt;： 显示行数</li><li>demo<ol><li>监控日志：<code>tail -f filename</code></li><li>从第n行开始查看文件：<code>tail -n +100 filename</code> (必须有<code>+</code>)</li><li>查看前n行的内容：<code>head -n 20 filename</code></li><li>查看n-m行之间的内容：<code>cat -n  info.log | tail -n +140 | head -n 2</code></li></ol></li></ol><h3 id="wc"><a href="#wc" class="headerlink" title="wc"></a>wc</h3><ol><li>功能：<br> wc – word, line, character, and byte count</li><li>用法：<br> wc [-clmw] [file …]</li><li>常用参数:<br> -c 统计字节数。<br> -l 统计行数。<br> -m 统计字符数。这个标志不能与 -c 标志一起使用。<br> -w 统计字数。一个字被定义为由空白、跳格或换行字符分隔的字符串</li><li>demo<ol><li>统计行数: <code>wc -l filename</code></li><li>统计当前目录下的文件数: <code>ls -l | wc -l</code></li></ol></li></ol><h3 id="less"><a href="#less" class="headerlink" title="less"></a>less</h3><p>less 命令（分页查看文件内容）分页查看日志，但是中文有乱码<br><code>less error.log</code><br>直接定位到第100行<br><code>less +100g xx.log</code><br>定位到最后一行<br><code>less +GG xx.log</code><br>查找并高亮关键字<br><code>less fis.log.2018-05-20  | grep 2018052019004984219071028 -A 5 --color=auto</code><br>移动日志<br>    G ：到日志最后<br>    g ：到日志最前面<br>    j/↑ ：向前移动一行<br>    k/↓ ：向后移动一行<br>    pgup ：向上翻页<br>    pgdn ：向下翻页</p><h3 id="sed"><a href="#sed" class="headerlink" title="sed"></a>sed</h3><p>查看n-m行之间的内容： <code>sed -n &#39;5,10p&#39; filename</code></p><h3 id="tac"><a href="#tac" class="headerlink" title="tac"></a>tac</h3><p>和cat反着来的</p><h3 id="nl"><a href="#nl" class="headerlink" title="nl"></a>nl</h3><p>加强版 <code>cat -n</code>,使用参考 <code>man nl</code></p><h2 id="常用组合"><a href="#常用组合" class="headerlink" title="常用组合"></a>常用组合</h2><ol><li><p>实时监控日志：</p><pre><code>tail -f 20 filename</code></pre></li><li><p>显示一个文件的某几行</p><pre><code>1. `cat -n  info.log | tail -n +140 | head -n 2`2. `sed -n &quot;10,20p&quot; filename`</code></pre></li><li><p>统计行数：</p><pre><code>1. wc -l filename</code></pre></li><li><p>现在有一万多条记录，其中包含重复的记录，每条记录占一行，问如何从这些记录中找到数量排名前10的记录:</p><pre><code>sort data | uniq -c | sort -k 1 -n -r | head 10</code></pre><blockquote><p>1) sort data<br>   表示对data文件中的内容进行排序。sort命令是对于每一行的内容根据字典序（ASCII码）进行排序，这样可以保证重复的记录时相邻的。<br>2) sort data | uniq -c<br>   这里，通过管道（|）将左边部分的命令的输出作为右边部分的输入。uniq -c 表示合并相邻的重复记录，并统计重复数。因为uniq -c 只会合并相邻的记录，所以在使用该命令之前需要先排序。<br>3) sort data | uniq -c | sort -k 1 -n -r<br>   经过uniq -c 处理之后的数据格式形如”2 data”，第一个字段是数字，表示重复的记录数；第二个字段为记录的内容。我们将对此内容进行排序。sort -k 1表示对于每行的第一个字段进行排序，这里即指代表重复记录数的那个字段。因为sort命令的默认排序是按照ASCII，这就会导致按从大到小进行排序时，数值2会排在数值11的前面，所以需要使用-n 参数指定sort命令按照数值大小进行排序。-r 表示逆序，即按照从大到小的顺序进行排序。<br>4) sort data | uniq -c | sort -k 1 -n -r | head 10</p><pre><code>head 命令表示选取文本的前x行。通过head 10 就可以得到排序结果中前十行的内容</code></pre><p>来自<a href="http://eriol.iteye.com/blog/870641" target="_blank" rel="noopener">blog</a></p></blockquote></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;命令&quot;&gt;&lt;a href=&quot;#命令&quot; class=&quot;headerlink&quot; title=&quot;命令&quot;&gt;&lt;/a&gt;命令&lt;/h2&gt;&lt;h3 id=&quot;必须掌握&quot;&gt;&lt;a href=&quot;#必须掌握&quot; class=&quot;headerlink&quot; title=&quot;必须掌握&quot;&gt;&lt;/a&gt;必须掌握&lt;/h
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>模版模式在golang的使用</title>
    <link href="http://lqczzz.github.io/2018/10/27/golang%E7%BB%84%E5%90%88%E5%92%8C%E7%BB%A7%E6%89%BF/"/>
    <id>http://lqczzz.github.io/2018/10/27/golang组合和继承/</id>
    <published>2018-10-27T10:05:57.000Z</published>
    <updated>2018-10-27T11:12:20.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="从需求说起"><a href="#从需求说起" class="headerlink" title="从需求说起"></a>从需求说起</h2><p>还是timeline（微博／朋友圈etc）的业务场景。<br>timeline业务从步骤上考虑，无非就是几个步骤：</p><ol><li>获取不同的数据队列（通常是meta信息)</li><li>根据一定的算法合并和截取数据</li><li>根据合并后的meta数据获取详细的信息（content信息)</li><li>返回</li></ol><p><em>如果第一步直接获取meta信息和content信息，则信息太大，tcp耗时和内存消耗也很多</em></p><p>另外，timeline可能会分成很多类型：</p><ol><li>用户未登录看到的</li><li>用户登录看到的</li><li>推荐列表</li><li>etc</li></ol><p>这种场景最适合用模版模式实现了<br>在java里面：</p><pre><code>public asbtract class BaseTimeline {    public void Do() {        this.doRetrieve()        this.doMerge()        this.doGetContent()    }    abstract void doRetrieve()    abstract void doMerge()    abstract void doGetContent()}class LoginedTimeline extends BaseTimeline {    public void doRetrieve() {}    public void doMerge() {}    public void doGetContent() {}}class UnLoginedTimeline extends BaseTimeline {    public void doRetrieve() {}    public void doMerge() {}    public void doGetContent() {}}// 场景类public class Server {    private BaseTimeline timeline     public static void main([]string args) {        if args[0] == &quot;&quot; {            timeline = new LoginedTimeline()        } else {            timeline = new UnLoginedTimeline()        }        timeline.Do()    }}</code></pre><p>通过模版模式可以很方便的实现对timeline的扩展，新增不同的展示方式直接新增timeline类。在java servlet编程和图形界面开发(android view, html5 vue .etc)中是很常见的设计模式</p><p>可是golang的组合的方式没办法支持抽象方法</p><pre><code>type ITimeline interface {    doRetrieve()   // 获取不同的队列    doMerge()      // 合并    doGetContent() // 获取详情    Do()}type BaseTimeline struct{}func (bt *BaseTimeline) doRetrieve()   { fmt.Println(&quot;base retrieve&quot;) }func (bt *BaseTimeline) doMerge()      { fmt.Println(&quot;base merge&quot;) }func (bt *BaseTimeline) doGetContent() { fmt.Println(&quot;base content&quot;) }func (bt *BaseTimeline) Do() {    bt.doRetrieve()    bt.doMerge()    bt.doGetContent()}type LoginedTimeline struct {    BaseTimeline}func (bt *LoginedTimeline) doRetrieve()   { fmt.Println(&quot;LoginedTimeline retrieve&quot;) }func (bt *LoginedTimeline) doMerge()      { fmt.Println(&quot;LoginedTimeline merge&quot;) }func (bt *LoginedTimeline) doGetContent() { fmt.Println(&quot;LoginedTimeline content&quot;) }type UnLoginedTimeline struct {    BaseTimeline}func (bt *UnLoginedTimeline) doRetrieve()   { fmt.Println(&quot;UnLoginedTimeline retrieve&quot;) }func (bt *UnLoginedTimeline) doMerge()      { fmt.Println(&quot;UnLoginedTimeline merge&quot;) }func (bt *UnLoginedTimeline) doGetContent() { fmt.Println(&quot;UnLoginedTimeline content&quot;) }// 使用type GetTimelineRequest struct {    UserID uint64}func server(request, response interface{}) {    // GetTimelineRequest is a struct    var timeline ITimeline    switch UserID := request.(*GetTimelineRequest).UserID; {    case UserID != uint64(0):        timeline = &amp;LoginedTimeline{}    default:        timeline = &amp;UnLoginedTimeline{}    }    timeline.Do()}func main() {    req := &amp;GetTimelineRequest{}    server(req, nil)}// 输出：// base retrieve// base merge// base content</code></pre><p>原因是因为组合方式不支持方法覆盖<br>可以把Do单独出来：</p><pre><code>type ITimeline interface {    doRetrieve()   // 获取不同的队列    doMerge()      // 合并    doGetContent() // 获取详情}type BaseTimeline struct{}func (bt *BaseTimeline) doRetrieve()   { fmt.Println(&quot;base retrieve&quot;) }func (bt *BaseTimeline) doMerge()      { fmt.Println(&quot;base merge&quot;) }func (bt *BaseTimeline) doGetContent() { fmt.Println(&quot;base content&quot;) }// !!! 这里Do不再是具有接收者的方法了，调用方式也会不一样func Do(bt ITimeline) {    bt.doRetrieve()    bt.doMerge()    bt.doGetContent()}type LoginedTimeline struct {    BaseTimeline}func (bt *LoginedTimeline) doRetrieve()   { fmt.Println(&quot;LoginedTimeline retrieve&quot;) }func (bt *LoginedTimeline) doMerge()      { fmt.Println(&quot;LoginedTimeline merge&quot;) }func (bt *LoginedTimeline) doGetContent() { fmt.Println(&quot;LoginedTimeline content&quot;) }type UnLoginedTimeline struct {    BaseTimeline}func (bt *UnLoginedTimeline) doRetrieve()   { fmt.Println(&quot;UnLoginedTimeline retrieve&quot;) }func (bt *UnLoginedTimeline) doMerge()      { fmt.Println(&quot;UnLoginedTimeline merge&quot;) }func (bt *UnLoginedTimeline) doGetContent() { fmt.Println(&quot;UnLoginedTimeline content&quot;) }// 使用type GetTimelineRequest struct {    UserID uint64}func server(request, response interface{}) {    // GetTimelineRequest is a struct    var timeline ITimeline    switch UserID := request.(*GetTimelineRequest).UserID; {    case UserID != uint64(0):        timeline = &amp;LoginedTimeline{}    default:        timeline = &amp;UnLoginedTimeline{}    }    // 这里的调用方式也就变化了    Do(timeline)}func main() {    req := &amp;GetTimelineRequest{}    server(req, nil)}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;从需求说起&quot;&gt;&lt;a href=&quot;#从需求说起&quot; class=&quot;headerlink&quot; title=&quot;从需求说起&quot;&gt;&lt;/a&gt;从需求说起&lt;/h2&gt;&lt;p&gt;还是timeline（微博／朋友圈etc）的业务场景。&lt;br&gt;timeline业务从步骤上考虑，无非就是几个步骤
      
    
    </summary>
    
    
      <category term="golang" scheme="http://lqczzz.github.io/tags/golang/"/>
    
  </entry>
  
  <entry>
    <title>break 和 continue</title>
    <link href="http://lqczzz.github.io/2018/10/26/break-in-golang/"/>
    <id>http://lqczzz.github.io/2018/10/26/break-in-golang/</id>
    <published>2018-10-26T10:49:42.000Z</published>
    <updated>2018-10-26T13:40:17.000Z</updated>
    
    <content type="html"><![CDATA[<p>golang的break和continue挺好用的，和别的语言不太一样</p><h1 id="break"><a href="#break" class="headerlink" title="break"></a>break</h1><p>golang的<code>break</code>关键字<code>for</code>,<code>switch</code>,<code>select</code>会跳出三个关键字的包裹</p><blockquote><p><a href="https://golang.org/ref/spec#Break_statements" target="_blank" rel="noopener">A “break” statement terminates execution of the innermost “for”, “switch”, or “select” statement within the same function. —— 《The Go Programming Language Specification》</a></p></blockquote><p>下面一段代码</p><pre><code>for i := 0; i &lt; 6; i++ {    switch i {    case 2:        break    default:        fmt.Println(i)    }}// go run main.go：// 0// 1// 3// 4// 5</code></pre><p>如果想跳出更上一层的<code>for</code>关键字，需要指定<code>label</code></p><pre><code>forLoop:    for i := 0; i &lt; 6; i++ {        switch i {        case 2:            break forLoop        default:            fmt.Println(i)        }    }// go run main.go:// 0// 1</code></pre><h1 id="continue"><a href="#continue" class="headerlink" title="continue"></a>continue</h1><p><code>continue</code>也可以指定label</p><pre><code>forLoop:    for i := 0; i &lt; 6; i++ {        switch i {        case 2:            continue forLoop        default:            fmt.Println(i)        }    }// go run main.go// 0// 1// 3// 4// 5</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;golang的break和continue挺好用的，和别的语言不太一样&lt;/p&gt;
&lt;h1 id=&quot;break&quot;&gt;&lt;a href=&quot;#break&quot; class=&quot;headerlink&quot; title=&quot;break&quot;&gt;&lt;/a&gt;break&lt;/h1&gt;&lt;p&gt;golang的&lt;code&gt;b
      
    
    </summary>
    
    
      <category term="golang思考" scheme="http://lqczzz.github.io/tags/golang%E6%80%9D%E8%80%83/"/>
    
  </entry>
  
  <entry>
    <title>unix网络编程笔记-tcp编程基础</title>
    <link href="http://lqczzz.github.io/2018/10/21/unix%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0-tcp%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/"/>
    <id>http://lqczzz.github.io/2018/10/21/unix网络编程笔记-tcp编程基础/</id>
    <published>2018-10-21T06:00:26.000Z</published>
    <updated>2018-10-24T15:24:33.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="关于《unix网络编程》"><a href="#关于《unix网络编程》" class="headerlink" title="关于《unix网络编程》"></a>关于《unix网络编程》</h2><p>unix网络编程这书分为两册：</p><ol><li>一册讲socket编程，700多页，31章</li><li>二册讲进程之间的通信，400页，16章</li></ol><p>看目录可以看出，最基础最核心的知识在：</p><ul><li>chapter1: 简介</li><li>chapter2: tcp／udp和stcp(这玩意不管)</li><li>chapter3: 套接字编程简介</li><li>chapter4: 基本tcp套接字编程</li><li>chapter5: tcp客户／服务端程序实例</li><li>chapter30: 客户／服务程序设计范式</li></ul><p>感觉这几章学完了就差不多够了，其他章节需要再读～</p><h2 id="阅读前提"><a href="#阅读前提" class="headerlink" title="阅读前提"></a>阅读前提</h2><p>假设你对OSI七层模型有所了解</p><h2 id="chapter0-简介"><a href="#chapter0-简介" class="headerlink" title="chapter0:简介"></a>chapter0:简介</h2><h3 id="从现代交换技术说起"><a href="#从现代交换技术说起" class="headerlink" title="从现代交换技术说起"></a>从现代交换技术说起</h3><p>《现代交换技术》是通信专业的必修课，嗯嗯，好歹我也是通信专业的学生，就先把知识脉络拓展一下～</p><p>现代交换技术的分类：</p><ol><li>电路交换</li><li>分组交换</li></ol><p>计算机网络的协议用的就是分组交换技术，我们发送的信息会像快递包裹一样一个个的传送到接收方。而电路交换很简单，就是每个通信实体都连接到交换机上，而交换机使用交换的方法，让实体之间可以很方便地通信，现在最广泛的应用就是电话网络了。<br>从打电话也可以看出来，电路交换一定是：</p><ol><li>面向连接；(分组交换则不一定，如udp协议)</li><li>同步时分复用；</li><li>信息传送无差错控制；</li></ol><h3 id="chapter1-分组交换协议"><a href="#chapter1-分组交换协议" class="headerlink" title="chapter1:分组交换协议"></a>chapter1:分组交换协议</h3><p><img src="/images/net/分组交换协议.png" alt="分组交换协议"></p><ol><li>PDU: 协议数据单元，即对等实体(处于同一层)之间的交换单元信息</li><li>SDU: 下一层承载上一层数据的单元，比如tcp层传输的tcp报文(报文头+报文体)数据在tcp层就是一个PDU，传给ip层之后，ip层认为它是SDU（ip层在tcp报文之外加入ip报文头，类似俄罗斯套娃）</li></ol><p>不同协议之间的不同完全取决于协议头（废话～）</p><h3 id="tcp／ip简介"><a href="#tcp／ip简介" class="headerlink" title="tcp／ip简介"></a>tcp／ip简介</h3><ol><li>一般认为web服务器程序是长时间运行的程序，即所谓的守护程序</li><li>用户进程定义应用协议，tcp和ip协议的转换和包装在内核协议栈中，由操作系统提供支持<br><img src="/images/net/1.1.png" alt=""></li><li><p>tcp是没有记录边界的字节流协议</p><ul><li>tcp应用进程之间是没有长度限制的字节流，udp进程交换的数据长度不能超过udp发送缓冲区大小的单个记录(record)</li><li>tcp协议：应用程序一次次输出操作写到socket的数据经过顺序分割，得到分节(segment)，<em>数据量太大的时候，我们无法确保一次read到所有的数据，所以必须要把read编写在某个循环中</em></li><li>tcp没有边界,所以tcp服务需要自己实现，提供一个表示长度的协议头</li></ul></li><li>ip报文的SDU最大是65535，所以tcp一次发送的报文大小不会超过64k<br> 对于平常实用的<code>conn.Write([]byte)</code>，我们是不用考虑这些，操作系统会对这类阻塞写操作进行自动分片并且不用考虑缓冲区写满的情况</li><li>套接字编程是应用层进入传输层的接口<ul><li>这样设计由两个理由：<ol><li>应用层对通信细节很少关心，而底下四层对应用协议不关心，只关心如何通信</li><li>应用层常构成用户进程，地下四层作为操作系统和内核的机制，存在与内核态</li></ol></li><li>socket可以绕过tcp和udp直接实用ipv4/ipv6，这种socket称为原始套接字(raw socket),很少用到，在整本书里面第28章介绍了它的两个用途：<ol><li>ping</li><li>traceroute<br>因此不打算深入了解了</li></ol></li></ul></li></ol><p><img src="/images/net/osi和网际协议的对应关系.png" alt="osi和网际协议的对应关系"></p><ol><li><code>netstat</code>和<code>ifconfig</code>可以很方便的查看网络的细节</li></ol><h4 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h4><h5 id="bug"><a href="#bug" class="headerlink" title="bug"></a>bug</h5><p>这里记录一个工作中遇到的bug：</p><pre><code>// 没有for循环读取数据func request(conn net.Conn, buffer bytes.Buffer, command []byte) error {    // 读协议头，得到body的长度    recvBuf := make([]byte, 4)    resHead := binary.LittleEndian.Uint32(recvBuf)    // 指定读取数据的大小，读取数据，bug:读取不完整    var resBody bytes.Buffer    recvBuf = make([]byte, resHead)    length, err := conn.Read(recvBuf)    if err != nil {        return err    }    return nil}</code></pre><p>bug分析：</p><h5 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h5><ol><li>原因1:</li></ol><p><img src="/images/net/bug_coreserver.png" alt="bug"><br>socket上的read和write(操作系统的系统调用)不同于通常的文件读写，可能的到的字节数比预期的要少，原因在于内核缓冲区可能数据不够(read)或者缓冲区已经满了(non block write),上面的主要问题是read的时候缓冲区的数据不够，在项目中，由于网络原因，当我们</p><pre><code>var recvData = make([]byte, Size)conn.Read(recvData)</code></pre><p>这样获取数据，由于网络不稳定，可能缓冲区的数据足够，可能不够，所以出现了调用20次成功一次的情况<br>既然如此,为什么go实现<code>conn.Read()</code>为什么不帮我们阻塞去等待数据的到来呢</p><p>很遗憾<code>Read</code>没有这样的能力，go也没有提供类似c的<code>Readn</code>这样的接口</p><blockquote><p>If some data is available but not len(p) bytes, Read conventionally returns what is available instead of waiting for more.<br>来自 go io包Read接口的注释</p></blockquote><ol><li><p>原因2:</p><p> 不知道服务器端发送的逻辑(也不应该依赖它)，可能是</p><pre><code>for {    conn.Write() // 手动分片}</code></pre><p> 也可能是：</p><pre><code>conn.Write([]整个数据)</code></pre></li></ol><h5 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h5><p>套一层for循环</p><pre><code>// 修改成for循环读取数据，bug解决func request(conn net.Conn, buffer bytes.Buffer, command []byte) error {    // 读协议头，得到body的长度    recvBuf := make([]byte, 4)    resHead := binary.LittleEndian.Uint32(recvBuf)    // 指定读取数据的大小，读取数据，bug:读取不完整    var resBody bytes.Buffer    recvBuf = make([]byte, resHead)    for resBody.Len() &lt; int(resHead) {        length, err := conn.Read(recvBuf)        if err != nil {            return err        }        resBody.Write(recvBuf[:length])    }    return nil  }</code></pre><h2 id="chapter2-传输层：tcp-udp-sctp"><a href="#chapter2-传输层：tcp-udp-sctp" class="headerlink" title="chapter2:传输层：tcp/udp/sctp"></a>chapter2:传输层：tcp/udp/sctp</h2><p>主要讲了UDP／TCP／SCTP三种协议，SCTP日常用的少，以后再了解，重点讲了TCP编程，部分笔记来自第三章(方便总结)</p><h3 id="TCP-UDP协议族"><a href="#TCP-UDP协议族" class="headerlink" title="TCP/UDP协议族"></a>TCP/UDP协议族</h3><p><img src="/images/net/2.1总图.png" alt="总图"></p><ol><li>ipv4/ipv6对上层协议提供了分组递送的能力，不具有可靠性(丢包可能)</li><li>tcp是面向连接的流式套接字(stream socket)，关心确认／超时／重传的细节<ul><li>需要三次握手建立连接</li><li>源端数据发送需要对端确认，一段时间内(超时时间:RTT)收不到确认应答则重传，多次重传失败则终止传输<ul><li>RTT(round-trip time)一次客户端和服务器端往返时间</li></ul></li><li>流量控制：接收方可以告诉发送方下一次我能接受的数据量，防止接收方缓冲区溢出</li><li>tcp是全双工的</li></ul></li><li>udp是一种无连接的数据包报套接字(datagram socket)：<ul><li>不保证是否到达</li><li>不保证到达顺序</li><li>没有自动重传</li><li>没有超时概念</li><li>每个数据包都都有报文头标示长度等</li></ul></li></ol><h3 id="三次握手和四次挥手"><a href="#三次握手和四次挥手" class="headerlink" title="三次握手和四次挥手"></a>三次握手和四次挥手</h3><h4 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h4><p><img src="/images/net/基本的tcp_socket函数.png" alt="基本socket函数for tcp"></p><p>上图来自第五章，展示了基本的一个tcp客户端和服务端的socket系统调用函数的关系，具体每个系统调用的作用在下面总结。这里关心的是三次握手触发的时机:<em>服务端调用了accept，客户端调用connect主动打开</em></p><p><img src="/images/net/tcp三次握手.png" alt="三次握手"></p><h4 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h4><p><img src="/images/net/tcp四次挥手.png" alt="四次挥手"></p><ol><li>主动关闭方(客户端)发送fin分节，意思是我该说的说完了，服务器收到立马回复说我收到了,然后这个分节放到服务端的缓冲区的末尾，等待应用程序处理</li><li>应用程序处理完了，服务端也需要发一个fin告诉客户端我也完事了</li><li>在服务端发送这两个分节的过程中，服务端仍然可以向客户端发送数据</li><li>缓冲队列没有数据，服务端也不需要发送数据的时候，服务端会合并发送<code>ack m+1</code>和<code>fin n</code>分节，这时候就是三次挥手了。</li><li>主动关闭方(客户端)响应了服务端的fin分节之后，会再等一段时间，进入<code>time_wait</code>状态，</li><li>tcp是全双工的，任何一方都可以关闭，通常是客户端关闭</li></ol><h4 id="tcp状态转换"><a href="#tcp状态转换" class="headerlink" title="tcp状态转换"></a>tcp状态转换</h4><p><img src="/images/net/tcp状态转换.png" alt="tcp状态转换"></p><p><img src="/images/net/tcp连接分组交换.png" alt="tcp连接分组交换"></p><h4 id="time-wait状态"><a href="#time-wait状态" class="headerlink" title="time_wait状态"></a>time_wait状态</h4><ol><li>可靠的实现全双工连接的终止：<br> 如果最后一个ack n+1没有发送给服务端，服务端会重新发送FIN N，这种情况<strong>至少</strong>花费一次来回(&gt;=2MSL)，因此time_wait需要有至少2MSL的时间间隔</li><li>允许老的重复分节消逝，主要是防止新的连接如果用了同样的ip和端口，被认为和上一次是同一个连接</li></ol><h4 id="socket-pair"><a href="#socket-pair" class="headerlink" title="socket pair"></a>socket pair</h4><p>socket pair即<code>(src_ip, src_port, dest_ip, dest_port)</code>唯一确认一个tcp连接</p><p><img src="/images/net/并发服务器.png" alt="并发服务器"></p><p>如上图，当两个客户端连接同一个socket的时候，无法通过服务端socket的ip和port唯一确认一个连接。详细原因看chapter4</p><h2 id="chapter3-套接字编程简介"><a href="#chapter3-套接字编程简介" class="headerlink" title="chapter3:套接字编程简介"></a>chapter3:套接字编程简介</h2><ol><li>网际协议采用大端字节传递多字节数（网络字节序）<ul><li>大端字节序：高位内存地址对应高序字节</li><li>小端字节序：低位内存地址对应高序字节</li></ul></li></ol><h2 id="chapter4-基本tcp套接字编程"><a href="#chapter4-基本tcp套接字编程" class="headerlink" title="chapter4:基本tcp套接字编程"></a>chapter4:基本tcp套接字编程</h2><h3 id="1-socket函数"><a href="#1-socket函数" class="headerlink" title="1. socket函数"></a>1. <code>socket</code>函数</h3><pre><code>// 执行网络io前的第一步：socket()#include&lt;sys/socket.h&gt;int socket(int family, int type, int protocol)</code></pre><ul><li>family<br>  <img src="/images/net/socket_family.png" alt=""></li><li>type<br>  <img src="/images/net/socket_type.png" alt=""></li><li>protocol<br>  <img src="/images/net/socket_protocol.png" alt=""></li></ul><p><code>socket</code>函数调用成功会返回一个套接字描述符(类似文件描述符),只要指定协议族和套接字类型。</p><p>套接字(socket)和套接字描述符(discriptor)是一对多的关系（一个socket可以有对应多个discriptor）</p><h3 id="2-connect函数"><a href="#2-connect函数" class="headerlink" title="2. connect函数"></a>2. <code>connect</code>函数</h3><p>客户端调用<code>connect</code>函数建立tcp连接，调用<code>connect</code>之前不必调用<code>bind</code>，系统会确定源ip地址并且默认选择一个临时端口作为源端口。</p><pre><code>int connect(int sockfd, const struct sockaddr *servaddr, socklen_t addrlen)</code></pre><p>connect触发三次握手的过程,这时候有几种结果：</p><ol><li>成功</li><li>第一个<code>SYN</code>分节没有受到<code>ACK</code>，则重试，重试也失败了，返回<code>ETIMEOUT</code>错误</li><li>返回的分节不是<code>ACK</code>，是<code>RST</code>。返回<code>ECONNREFUSED</code><ul><li><code>RST</code>出现有三个条件：<ol><li>目标主机收到<code>SYN</code>分节,但是没有监听这个端口的服务器进程</li><li>tcp想取消一个已有的连接</li><li>tcp收到的分节不属于这个连接</li></ol></li></ul></li><li>ICMP路由不可达错误，客户端会重试</li></ol><h3 id="3-bind函数"><a href="#3-bind函数" class="headerlink" title="3. bind函数"></a>3. <code>bind</code>函数</h3><pre><code>int bind(int sockfd, const struct sockaddr *myaddr, socklen_t addrlen)</code></pre><p><code>bind</code>函数用于给socket地址赋予一个协议地址(ip+port)<br>服务器程序通常需要使用<code>bind</code>，客户端则由系统分配就好</p><p><code>bind</code>函数常见返回错误是<code>Address aready in use</code></p><h3 id="4-listen函数"><a href="#4-listen函数" class="headerlink" title="4. listen函数"></a>4. <code>listen</code>函数</h3><pre><code>int listen(int sockfd, int backlog)</code></pre><p><code>socket</code>函数得到的套接字默认是主动套接字，即系统认为它以后是要去做<code>connect</code>发起连接的<br>而<code>listen</code>函数的作用有二：</p><ol><li>将主动转被动，告诉系统“我不该主动，我该接受指向这个套接字的请求”</li><li><code>backlog</code>指定了内核为这个socket排队的最大连接个数(有的操作系统增加了一个模糊因子，<code>backlog</code>作为一个和最大连接数正相关的值)，内核有两个队列<br><img src="/images/net/listen的内核队列.png" alt=""></li></ol><p>三次握手的过程：<br><img src="/images/net/三次握手和队列.png" alt=""></p><ol><li>通常RTT平均在187ms</li><li>未完成队列满了对继续过来的请求分节丢弃不处理（因为客户端会重传）</li></ol><h3 id="5-accept函数"><a href="#5-accept函数" class="headerlink" title="5. accept函数"></a>5. <code>accept</code>函数</h3><pre><code>int accept(int sockfd, struct sockaddr *cliaddr, socklen_t *addrlen)</code></pre><p><code>accept</code>函数会从完成队列头push一个连接，由内核生成一个已连接套接字(connected socket)，一个服务进程通常持有一个<code>listening socket</code>（监听套接字）,n个<code>connect socket</code>（每个客户端一个）</p><h3 id="并发服务器基本原理："><a href="#并发服务器基本原理：" class="headerlink" title="并发服务器基本原理："></a>并发服务器基本原理：</h3><p>基础：文件描述符和socket描述符有一个引用计数器，被引用一次则加一，没有引用才会被清理</p><p><img src="/images/net/并发服务器套接字.png" alt=""></p><h2 id="chapter5-tcp客户／服务程序示例"><a href="#chapter5-tcp客户／服务程序示例" class="headerlink" title="chapter5:tcp客户／服务程序示例"></a>chapter5:tcp客户／服务程序示例</h2><h2 id="chapter30-客户／服务器程序设计范式"><a href="#chapter30-客户／服务器程序设计范式" class="headerlink" title="chapter30:客户／服务器程序设计范式"></a>chapter30:客户／服务器程序设计范式</h2><blockquote><p>《unix网络编程卷一》<br>《图解tcp/ip》</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;关于《unix网络编程》&quot;&gt;&lt;a href=&quot;#关于《unix网络编程》&quot; class=&quot;headerlink&quot; title=&quot;关于《unix网络编程》&quot;&gt;&lt;/a&gt;关于《unix网络编程》&lt;/h2&gt;&lt;p&gt;unix网络编程这书分为两册：&lt;/p&gt;
&lt;ol&gt;
&lt;li
      
    
    </summary>
    
    
      <category term="tcp/ip" scheme="http://lqczzz.github.io/tags/tcp-ip/"/>
    
  </entry>
  
  <entry>
    <title>优秀的博文记录</title>
    <link href="http://lqczzz.github.io/2018/10/18/%E4%BC%98%E7%A7%80%E7%9A%84%E5%8D%9A%E6%96%87%E8%AE%B0%E5%BD%95/"/>
    <id>http://lqczzz.github.io/2018/10/18/优秀的博文记录/</id>
    <published>2018-10-18T07:46:41.000Z</published>
    <updated>2018-10-18T07:47:16.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="golang优化"><a href="#golang优化" class="headerlink" title="golang优化"></a>golang优化</h2><p><a href="http://blog.cyeam.com/golang/2016/08/18/apatternforoptimizinggo" target="_blank" rel="noopener">优化Go的模式</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;golang优化&quot;&gt;&lt;a href=&quot;#golang优化&quot; class=&quot;headerlink&quot; title=&quot;golang优化&quot;&gt;&lt;/a&gt;golang优化&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;http://blog.cyeam.com/golang/2016/08/
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>从golang的fmt包入门手动内存管理</title>
    <link href="http://lqczzz.github.io/2018/10/17/golang%E7%9A%84fmt%E5%8C%85%E5%85%A5%E9%97%A8%E6%89%8B%E5%8A%A8%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"/>
    <id>http://lqczzz.github.io/2018/10/17/golang的fmt包入门手动内存管理/</id>
    <published>2018-10-17T14:01:43.000Z</published>
    <updated>2018-10-17T15:05:48.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="矫情的话"><a href="#矫情的话" class="headerlink" title="矫情的话"></a>矫情的话</h2><p>在做feed流开发的时候，我负责timeline的业务开发，刚开始设计的时候我以为也就是个业务代码开发，能有啥难度。结果开发完了之后，被leader疯狂吐槽。代码组织不好，这些都能通过对业务的深入理解，去重新设计，但是说到一个内存管理的问题，我是完全没想到的，以前没有接触过高并发场景，不知道在高并发场景下，依赖语言自身的gc会导致内存的频繁申请和回收。</p><p>痛定几周之后决定思痛，要参考学习优秀的代码<br>于是我想，哪里会有优秀的涉及到内存管理的代码呢！</p><p>官方库！！</p><p>然后想，timeline涉及网络io，io才会有大量的内存分配和回收的场景！！</p><p>直接看net包？太尼玛复杂了<br>ok，看fmt包</p><h2 id="fmt包源码摘要和笔记"><a href="#fmt包源码摘要和笔记" class="headerlink" title="fmt包源码摘要和笔记"></a>fmt包源码摘要和笔记</h2><blockquote><p>来自fmt/print.go</p></blockquote><pre><code>// Fprintf根据w的不同，调用w的write方法，很容易做到打印日志到不同地方func Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error) {    p := newPrinter()    p.doPrintf(format, a)    n, err = w.Write(p.buf)    p.free()    return}// Printf调用了Fprintf，打印的地方是os.Stdoutfunc Printf(format string, a ...interface{}) (n int, err error) {    return Fprintf(os.Stdout, format, a...)}func Sprintf(format string, a ...interface{}) string {    p := newPrinter()    p.doPrintf(format, a)    s := string(p.buf)    p.free()    return s}</code></pre><p>这里至少有三点可以学:</p><ol><li>包本身就是模块化的一种方式，对外提供的函数不一定非得属于某个对象</li><li>接口作为参数的好处：封装变化<br> 这里，变化指的是[]byte的去向，比如os.Stdout</li><li><code>p := newPrinter()</code>这里采用了临时对象池来实现内存的管理</li></ol><p>看下去：</p><pre><code>// pp is used to store a printer&apos;s state and is reused with sync.Pool to avoid allocations.type pp struct {    buf buffer    // 省略}var ppFree = sync.Pool{    New: func() interface{} { return new(pp) },}// newPrinter allocates a new pp struct or grabs a cached one.func newPrinter() *pp {    p := ppFree.Get().(*pp)    p.panicking = false    p.erroring = false    p.fmt.init(&amp;p.buf)    return p}// free saves used pp structs in ppFree; avoids an allocation per invocation.func (p *pp) free() {    p.buf = p.buf[:0]   // 清空slice    p.arg = nil     p.value = reflect.Value{}    ppFree.Put(p)   // 放回对象池里}</code></pre><p>一个sync.Pool对象就是一组临时对象的集合。Pool是协程安全的。<br>Pool用于存储那些被分配了但是没有被使用，而未来可能会使用的值，以减小垃圾回收的压力。</p><p>fmt包总是需要使用一些[]byte之类的对象，golang建立了一个临时对象池，存放着这些对象，如果需要使用一个[]byte，就去Pool里面拿，如果拿不到就分配一份。<br>这比起不停生成新的[]byte，用完了再等待gc回收来要高效得多</p><h2 id="sync-Pool测试"><a href="#sync-Pool测试" class="headerlink" title="sync.Pool测试"></a>sync.Pool测试</h2><pre><code>// 一个[]byte的对象池，每个对象为一个[]bytevar bytePool = sync.Pool{    New: func() interface{} {        b := make([]byte, 1024)        return &amp;b    },}func main() {    a := time.Now().Unix()    // 不使用对象池    for i := 0; i &lt; 1000000000; i++ {        obj := make([]byte, 1024)        _ = obj    }    b := time.Now().Unix()    // 使用对象池    for i := 0; i &lt; 1000000000; i++ {        obj := bytePool.Get().(*[]byte)        _ = obj        bytePool.Put(obj)    }    c := time.Now().Unix()    fmt.Println(&quot;without pool &quot;, b-a, &quot;s&quot;)    fmt.Println(&quot;with    pool &quot;, c-b, &quot;s&quot;)}</code></pre><blockquote><p>来自：<a href="https://www.jianshu.com/p/2bd41a8f2254" target="_blank" rel="noopener">go的临时对象池–sync.Pool</a></p></blockquote><p>测试效果：</p><pre><code>// 数据量更大更明显without pool  21 swith    pool  16 s</code></pre><p>the end…</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;矫情的话&quot;&gt;&lt;a href=&quot;#矫情的话&quot; class=&quot;headerlink&quot; title=&quot;矫情的话&quot;&gt;&lt;/a&gt;矫情的话&lt;/h2&gt;&lt;p&gt;在做feed流开发的时候，我负责timeline的业务开发，刚开始设计的时候我以为也就是个业务代码开发，能有啥难度。结果开发
      
    
    </summary>
    
    
      <category term="timeline重构任重道远" scheme="http://lqczzz.github.io/tags/timeline%E9%87%8D%E6%9E%84%E4%BB%BB%E9%87%8D%E9%81%93%E8%BF%9C/"/>
    
  </entry>
  
  <entry>
    <title>一次goroutine内存泄漏问题定位</title>
    <link href="http://lqczzz.github.io/2018/10/16/%E4%B8%80%E6%AC%A1goroutine%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D/"/>
    <id>http://lqczzz.github.io/2018/10/16/一次goroutine内存泄漏问题定位/</id>
    <published>2018-10-16T05:38:08.000Z</published>
    <updated>2018-10-21T05:57:30.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="定位过程"><a href="#定位过程" class="headerlink" title="定位过程"></a>定位过程</h2><p>问题：</p><p><img src="/images/goroutine-leak.png" alt="goroutine-leak"></p><p>Dump goroutines:</p><pre><code>ps aux | grep &apos;content_svr&apos; #43kill -USR2 43</code></pre><p>比较两小时间的Diff：<br>两小时前:</p><pre><code>$ grep &apos;cron/hashtag_suggestion&apos; /proc/43/fd/11$ grep &apos;producer&apos; /proc/43/fd153</code></pre><p>两小时后:</p><pre><code>$ grep &apos;cron/hashtag_suggestion&apos; /proc/43/fd/141$ grep &apos;producer&apos; /proc/43/fd1221</code></pre><h2 id="问题代码"><a href="#问题代码" class="headerlink" title="问题代码"></a>问题代码</h2><pre><code>// 简化了业务逻辑type Cron struct{    ch1 chan []int    ch2 chan []int}func (cron *Cron)start() {    timer := time.NewTicker(cron.taskDuration)    for {        select {        case &lt;-timer.C:            cron.doCron()        }    }}func (cron *Cron)doCron() {    cron.step1()    cron.step2()    cron.step3()}func (cron *Cron)step1() {    go func(){        cron.ch1 &lt;- []int{100}        // 注意这里没有关闭ch1，导致下面的goroutine一直没有关闭    }()}func (cron *Cron)step2() {    go func(){        for item := range cron.ch1 {            _ = item            cron.ch2 &lt;- []int{200}            // 注意这里没有关闭ch2，导致下面的goroutine一直没有关闭        }    }()}func (cron *Cron)step3() {    go func(){        for item := range cron.ch2 {            _ = item        }    }()}</code></pre><h2 id="纠正"><a href="#纠正" class="headerlink" title="纠正"></a>纠正</h2><pre><code>// 1. 每次创建goroutine时候创建channel// 2. 每次使用完channel，close channel，退出goroutinetype Cron struct{    ch1 chan []int    ch2 chan []int}const (    concurrency = 100)func (cron *Cron)start() {    timer := time.NewTicker(cron.taskDuration)    for {        select {        case &lt;-timer.C:            cron.doCron()        }    }}func (cron *Cron)doCron() {    cron.ch1 = make(chan []int, concurrency) // fixed    cron.ch2 = make(chan []int, concurrency) // fixed    cron.step1()    cron.step2()    cron.step3()}func (cron *Cron)step1() {    go func(){        cron.ch1 &lt;- []int{100}        close(ch1) // fixed    }()}func (cron *Cron)step2() {    go func(){        for item := range cron.ch1 {            _ = item            cron.ch2 &lt;- []int{200}            close(ch2) // fixed        }    }()}func (cron *Cron)step3() {    go func(){        for item := range cron.ch2 {            _ = item        }    }()}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;定位过程&quot;&gt;&lt;a href=&quot;#定位过程&quot; class=&quot;headerlink&quot; title=&quot;定位过程&quot;&gt;&lt;/a&gt;定位过程&lt;/h2&gt;&lt;p&gt;问题：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/goroutine-leak.png&quot; alt=&quot;goroutin
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>elasticSearch学习笔记</title>
    <link href="http://lqczzz.github.io/2018/10/13/elasticSearch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://lqczzz.github.io/2018/10/13/elasticSearch学习笔记/</id>
    <published>2018-10-13T14:29:32.000Z</published>
    <updated>2018-10-17T05:17:10.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="elasticSearch入门"><a href="#elasticSearch入门" class="headerlink" title="elasticSearch入门"></a>elasticSearch入门</h1><p>最近在项目中遇到了需要搜索引擎的场景，对用户输入进行自动推荐和补全，elasticSearch是开源的搜索引引擎，入门使用也很简单。</p><p>怎么入门：</p><ol><li>类比入门：类比一个熟悉的知识点，知识迁移会更容易</li><li>简单的事例入门：动手进行简单的一个demo感受一下流程</li></ol><h2 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h2><h3 id="1-安装es"><a href="#1-安装es" class="headerlink" title="1.安装es"></a>1.安装es</h3><p>前置条件：mac环境(其他环境自行google)，brew工具安装好了，java环境安装好了</p><p>步骤：</p><ol><li>安装es：<ul><li>brew install elasticsearch</li><li>es服务端会被安装</li></ul></li><li>安装kibana：<ul><li>brew install kibana</li><li>kibana可以理解为图形化的es客户端</li></ul></li><li>启动es：brew services start elasticsearch</li><li>启动kibana：brew services start kibana</li></ol><p>安装es成功之后访问<code>http://localhost:9200/</code>可以获得es的状态信息<br>安装kibana成功之后访问<code>http://localhost:5601/app/kibana#/dev_tools/console?_g=()</code>可以对es进行操作</p><h3 id="2-自动补全"><a href="#2-自动补全" class="headerlink" title="2.自动补全"></a>2.自动补全</h3><pre><code>// hashtag{    id,    name,    score, // weight}</code></pre><h4 id="mappings-amp-analysizer"><a href="#mappings-amp-analysizer" class="headerlink" title="mappings &amp; analysizer"></a>mappings &amp; analysizer</h4><pre><code>PUT feed_id{    &quot;mappings&quot;: {        &quot;hashtag&quot;: {            &quot;properties&quot;: {                &quot;name&quot;: {                    &quot;type&quot;: &quot;completion&quot;                 }            }        }    }}</code></pre><h4 id="添加数据"><a href="#添加数据" class="headerlink" title="添加数据"></a>添加数据</h4><pre><code>POST feed_id/hashtag{    &quot;name&quot;: {        &quot;input&quot;: [&quot;hashtag name&quot;],        &quot;weight&quot;: 2    }}POST feed_id/hashtag/3{    &quot;name&quot;: {        &quot;input&quot;: [&quot;hashtag name2&quot;],        &quot;weight&quot;: 3    }}POST feed_id/hashtag/4{    &quot;name&quot;: {        &quot;input&quot;: [&quot;ashtag name2&quot;],        &quot;weight&quot;: 4    }}POST feed_id/hashtag/5{    &quot;name&quot;: {        &quot;input&quot;: [&quot;shtag name2&quot;],        &quot;weight&quot;: 5    }}POST feed_id/hashtag/6{    &quot;name&quot;: {        &quot;input&quot;: [&quot;htag name2&quot;],        &quot;weight&quot;: 6    }}POST feed_id/hashtag/7{    &quot;name&quot;: {        &quot;input&quot;: [&quot;爱我中华&quot;],        &quot;weight&quot;: 6    }}POST feed_id/hashtag/8{    &quot;name&quot;: {        &quot;input&quot;: [&quot;爱你中华&quot;],        &quot;weight&quot;: 6    }}POST feed_id/hashtag/9{    &quot;name&quot;: {        &quot;input&quot;: [&quot;爱你&quot;],        &quot;weight&quot;: 6    }}</code></pre><h4 id="查询数据"><a href="#查询数据" class="headerlink" title="查询数据"></a>查询数据</h4><pre><code>POST feed_id/_search?pretty{    &quot;suggest&quot;: {        &quot;hashtag-suggest&quot;: {            &quot;prefix&quot;: &quot;h&quot;,            &quot;completion&quot;: {                &quot;field&quot;: &quot;name&quot;            }        }    }}</code></pre><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>摘抄自<a href="ttps://github.com/looly/elasticsearch-definitive-guide-cn" target="_blank" rel="noopener">elasticsearch-definitive-guide-cn</a></p><h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;elasticSearch入门&quot;&gt;&lt;a href=&quot;#elasticSearch入门&quot; class=&quot;headerlink&quot; title=&quot;elasticSearch入门&quot;&gt;&lt;/a&gt;elasticSearch入门&lt;/h1&gt;&lt;p&gt;最近在项目中遇到了需要搜索引擎的场景
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>golang并发学习笔记</title>
    <link href="http://lqczzz.github.io/2018/10/13/golang%E5%B9%B6%E5%8F%91/"/>
    <id>http://lqczzz.github.io/2018/10/13/golang并发/</id>
    <published>2018-10-12T22:28:05.000Z</published>
    <updated>2018-10-14T16:03:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>golang的并发模型叫做CSP（communicating sequential process），称为通信顺序进程模型，模型由独立并发执行的实体组成（go块），模型之间的通信通过channel来实现。因此，golang的并发模型哲学是：万物皆通信！！golang的核心概念主要是：</p><ol><li>channel</li><li>go块</li></ol><h2 id="channel"><a href="#channel" class="headerlink" title="channel"></a>channel</h2><ul><li>channel可以单独创建，在进程之间传递</li><li>channel是<code>线程安全</code>队列，任何持有channel引用的任务(go块)都可以读写channel</li><li>channel默认是无缓冲区的，也就是channel本身是同步的，一端写数据操作必然会阻塞直到channel的数据被别的地方读取</li><li><p>channel可以关闭，向关闭的channel读数据会读到的默认值，向关闭的channel写数据会导致panic！！</p><pre><code>func main() {    ch := make(chan int)    go func() {        ch &lt;- 20        close(ch)        ch &lt;- 30 //panic: send on closed channel    }()    println(&lt;-ch) // 20    println(&lt;-ch) // 0(默认值)}</code></pre></li><li><p>有缓冲区的channel，根据缓冲区已满时候的策略，可以分为</p><ul><li>阻塞型：写入阻塞</li><li>弃用新值：新值写入被抛弃</li><li>移除旧值：太旧的数据被channel抛弃</li></ul></li><li><p>channel和队列很像<br>  在 <code>golang</code>里，channel可以用 <code>for i := range channelName {}</code>循环获取channel信息</p></li></ul><h2 id="goroutine"><a href="#goroutine" class="headerlink" title="goroutine"></a>goroutine</h2><h3 id="线程模型的缺点"><a href="#线程模型的缺点" class="headerlink" title="线程模型的缺点"></a>线程模型的缺点</h3><p>java和c++的并发模型都是线程模型，它的好处是直接对硬件的抽象，大多数语言，包括python，它的线程模型都是操作系统线程，但是坏处是使用复杂。</p><p>但是线程模型有三个危害</p><blockquote><ol><li>竞态条件</li><li>死锁</li><li>内存可见性问题<br>引用自《七周七并发编程模型》</li></ol></blockquote><pre><code>public class Test {    static boolean ready = false;   // 竞态条件一：共享变量    static int data = 0    static Thread t1 = new Thread() {        public void run() {            data = 10;  // 竞态条件二：会有并行实体(线程)修改变量            ready = true;        }    };    static Thread t2 = new Thread() {        public void run() {            if (ready) {    // 竞态条件三：一个未处理完成另外一个处理可能会介入                System.out.Println(&quot;data is :&quot; + data)            } else {                System.out.Println(&quot;no data&quot;)            }        }    };    public static void main(String[] args) throw InterruptedException{        t1.start();        t2.start();        t1.join();        t2.join();    }}</code></pre><p>尽管线程模型问题很多，但是线程模型是其他模型的基础，比如nodejs的异步io模型，本质上也是基于线程池技术实现的，java的nio底层实现也是基于线程池。</p><p>线程池是多线程模型的改良，线程的启动和运行都有一定的开销，为了避免直接创建线程，才有了线程池，线程池方便了线程的复用，但是涉及线程通信的时候，如果线程被阻塞，那这个线程的资源永远都被占用者，线程池就显得鸡肋了。nodejs的决绝方法是限制程序员的代码风格，使之变成<code>事件驱动</code>的形式。</p><h3 id="goroutine调度机制和状态机"><a href="#goroutine调度机制和状态机" class="headerlink" title="goroutine调度机制和状态机"></a>goroutine调度机制和状态机</h3><p>所谓事件驱动是指node.js会把所有的异步操作使用事件机制解决，有个线程在不断地循环检测事件队列。</p><p>node.js中所有的逻辑都是事件的回调函数，所以node.js始终在事件循环中，程序入口就是事件循环第一个事件的回调函数。事件的回调函数中可能会发出I/O请求或直接发射（ emit）事件，执行完毕后返回事件循环。事件循环会检查事件队列中有没有未处理的事件，直到程序结束，因此，node.js 是单线程，异步非阻塞</p><p>node的这种方式有几个问题：</p><ol><li>CPU密集型任务存在短板</li><li>无法利用CPU的多核</li><li>代码变得难以阅读</li><li>回调函数保存数据需要经常用到全局变量</li></ol><p>golang本质上也是使用了事件驱动的机制，但是这个过程对我们是透明的，主要解决了第三个问题，原理是把每个go块(<code>go func(){}()</code>)当层成了一个状态机，当go块从channel里读写，遇到阻塞的时候，go块进入暂停状态，让出线程控制权，代码可以继续进行的时候，状态扭转，go块继续运行(可能不在原来的线程上了) </p><h4 id="goroutine和线程"><a href="#goroutine和线程" class="headerlink" title="goroutine和线程"></a>goroutine和线程</h4><ul><li>每个os线程有一个固定大小的栈内存（通常2MB）</li><li>goroutine的栈空间大小不固定，开始通常是2KB，按需扩展，最大可达1GB</li><li>go运行时候有自己的goroutine调度算法，称为m：n调度，m个goroutine运行在n个线程上</li></ul><p>同是调度算法，为何go的调度算法如此优秀？</p><p>其实不然，和操作系统线程调度器对比，主要不同在于：</p><ol><li>os内核调度上下文切换开销大，go调度器只需要调度一个go程序自己的goroutine，更容易hold住</li><li>os调度是硬件时钟中断触发的，goroutine调度的触发是channel读写阻塞或者<code>time.Sleep()</code>来实现的，因此不需要切换到内核态。</li></ol><blockquote><p>goroutine没有标识，线程是有自己的标识的，因此可以方便的实现一个线程局部变量(<code>map[thread_symbol]object</code>),在web服务器上，线程局部变量通常会被用来存储http请求信息。在goroutine上没有这种机制，鼓励更简单的编程风格。<br>——《go程序设计语言》</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;golang的并发模型叫做CSP（communicating sequential process），称为通信顺序进程模型，模型由独立并发执行的实体组成（go块），模型之间的通信通过channel来实现。因此，golang的并发模型哲学是：万物皆通信！！golang的核心概
      
    
    </summary>
    
    
      <category term="golang" scheme="http://lqczzz.github.io/tags/golang/"/>
    
      <category term="并发" scheme="http://lqczzz.github.io/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
</feed>
