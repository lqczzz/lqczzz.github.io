{"meta":{"title":"Hexo","subtitle":null,"description":null,"author":"lqczzz","url":"http://lqczzz.github.io"},"pages":[{"title":"关于","date":"2019-08-16T17:02:32.000Z","updated":"2019-08-16T17:02:32.000Z","comments":false,"path":"about/index.html","permalink":"http://lqczzz.github.io/about/index.html","excerpt":"","text":"关于我 华南理工大学 本科 2016.7 - 2018.5 华为 2018.5 - 今 shopee 兴趣 编码 旅行 vlog 文章 图：大分别府"},{"title":"分类","date":"2018-10-12T21:48:40.000Z","updated":"2018-10-12T21:48:40.000Z","comments":false,"path":"categories/index.html","permalink":"http://lqczzz.github.io/categories/index.html","excerpt":"","text":""},{"title":"书单","date":"2018-10-12T21:48:40.000Z","updated":"2018-10-12T21:48:40.000Z","comments":false,"path":"books/index.html","permalink":"http://lqczzz.github.io/books/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2018-10-12T21:48:40.000Z","updated":"2018-10-12T21:48:40.000Z","comments":true,"path":"links/index.html","permalink":"http://lqczzz.github.io/links/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-10-12T21:48:40.000Z","updated":"2018-10-12T21:48:40.000Z","comments":false,"path":"tags/index.html","permalink":"http://lqczzz.github.io/tags/index.html","excerpt":"","text":"tags: 文章标签 文章标签 文章标签"}],"posts":[{"title":"对数据系统架构设计权衡的思考","slug":"对数据系统架构设计权衡的思考","date":"2019-11-20T03:04:32.000Z","updated":"2019-11-21T07:42:47.346Z","comments":true,"path":"2019/11/20/对数据系统架构设计权衡的思考/","link":"","permalink":"http://lqczzz.github.io/2019/11/20/对数据系统架构设计权衡的思考/","excerpt":"","text":"这篇文章是在shopee参与feed项目设计和开发过程的一些思考。在feed系统设计中，很多设计算是实践了《DDIA》里面的一些论点。自认为《DDIA》中谈及的理论和在项目中得意实践其中的部分理论，让我在这两年里成长不少。 一.什么是数据系统现在的互联网产品，大部分都可以归纳为是这样一种数据系统：它使用了多种数据存储系统：mysql/redis/kafka/es/hdfs涉及到关系数据库，缓存，消息队列，搜索引擎，分布式文件系统等等，如果需要推荐，还可能有hbase等数据存储工具，每种工具各司其职，分工合作，而代码更像是连接各个系统的粘合剂。 api +----------------------------------------------------+--------------------------------------+ | | | | +-----------------+ read request .................... asyncjob | | | in-memory cache | --------------- . application code . ------------------+ | | +--------+--------+ check if data .................... | | | | in cache first | | cache miss | | | | +------------------+ | or writes | | | | |search request | | | | +-------+--------+ +---------+--------+ +-------+------+ | | | | full_text_q | | primary db | | message q | | | | +-------+--------+ +---------+--------+ +-------+------+ | | | | sync to full text | capture change | | | | +----------+-----------+ +---+ | | | | | | | | sync ...................... ...................... | | +-------------- . application code . . application code . | | ...................... ...................... | | | | +-----------------------------------------------------------------------------+-------------+ | thrid api 以twitter/weibo为代表的feed流产品就是这样一个典型的数据系统产品：它使用mysql/cassandra来持久化用户数据使用redis加速访问速度使用消息队列削峰填谷使用搜索引擎支持搜索特定用户/内容使用hbase等列式存储来做推荐/数据分析… 二.数据系统系统设计方法论2.0 数据系统设计方法和软件方法的收敛对于数据系统设计方法，先抛出结论：数据系统设计主要可以从三个角度给出问题，然后通过回答这些问题，基本可以得出一个比较合理的架构设计。 数据模型数据的访问模式 结构性/半结构性/非结构性 局部性 or 多对多关系(访问) 系统负载 读多写少(负载类型，读写扩散).. 冷热数据(负载).. 数据量.. 索引类型.. 数据的正确性和时效性 正确性：持久化保证 正确性：一致性保证(限行一致性/顺序一致性/因果一致性…) 时效性：低时效 == 最终一致 除了上面的三个角度，其实还应该考虑上人的因素，比如团队对于某种数据系统的熟悉程度。 潘家宇的《软件方法》里提供了几个软件建模思路，大体上遵循 2.1 数据模型和访问模式 在思考数据模型的时候其实需要我们充分理解需求，抽象出领域模型，通过对象关系图(1:1/1:n/n:n)，正向反向关系等区分出核心数据模型和派生的数据模型 数据模型就是判断数据是属于结构性/半结构性还是非结构性(blob)blob数据不用说，大部分都是使用分布式文件系统存储半结构性数据，比如一则feed的json { &quot;feedid&quot;: &quot;xx&quot;, &quot;feed_uid&quot;: 123, &quot;type&quot;: 1, &quot;source: 2, &quot;feed_username&quot;: &quot;&quot;, &quot;content&quot;: { &quot;voucher_stickers&quot;: [{ }], &quot;caption&quot;: &quot;&quot; }, &quot;comments&quot;: [{ }] } 因为这种数据很少需要关联查询，很适合使用mongodb等文档结构模型数据库存储，也可以采用关系型数据库存储半结构性具有更加好的局部性，有利于一对多关系，不利于多对多关系，也容易造成冗余结构性（关系型）数据利于表示多对多关系，但是局部性更差 结构性数据库表可以使用一定的犯范式设计，提高了冗余，降低一致性，但是可以提高局部性。 在做feed需求里，明显feed数据更适合使用半结构化的数据库，比如mongodb/cassandra但是shopee历史原因只支持mysql/tidb做持久化的存储。所以我们的feed内容数据是以非范式化的方式存储在表个的一个字段里的。 2.2 系统负载思考系统负载的时候其实就是思考系统的用例，系统需要对外提供哪些能力，这些接口具有哪些特性，核心难题在哪里这时候可以列出系统的关键接口，帮组我们思考。 2.2.1 读负载类型还是写负载类型负载有很多种，互联网典型的是读多写少，读多，导致了索引计数的诞生b+树类型的索引的innodb很适合读多写少的场景，但是当读的负载更高，如读放大情况，光靠innodb也不行这时候需要redis做缓存。 但是使用缓存之后，一般需要代码里双写，那么是使用cache aside模式,是淘汰缓存，都是第三点：数据的正确性和时效性考虑的这里只是根据负载特性，确定需不需要引入缓存 2.2.2 冷热数据有时候需要考虑热点数据问题，比如大v发文，评论点赞会比普通人更多，比如新旧数据，新的feed被访问概率大于旧的feed这些会影响到分表方式，kafka 分区数据等。 2.2.3 数据量决定了分表的大小和缓存的开销 2.2.4 索引选用什么类型的索引往往也是负载决定的，b+树/hash/lsm全文索引… 2.3 数据的正确性和时效性数据的正确性和时效性其实算是CA(CAP)的一种选取,需要进一步考虑各个用例的流程图(时序图)。在分布式系统里，不可靠体现在： 网络延迟 节点故障 网络超时 其中网络超时是网络延迟的另一种形式，因为分布式系统里，识别异常通常通过超时机制来实现，而超时机制的缺点就是网络超时，此时你不知道请求是否成功到达了另一个节点。所以它是最麻烦的一种异常。因为种种的不确定性，我们可以使用逐步推断的方式建立一个正确的数据系统(如果一下子假设三种情况都成立，则考虑的分支太多，不利于思考)然后思考哪些一致性是需要得到保证的 2.3.1 正确性如持久化保证顺序保证对于持久化也很重要比如CDC(change data capture)为核心的数据总线系统，使用binlog解析，导入kafka，消费者消费kafka到异构数据系统实现全文索引/推荐等功能，这时候，消息的顺序就显得很重要顺序可以通过id发号器来保证，分布式系统中，兰伯特时间序就是很重要的一个结论 2.3.2 时效性只有强一致性才能保证实时生效，在异构系统里，时效性的保证需要牺牲性能。而且大部分业务场景其实并不需要这么强的时效性，这时候就需要做权衡了。 三.举个栗子常见的社交场景中的点赞功能落地 四.总结无论是分布式系统，还是其他架构的设计，都是一种权衡的艺术，分布式面临的很多问题其实在古老的操作系统，数据库中早就有了类似的场景。","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://lqczzz.github.io/tags/分布式/"},{"name":"架构设计","slug":"架构设计","permalink":"http://lqczzz.github.io/tags/架构设计/"}]},{"title":"动手写一个数据库(开篇)","slug":"树,文件系统和数据库","date":"2019-08-27T03:04:32.000Z","updated":"2019-11-21T02:59:32.246Z","comments":true,"path":"2019/08/27/树,文件系统和数据库/","link":"","permalink":"http://lqczzz.github.io/2019/08/27/树,文件系统和数据库/","excerpt":"","text":"最近打算通过手写一个数据库的方式，来达到掌握数据库的原理的目的，同时，以此为脉络，把数据库设计涉及的一些知识形成脉络，另外还对自己的薄弱的知识块进行查漏补缺，从初级开发到高级开发那些短板都能补齐。也不好承诺一周能拿出多少时间去做这个事情，毕竟身后已满是旗帜（flag）。一步步来吧，万丈高楼平地起嘛。 这篇笔记属于知识脉络梳理的，一方面可以让知识系统化，另一方面可以细化任务，让学习的目的和方向更清晰，更可控。 stanford CS346stanford CS346 课程作业是实现一个简单的数据库系统，具体拆分为以下几步： RM（record manager 数据管理） IX（index system） SM（system manager） QL（sql 查询语言实现） EX（选一个方向然后实现） 这篇笔记算是对RM和IX的抛砖引玉。 数据库的诞生和发展鲁迅说过，计算机主要完成两件事：计算和存储（鲁迅：那是周树人说的与我何干）。翻阅图灵奖的历史，至今有四位图灵奖获得者因为在数据库领域的杰出贡献而获奖，足以见得，数据库诞生的重要意义。 1956年，在计算机诞生将近20年的时候，IBM公司成功推出磁盘存储方案，相较于在那之间的磁带技术，磁盘支持随机读取，容量大，计算机开始逐渐活跃在数据处理领域。最开始，数据处理软件只有文件管理，后来出现了文件系统，但是磁盘的数据冗余问题非常严重，据说阿波罗登月计划用的磁盘有60%以上是冗余数据，后来，一个老家伙倒腾出了网状数据库，并且于1971年推动CODASYL提出了DTBG模型，直接影响了后续的数据库技术，同年，unix的缔造者们开始撸unix-kernal，数据库的诞生完全和操作系统是同时进行的。 注意，数据库最初的诞生完全是为了解决磁盘数据冗余的问题！！所以wangyin在关系式模型的实质对数据库和关系模型的吐槽显得站不住脚，当然不是说他说的东西有问题，他说关系模型表现力不如基础的数据结构，说查询语言，sql，cyber之类的不如普通的编程语言，这当然是在扯淡了。 关系模型只能等价于别的数据结构，比如用关系模型去模拟1:1/1:m/n:m关系都是ojbk的。 sql，cypher之类的语言本身是图灵不完备的语言，编程语言基本上都是图灵完备的语言，表现力不足不是板上钉钉的吗？ 用今天的观点去看待历史，批评数据库，关系模型，何不食肉糜？ 数据库和文件系统CS346在RM一节中的任务主要介绍了 12345678910111213class PF_Manager&#123; public: PF_Manager (); // Constructor ~PF_Manager (); // Destructor RC CreateFile (const char *fileName); // Create a new file RC DestroyFile (const char *fileName); // Destroy a file RC OpenFile (const char *fileName, PF_FileHandle &amp;fileHandle); // Open a file RC CloseFile (PF_FileHandle &amp;fileHandle); // Close a file RC AllocateBlock (char *&amp;buffer); // Allocate a new scratch page in buffer RC DisposeBlock (char *buffer); // Dispose of a scratch page&#125;; 数据库和树参考资料： 《图灵和ACM图灵奖》","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://lqczzz.github.io/tags/数据库/"}]},{"title":"一个入行两年的菜鸟程序员的思考","slug":"一个入行两年的菜鸟程序员的思考 ","date":"2019-08-16T17:45:32.000Z","updated":"2019-08-17T02:37:03.000Z","comments":true,"path":"2019/08/17/一个入行两年的菜鸟程序员的思考 /","link":"","permalink":"http://lqczzz.github.io/2019/08/17/一个入行两年的菜鸟程序员的思考 /","excerpt":"","text":"前面的话从6月到8月，feed着手timeline的优化和新需求开发。从开始的轻松从容，到后来的逐渐失控。实际上，一个仿造的“人月神话”悄悄来到了我的身边。其中有很多值得反思和总结的地方。希望趁现在处于羞耻，自责和焦虑中，思考和总结点东西，一方面希望能够总结出一些自己受用的一些规则和教训，对以后成长更有帮助。另一方面，希望能借此透过现象看本质，穿越流于表面的情绪看到问题的本质，真正的获得成长。 需求之坑在做feed之前，我也曾经被需求弄的很头疼，但是当时自己并没有很重视，而是单纯的归因到团队里去。在华为正式工作的时候，因为在预研部门，项目流程不是很规范，直接leader是项目管理和人员管理的，需求是由另一个领导直接提的。 需求不是架构，需求不是设计也不是用户界面，需求是需要 —— 《程序员修炼之道》 在华为的时候，我们得到的并不是真正的需求，只是用户(leader)的模糊的需要。这种需要没有形成需求文档，产品设计文档，没有ui去描绘用户界面。还是初入职场的菜鸟的我那时候也不懂得《程序员修炼之道》里面的真知灼见，单纯的归因为团队的不规范，却又说不出具体怎么的不规范，归因为自己的技术水平但事实上，导致项目失败的原因，技术水平只占了不到1%。 来到shopee，leader是在微信和产品经理斗智斗勇多年的老司机，他用他的经验告诉我们，开发要站在用户的角度思考问题，要评估需求的合理性.另一方面，这边的产品经理也显得更加正规靠谱，毕竟是阿里头条挖过来的。 与用户一同工作，以像用户一样思考 —— 《程序员修炼之道》 正是这些，导致我再一次忽略了对需求的思考。也许我用leader那拾人牙慧的学习到了一点需求的经验。但是并没有形成自己的一套方法。 先抛出我作为一个开发者对需求评估的工作流总结： 不要搜集需求，要挖掘需求《程序员修炼之道》里给了一个典型的例子：”只有员工的上级和人事部们可以查看员工的档案”是需求吗。转换一下：只有获得授权的用户才可以访问员工档案。两种陈述对于实现来说是截然不同的。 这一点通常主要是产品的工作，但是开发从产品和用户角度去思考需求产生的原因，往往更能把控实现这件事情的方式。典型的例子是对于这一次开放用户白名单给非kol的商家的需求，PM提出来之后我马上就思考现有的实现细节，没有先分析需求提出来的原因，或者说思考的不够认真，只是流于表面的认为这个只是为了紧急支持local的99促销活动。如果我再进一步的思考，我应该去思考为什么现有的系统不能做，怎么做更佳合理。最终导致自己加班加点的去做需求。 需求文档的坑同上，这个也主要是PM的工作，但是需求文档是PM和开发的接口文档，对于开发来说，分析需求文档，建立用例图，然后通过沟通和PM澄清需求，是开发前期最重要的一个阶段。 在我们的系统中，需求文档主要有两个问题： 需求文档变更，我们经常抱怨需求文档变化，一方面是需求下来的时候可能比较紧急，文档确实不够详细，另一方面，这是需求文档本来的”原罪”，我们只是没有认识到这一点而已。 制作需求文档的一大危险是太过具体，好的需求文档会保持抽象，需求文档能准确反映商业需求 — 《程序员修炼之道》 在multitabs的需求中，我承认自己对需求文档不够重视，没有仔细斟酌里面的描述，缺少在写代码前和PM的交流，澄清需求，为了逃避交流自己做了太多假设。交流产生的结果也没有准确写入到PRD或者自己的需求规约汇中。这是自己给自己埋下的第一个坑。 ### 进度管理人月神话在”系统测试”一节给出了一个软件任务进度安排的经验法则： 1/3 计划 1/6 编码 1/4 构建测试和早期系统测试 1/4 系统测试，所有构件完成 在我看来，这些比例也并非一成不变的，但是更多的东西我没有足够的重视，或者没有足够的经验去思考出自己的一套需求开发进度安排和任务工作量估算的方式。经过一年多的踩坑，我终于认识到，进度管理真的不仅仅是leader的事情，也许我们只需要管理好一部分进度，但是进度管理的基本方法论是不变的。 计划计划这一阶段应该在需求评审会的时候，明确好以下的一些东西。 任务 责任人 进度 接口定义 设计和编码的分离首先一点我没有清晰的认识的是，计划和编码是具有清晰明确的边界的。而且计划的时间一定比编码长。在feed项目之初或者至今，我都没有很好的平衡这两点。系统时序图对于思考编码的实现，业务流程是很好的工具，可以当作设计阶段的一个很好的形式化工具，类似于vscode之于编码，系统时序图就是设计阶段的工作。 设计工作量永远大于编码，除非是一个需求很清晰，实现很清晰，代码量不足50行的需求，否则我都应该在编码之前，在草稿纸上，画出一个简单的设计。更加复杂的需求，就要借助startuml工具(puml)来完成了。 外部依赖管理一个0.5天工作量的需求，往往具有的特点是： 不存在外部依赖 代码修改量少于50行 存在外部依赖的时候，即使条件2满足了，也不能乐观的认为工作量只有0.5天完事，《人月神话》里，对于职业的苦恼，有一点正是说的—— “苦恼来自由他人设定目标，供给资源和提供信息” 推荐团队是我见过的最恶劣的合作团队，不仅仅无限延期对接的接口，给出的接口竟然能不按照穿进去的分页参数去返回结果。这也让我认识到，外部依赖永远都是不可靠的。 不仅仅是团队，内部的依赖往往也不可靠，比如你永远不清楚，一个别人定义的delexxx方法，究竟在实现里面会不会带有副作用。 在有外部依赖的情况下，工作量都需要按照1天起估算，主要是因为，对于外部依赖，需要有充足的系统测试时间。另外，当一个需求实现的工作量时间大于两天，往往需要再细分到更小的粒度，不然很容易导致失控，或者在遇到困难的时候，没办法让别人更好的参与进来一起解决。 设计之坑初级设计之坑用华为的等级来看，能不能掌握避开初级设计之坑的方法，是13级和14级的区别。13级基本不需要设计，按照既定的规范来做就好，14级开始要做初级设计，接口文档，系统设计之类的。不再埋头编码，是一个准备入行的菜鸟和已入行的弱鸡的区别。 设计阶段，有两个坑： 不知道抓重点 不知道使用什么工具／流程图表达 第1点在去年的时候我也没有清晰的认识，但是今年看完《DDIA》，结合一些实践上的思考，得出一些自己的经验规律。 比如对于接口，或者系统设计，我们首先要明确好负载，负载可能是一个高并发场景下的QPS这个指标，也可能是feed关注关系的读写扩散导致的读写放大。之后要明确好性能，性能主要是响应时间等一些我们期望达到的目标。抓重点首先要简化需求模型，脑海里有一个MVP（最小可行性）模型，方便我们对症下药。 不知道使用什么工具，一方面可能是我们对于软件开发的众多UML工具没有一个系统的了解。但是在学习完《软件方法》课程之后，其实就不太应该了。我觉得，最应该熟悉的是： 用例图 系统时序图 其他的都是用的时候再去思考哪种合适就好，永远都不要做工具的奴隶，拿起锤子，看到什么都是钉子。 高级设计之坑在华为我见过最厉害的14级的设计，也很少去很好的思考以下的一些问题： 责任是否得到了良好的定义 协作是否得到了良好的定义 耦合是否得以最小化 接口定义和各项约束是否可接受 这些都涉及一定的经验和一定的技术直觉。经验有得到需要的是3年／5年，对于善于思考的人，往往更短。 实践是最好的老师，但智者还能从其他的地方有所收获 — 《穷查理年鉴》 我们可以在自己的设计和别人的设计中不断思考反思上面的4点是如何迭代实现的。在学习开源框架中学习如何抽象对象和结构，在业务开发中，更佳灵活的根据各种需求来进行设计，把阅读开源代码学习到设计灵活应用起来，这样才能真正转化为自己的东西。 技术直觉需要源源不断的学习，保持好奇心，保持兴趣。 比如通过DDIA对数据系统的高屋建瓴般的总结，从而对常用的中间件建立一定的技术直觉。 当然，好奇心和兴趣往往因为压力打压变小，这种时候就该反思自己最近一段时间的状态了。而不是把这种状态视为理所当然。不要逃避问题，否则只能遭致更大的问题。 总结和勉励有时候，心里总会有这样的一个声音反复问自己：”为什么要总结这些东西，再怎么总结，以自己的经验，都是做不到比书本更完美的”。我想，有了两年的工作经验之后的今年，我终于找到了原因： 不把信息当知识，不把收藏当学习，不把阅读当思考，不把存储当掌握 当我们生搬硬套教科书的知识／别人的经验，那是永远都没有真正去掌握并转化为自己的能力的。 比如网络5层协议没有生搬硬套OSI7层网络模型 比如东施效颦 编码工作是理性的，枯燥和创造性并存，让其成为近百年来改变世界最明显的工作的原因，正是千百年来无数数学家思考的结晶。很多东西和生活也是相通的，比如生活中怎么管理好大大小小的事情，和项目管理也没啥区别。 愿我能继续拥有感性的精神世界，理性的生活方式。继续矫情下去，但是也能理性的去掌控好自己的生活。","categories":[],"tags":[]},{"title":"分布式系统入门","slug":"分布式系统入门","date":"2019-01-06T12:26:51.000Z","updated":"2019-03-15T17:32:40.000Z","comments":true,"path":"2019/01/06/分布式系统入门/","link":"","permalink":"http://lqczzz.github.io/2019/01/06/分布式系统入门/","excerpt":"","text":"分布式基础本文主要是《Distributed systems for fun and profit》的笔记 一.基础计算机主要做两个事情： 计算 存储 1. 为什么要用分布式系统当单台机器的硬件升级也没法解决问题的时候，就需要分布式系统。理论上来说，添加一个服务节点可以线性提升性能，但是现实中，多台机器还涉及到数据拷贝，任务合作等问题。 1.1 目标分布式系统，我们想要：可扩展性——数据或者问题规模变大，可以单纯的通过增加节点解决。 扩展性，就要求规模，节点规模从小到大，就会遇到以下问题： 性能 低时延 高吞吐 资源消耗低 可用 容错性：允许某些节点失败 延时不能过高 Availability = uptime / (uptime + downtime) | Availability % | How much downtime is allowed per year? || ———————- | ————————————– || 90% (“one nine”) | More than a month || 99% (“two nines”) | Less than 4 days || 99.9% (“three nines”) | Less than 9 hours || 99.99% (“four nines”) | Less than an hour || 99.999% (“five nines”) | ~ 5 minutes || 99.9999% (“six nines”) | ~ 31 seconds | 1.2 阻碍 节点数量 节点的距离 光速传播速度和cpu频率决定了最低时延 2. 如何研究分布式系统2.1 抽象和模型抽象可以从现实世界的复杂中得到本质的东西，这种本质就是模型 分布式系统的本质可以归纳为三个模型： 系统模型（同步／异步） 容错模型（crash-fail/partition/拜占庭问题） 一致性模型（强一致／弱一致） 抽象的目的就是为了让这个系统对外看起来像是一个节点。这里有一个矛盾，过分强调一致，会使得使用者容易理解，但是会导致性能不好，可用性降低，适当暴露一些细节会提高性能，但是增加了系统的理解成本。 3 分布式实现本质上只有两种手段： 数据分区（partition） 数据复制（replication） partition可以把数据分成几块，解决了单一节点的存储限制 replication允许我们实现可扩展，容错，但是涉及到数据的同步，是很多问题的源泉，一致性模型就是为了描述这个问题而存在的 二.理论抽象可以提取实物的本质，再通过这个本质可以推导出某种公理性的东西 系统模型就是分布式系统的抽象 1. 系统模型分布式系统模型的抽象取决于假设的多少，一般来说，假设越少越好，系统模型有三个基本的假设 节点独立运行 节点通过网络连接 节点之间的内存和时钟不共享 假设越少，推演出来的理论和算法的适用范围越广，如增加假设：节点从来不会失灵，则推演出来的算法会忽略掉节点失灵的错误处理，系统就会变得不健壮。 关于节点——节点提供了： 可执行程序 数据存储到内存和磁盘 本地时钟 节点的状态： 失灵（fail） crash 拜占庭将军问题：(叛徒) 节点通信的两种异常：左边是节点失灵，右边是网络 2. 公理有了系统模型，我们推演出了一些公理 2.1 FLP理论假设： 节点 Fail by crash （不会出现拜占庭将军问题） 网络可靠 异步系统模型 消息可能无限delay 结论 ​ 在异步通信场景，即使只有一个进程失败，也没有任何算法能保证非失败进程达到一致性 证明见参考 2.2 CAP理论 consistency: 所有节点在同一时刻看到同样的值 availability：某些节点失效并不影响剩余节点运行 Partition tolerance：即使因为网络分割或者节点失效造成的消息丢失，系统正常运行 同时满足三个性质的系统是不存在的。 比如你要强一致，并且保证高可用性，任何节点失效系统都不失效，那么对网络分割就没办法容忍了，每条消息都不能丢失。 CA（Consistency + Availability）如two-phase commit CP（Consistency + Partition tolerance）如Paxos，raft AP (Availibity + Partition tolerance) 弱一致系统，如gossip 通常，分布式系统我们需要保证P，所以要在CA作取舍 实践中我们大多已经采取了弱一致性的异步延时同步方案，以提高可用性 2.2.1 一致性的扩展这里，CAP的C理解为多个数据副本的读写一致性问题，其实C可以在很多场景拓展 多个数据副本的读写 事务 关联 关系数据库关于事务操作，必须遵循ACID原则：原子性（Atomicity，或称不可分割性）、一致性（Consistency）、隔离性（Isolation，又称独立性）和持久性（Durability） 这里的C表示一个事务中多个操作成功失败是一致的。 众所周知，分布式事务一般采用两阶段提交策略来实现，这是一个非常耗时的复杂过程，会严重影响系统效率，在实践中我们尽量避免使用它。在实践过程中，如果我们为了扩展数据容量将数据分布式存储，而事务的要求又完全不能降低。那么，系统的可用性一定会大大降低，在现实中我们一般都采用对这些数据不分散存储的策略。 nosql数据库为了实现P，牺牲了C，也即牺牲了事务，事务遵循BASE而不是ACID 三.时间和顺序3.1 全序和偏序全序就是在集合里任何两个元素都可以比较，分出大小。偏序中，某些元素是没办法比较大小的。 在分布式的系统里，每个节点的指令运行顺序都取决于本地节点的时钟，所以分布式系统是偏序。 3.2 时间匀速流逝时间是顺序的来源，分布式系统中每个节点都有独立的本地时间和时间戳，于是事件的发生有本地的顺序，但是该顺序和其他节点完全独立，很难做到全部节点有序。当然也不是做不到全序，维持一个全局时钟就是一种方法，只是这种方法的代价太大。 全局时钟（Global Clock） 本地时钟（Local Clock） 没有时钟存在（No Clock） 3.2.1 全局时钟 完美的时钟，走时同步，存在于所有节点。这是分布式系统的理想假设。实际上，时钟同步只能保证有限的精度。用户可能随机地改变本机时间，新节点加入，都有可能破坏全局时钟的假设。 现实系统也有做出这个假设的。FB的Cassandra，就是使用时间戳来解决write的冲突的 3.2.2 本地时钟 本地时钟无法保证全局有序 3.2.3 没有时钟完全不使用”时钟”这个概念，取而代之，“逻辑时间”。因为时间戳么，只不过是当前世界状态的一个快照，那我们用一个计数器（Counter），并和节点之间交流就可以做到了。 这样，我们可以在不同的节点之间决定事件顺序。不过有个坏处，因为缺乏时钟，没办法决定timeout。 “没有时钟”的假设的实现有： Lamport时钟 Vector clocks Cassandra的cousin Riak 和 Vodemort（LinkedIn）是它的应用。这些系统避免了全局or本地时钟漂移带来的不确定性。 3.2.4 逻辑时钟Lamport时钟和向量时钟通过计数器和通信来决定分布式系统中事件发生顺序的。计数器可以在不同节点之前进行比较。 3.2.4.1 Lamport时钟每个进程都维护一个计时器。 当进程做了任意一件事，增加计时器计数。 进程发送的消息中包含计时器计数。 当收到消息以后，计数器设置如下：max(local_counter, received_counter) + 1 Lamport时钟定义了一个偏序，如果 timestamp(a) &lt; timestamp(b): a 可能发生在b之前 a和b压根没法比较 第二种情况发生在a和b所在的Partition没有发送通信。 3.2.4.2 Vector clocks向量时钟是Lamport时钟的一种扩展。它维护大小为N的数列[t1, t2, ….]，N为节点数。每个节点都更新自己的时钟。 每当进程做了事情，更新该node的时钟。 进程发送的消息，包含上面提到的数组。 当收到消息以后，更新本地的数组里面的每个元素max(local, received)；为当前节点的counter加1 如图： 3.3 失灵检测对于一个节点上的程序，它怎么知道远程某个节点失效了呢？在缺乏有效准确的全局信息下，我们可以通过一个合理的timeout值来确定。但是合理的timeout值该怎么确定呢？ 失灵检测器可以通过使用心跳消息来实现timeout。节点之间交换心跳消息。如果消息在timeout之前没有收到响应，就可以认为出现失效。这种检测要么太冲动(把正常的节点算成失效），要么太保守，很长时间才能检测出错误。 论文 讨论了失灵检测在解决一致性问题中的两大属性：完整性和精准性 3.4 总结在分布式系统中应假设偏序而不是全序。而要承诺全序也是可能的，但是代价非常大。 时间，顺序和同步真的必要么？看情况。有时候可能你只不过需要最后的结果而不关系中间事件发生的顺序。 四.replication拷贝其实是一组通信问题，为一些子问题，例如选举，失灵检测，一致性和原子广播提供了上下文 拷贝本质就只有两种： 同步拷贝 异步拷贝 4.1 拷贝范式4.1.1 同步拷贝 首先client发送请求。然后同步拷贝，同步意味着这时候client还在等待着请求返回。最后，服务器返回。 这就是N-of-N write，只有等所有N个节点成功写，才返回写成功给client。系统不容忍任何服务器下线。从性能上说，最慢的服务器决定了写的速度 4.1.2 异步拷贝 master节点立即返回。该节点可能在本地做了复制，但是不会向其他服务器发送拷贝。只有在返回以后，异步的任务在开始执行。 相对地，这是1-of-N write。性能上说，快。但是不能提供强一致性保证。 4.2 拷贝算法4.2.1 overview一致性的强弱可以用来区分拷贝算法 一致性就是所有的节点都同意某一个值，具体的说，一致性包括： 协议：每个正确的流程必须就相同的价值达成一致。完整性：每个正确的过程最多决定一个值，如果它决定某个值，那么它必须由某个过程提出。终止：所有流程最终都会做出决定。有效性：如果所有正确的过程提出相同的值V，那么所有正确的过程决定V 互斥，leader选举，多播和原子广播都是更普遍的一致性问题 单拷贝系统按照一次执行中传递的消息数目，可以做一下分类： 1n messages（异步 主从备份） 2n messages（同步 主从备份） 4n messages（2-phase commit，Multi-Paxos) 6n messages （3-phase commit，Paxos with repeated leader election） 上图列出的复制算法不难发现，一致性强的算法，相应的延时高，性能低，这是一种取舍，得此失彼。 4.2.2 主从备份拷贝最常见最基本的拷贝方式。所有的update发生在primary，并且以log的形式拷贝到backup 服务器。主从备份也分同步和异步两种。 MySQL和MongoDB都使用异步主从备份。同步主从备份保证在返回给client之前，backup节点成功存储了拷贝（Replica）。不过即使这样，同步方式也仅能保证较弱的承诺。考虑下面的场景： 主服务器收到write，发送到backup backup 写成功。返回ACK 主服务器fail，client超时，认为写失败。 client现在认为写失败，但是backup其实成功。如果backup promote成为primary，那么就不对了 4.2.3 两阶段提交（2PC）2PC在很多经典的关系型数据库中都使用到了。例如MySQL 集群使用2PC提供同步拷贝。下面是2PC的基本流程 12345[ Coordinator ] -&gt; OK to commit? [ Peers ] &lt;- Yes / No[ Coordinator ] -&gt; Commit / Rollback [ Peers ] &lt;- ACK 在第一阶段，投票，协调者（Coordinator）给所有参与者发送update。每个参与者投票决定是否commit。如果选择commit，结果首先存放在临时区域（the write-ahead log）。除非第二阶段完成，这部分都只算“临时”的update。 在第二阶段，决策，协调者决定结果，并通知参与者。如果所有参与者都选择commit，那结果从临时区域移除，而成为最终结果。 2PC在最后commit之前，有一个临时区域，就能够在节点失效的时候，从而允许回滚。 之前讨论过，2PC属于CA，所以它没有考虑网络分割，对网络分割并没有容错。同时由于是N-of-N write，所以性能上会有一些折扣 4.2.4 对网络分割容错的一致性算法：gossip/raft和ZAB对网络分割容错的一致性算法其实就是实现了CAP的CP，同时保重了一定的A。 什么是网络分割（Network Partition）节点本身正常运行，但是网络链路发生问题。不同的Partition甚至还能接收client的请求。 2节点，节点失效 vs 网络分割 3节点，节点失效 vs网络分割 对这类算法会在学习MIT6.824公开课深入学习，to be continues… 4.3 总结总结下各类算法的一些关键特征。 主从备份 单独的，静态的master节点 复制日志，slaves节点并不参与执行具体操作 拷贝操作的延时没有上限 无法容错网络分割 在不一致和错误发生情况下，需要手工干涉 2PC 统一投票：提交或者放弃 静态的master节点 协调者和普通节点同时挂掉情况下无法保证一致性 无法容错网络分割 Paxos like 多数投票 动态master节点 允许n/2-1节点挂 对延时并不太敏感 遗留的问题 拜占庭将军问题 2PC flp实现 参考1. ebook 2. 区块链时代的拜占庭将军们 3. FLP impossible 4. 如何正确理解CAP","categories":[],"tags":[]},{"title":"怎样设计golang友好的api","slug":"怎样设计golang友好的api","date":"2018-12-23T17:08:47.000Z","updated":"2018-12-23T17:13:28.000Z","comments":true,"path":"2018/12/24/怎样设计golang友好的api/","link":"","permalink":"http://lqczzz.github.io/2018/12/24/怎样设计golang友好的api/","excerpt":"","text":"这篇文章是Dave Cheney在2014年发表的，我认为在go语言的接口设计上，这篇文章起到了指明灯的作用，包括Micro在内的框架，都使用了这种方式提供API。原文看这里 正文开始： 下面的内容是我的一次演示的文字版本，这是我在dotGo上演讲的『Functional options for friendly APIs』，在这里已经编辑的可读了。 我想用一个故事作为开头。 在2014年的晚些时候，你的公司发布了一款革命性的分布式社交网络工具，很明智的，你选择了Go来开发你的产品。 你分配到的任务是编写极为重要的服务端组件，看起来可能像这样 这里有一些不可导出的字段需要初始化，通过一个goroutine运行起来，响应请求。 这个包有很简单的API，非常容易使用。 但有一个问题，当你发布了你的第一个版本后，新的需求不断的被提出来。 手机客户端经常是响应的很慢，甚至停止响应。你需要添加支持来对慢的客户端主动断开连接。 为了增加安全，新的需求是增加安全连接（TLS）。 然后，你的某些用户是在一个很小的服务器上运行服务，他们需要限制客户端数量的方式。 下面是想要对并发数进行限制。 不断的新需求… 限制你需要调整你的API来满足这一系列的新需求 还需要考虑不同版本直接接口的兼容性问题。 实话说，谁用过这样的API？ 谁编写过这样的API? 谁的代码以为依赖了这样的包，而不能正常使用了？ 明显的这种解决方式是笨重而脆弱的，同时也不容易发现问题。 你的包的新用户，不知道哪些参数是可选的，哪些是必须的。 比如说，如果我想创建一个服务的实例作为测试，我需要提供一个真实的TLS证书吗，如果不需要，我需要在接口中提供什么？ 如果我不关心最大连接数，或者最大并发数，我应该在参数中设置什么值，我应该使用0？0听起来是合理的，但这依赖于具体的接口是怎样实现的，这也许真的会导致并发数限制为0。 在我看来，这样写API是容易的，同时你把正确使用接口的责任抛给了使用者。 这个例子甚至代码写的很糟糕，文档也不友好，我想这示范了一个看起来华丽，其实很脆弱的API设计。 现在我们定位了问题，我们看看解决方案。 与其提供一个单独的接口处理多种情况，一种解决方案是提供一系列的接口。 用户按需调用即可。 但你很快会发现，提供如此大量的接口，很快会让你不堪重负。 让我们看看另一种方式。 一种非常简单的方式是提供一个配置结构体。 这有一些优势。 使用这种方式，如果有新的需求加入，在结构体中增加选项即可。对外的公共API仍然保持不变。这也能让文档更加友好、可读。 在结构体上注明这是NewServer的参数，文档上也很容易识别。 潜在的它也允许用户使用0作为参数的值。 但是这种模式并不完美。 对于默认值是有歧义的，特别是0的值如果有特别的含义。 比如在这里的配置结构中，如果port没有被设置，NewServer会监听8080端口。 但是这有一个负面影响，你也许想设置为0，然后服务端默认分配一个随机端口，但你设置的0与默认值是相同的。 大部分时候，你的API用户只是想使用你的默认值。 即使他们不想改变你的配置的任何内容，仍然不得不传入一些参数。 当你的用户读你的测试代码或者示例代码时，在想着怎样使用你的包，他们会看到这个魔幻的空字符串参数。 对我来说，这让我感觉很糟糕。 为什么你的API的用户需要传入一个空的值，只是简单的让你的函数满足声明需求？ 一个常见的解决办法是传入一个结构体指针，这让调用者可以传入nil，而不用考虑空值的问题。 在我看来，这个方案有前面的示例中的所有问题，甚至让问题更复杂了。 首先，我们仍然需要在第二个参数传入点什么，但目前，这个参数可以是nil了，而且大部分时候，对于默认的使用者，它就是nil。 使用指针的方式，包的作者和使用者都会担心的是，他们引用了同一份数据，随时有可能在运行中这份数据被修改而发生突变。 我想设计精良的API不应该要求用户传递这些额外的参数，只是为了应对一些罕见的情况。 我认为我们，Go程序员，应该努力确保不要求用户传递一个nil作为参数。 如果我们想要传递配置信息时，这应该是自解释的，尽量的有表达性。 现在，我们怀着这样的理念，我讨论一下我认为更好的解决方案。 我们可以让API把不必须的参数作为一个变参。 不是传入nil，或者一些值为0的结构体，这种函数的设计发出了这样的信号：你不需要在config上传入任何参数。 在我看来这解决了两个问题。 首先，默认的调用方式变得简介命了。 其次，NewServer现在只接受config的值，不是指针，移除了nil和其他可能的参数，确保用户不会修改已经传入的参数。 我认为这个一个巨大的提升。 但我们深究一下，这仍然有问题。 明显对你的预期是提供最多一个config值，但这个参数是变参，实现的时候需要考虑用户传入多个参数的情况。 我们可以既能使用变参，同时也能提高我们的参数的表达性吗？ 我认为这就是结局方案。 在这里我想要说清楚，函数式参数的想法是来自于Rob Pike的这篇文章：Self referential functions and design ，我鼓励每个人都去看看。 这种方式与上面的例子关键的不同在于，服务的定制化并不是通过传递参数实现的，而是通过函数来直接修改server的配置本身。 正如前面看到的，不传递变参让我们使用默认的方式。 当需要进行配置时，我们传递一个操作server的配置的函数。 上面的代码中，timeout这个函数是用于改变server的配置中的timeout字段。 在NewServer的实现内部，直接应用这些函数即可。 在上面的代码中，我们调用了一个 net.Listener，在server的示例中，我们使用了这个默认的listener。 然后，对于每个传入的option，我们都调用它，把我们的配置传入进去。 很明显，如果没有option传递进来，我们就使用的是默认的server. 使用这种方式，我们可以让API有这样的特性 默认情况是实用的 高度可配置 配置可以不断增长 自解释的文档 对新的使用者很安全 不会要求传入一个nil的或者空值（只是为了让编译通过）","categories":[],"tags":[]},{"title":"可插拔式代码结构思考","slug":"可插拔式代码结构思考","date":"2018-12-12T11:10:36.000Z","updated":"2018-12-23T17:04:23.000Z","comments":true,"path":"2018/12/12/可插拔式代码结构思考/","link":"","permalink":"http://lqczzz.github.io/2018/12/12/可插拔式代码结构思考/","excerpt":"","text":"什么是可插拔式框架最早接触可插拔式的框架是python的flask，当时觉得这玩意老牛逼了，任何组件都能替换，你可以用jinja2/mako来做模版引擎，你可以选择SQLAlchemy或者其他orm框架来操作数据库。 思考了很久，pluggable的本质在于可替换。可替换在软件开发处处都可以体现，比如mysql驱动和mysql驱动实现，orm框架和数据库连接池，同样的orm框架，可以使用不同的连接池。而这种可替换在于抽象，golang标准库给我们提供了一套标准的sql操作接口，不同数据库只要实现这个接口。 这样想，pluggable也是离不开抽象的。抽空研究了一下micro的代码，发现，确实如此。 可默认，可替换1. 默认参数pluggable,最直观的理解大概就是“可以替换，不替换也行”。在编码中，很多语言天生有一项能力和这个类似——默认参数： # python def test(name=&quot;lqczzz&quot;): print(name) test() # &quot;lqczzz&quot; test(&quot;jack&quot;) # &quot;jack&quot; 这里，name这个变量是可以替换的，某种意义上也可以说是“pluggable” 2. 可选参数 + 默认值默认参数很方便，golang没有默认参数,可以通过可选参数和默认值来实现 const DefaultName = &quot;lqczzz&quot; func test(args ...string) { name := DefaultName if len(args) != 0 { name = args[0] } fmt.Println(name) } // 不传参数 test() // &quot;lqczzz&quot; // 传参数 test(&quot;jack&quot;) // &quot;jack&quot; micro的可插拔式的实现本质上也是如此。 // eg: type iBE interface { FeatureImpl() } type beOption struct { pm iPM } type qczzzl struct { opts beOption } func (qc *qczzzl) FeatureImpl() { qc.opts.pm.AddFeature() fmt.Println(&quot;qczzzl will implement it!&quot;) } pm = &amp;defaultPM{} be = &amp;qczzzl{opts: beOption{pm: pm}} be.FeatureImpl() // output: // zhangiaolong add feature // qczzzl will implement it! // 换pm newPm := &amp;pmLiyunlong{} be.opts.pm = newPm be.FeatureImpl() // output: // liyunlong add feature // qczzzl will implement it! 3. 接口函数式参数模块的抽象变化和不变 接口契约不变实现方式变化 struct封装依赖的变化（不变的契约依赖）封装通用数据（不变的数据依赖）","categories":[],"tags":[]},{"title":"[转]go服务监控指标(metric)上报open-falcon","slug":"转-go服务监控指标-metric-上报open-falcon","date":"2018-11-26T05:20:30.000Z","updated":"2018-11-26T05:38:22.000Z","comments":true,"path":"2018/11/26/转-go服务监控指标-metric-上报open-falcon/","link":"","permalink":"http://lqczzz.github.io/2018/11/26/转-go服务监控指标-metric-上报open-falcon/","excerpt":"","text":"出处 1. 概述指标统计是实现APM（Application performance management)的基础，通常通过一些指标的统计以及上报，我们可以了解程序的运行状况，及时发现程序的问题，提前预估系统瓶颈．指标(metric)目前的实现有metrics,这是java的实现，可以直接引入程序作为库使用．go语言的实现见go-metrics.另外，这里只是将指标在内存中进行处理及计算，如果我们想要展示，需要将数据抛出来，这里可以抛到日志里，也可以抛到时序数据库，最简单的做法就是直接抛到监控系统进行绘图或者报警．因此本文后面将讲解各指标的含义以及如何将计算好的数据抛到监控open-falcon 2.指标统计方式2.1 Meters用于计算一段时间内的计量，通常用于计算接口调用频率，如QPS(每秒的次数)，主要分为rateMean,Rate1/Rate5/Rate15等指标． RateMean单位时间内发生的次数，如一分钟发送100次，则该值为100/60. Rate1/Rate5/Rate151分钟/5分钟/15分钟内的滑动平均值(moving average), 2.2 Gauges用于对瞬时值的测量，如我们可以过一段时间就对内存的使用量进行统计，并上报，那么所有的数据点集就是对应时间点的内存值，Gauges只有value指标．也就是上报的是什么就是什么． 2.3 Counter计数类统计，可以进行加或减，也可以进行归零操作，所有的操作都是在旧值的基础上进行的．这里可以通过每天归零，然后新增注册用户时加1来统计每天的注册用户． 2.4 Histograms主要用于对数据集中的值分布情况进行统计，典型的应用场景为接口耗时，接口每次调用都会产生耗时，记录每次调用耗时来对接口耗时情况进行分析显然不现实．因此将接口一段时间内的耗时看做数据集，并采集Count，Min, Max, Mean, Median, 75%, 95%, 99%等指标．以相对较小的资源消耗，来尽可能反应数据集的真实情况． Count距离上次清理后产生的样本数量． Min样本中的最小值 Max样本中的最大值 Mean所有样本的求得的平均值 Median样本中的中间位置的值． 75%样本中的%75位置的值． 95%样本中的%95位置的值． 99%样本中的%99位置的值． 2.5 Timers对某个代码模块同时进行统计调用频率以及调用耗时统计．指标就是Histograms以及Meters两种统计方式的合集． 3.使用方式更对详细用法见go-metric文档 3.1 Counterc := metrics.NewCounter() metrics.Register(&quot;foo&quot;, c) //进行加操作 c.Inc(47) //进行减操作 c.Dec(1) //获取出值 c.Count() 3.2 Gaugeg := metrics.NewGauge() metrics.Register(&quot;bar&quot;, g) //更新瞬时值 g.Update(47) //获取出瞬时值 g.Value() 3.3 Metersm := metrics.NewMeter() metrics.Register(&quot;quux&quot;, m) //写入数据集 m.Mark(47) //获取数据集只读快照 m := metric.Snapshot() //数据集大小 m.Count() //1分钟滑动平均值 m.Rate1() //5分钟滑动平均值 m.Rate5() //15分钟滑动平均值 m.Rate15() //平均值 m.RateMean() 3.4 Histograms h := metrics.NewHistogram(s) metrics.Register(&quot;baz&quot;, h) //写入数据集 h.Update(47) //获取数据集只读快照 h := metric.Snapshot() //数据集大小 h.Count() //最小值 h.Min() //最大值 h.Max() //平均值 h.Mean() ps := h.Percentiles([]float64{0.5, 0.75, 0.95, 0.99}) //中位数 ps[0] //75%的数 ps[1] //95%的数 ps[2] //99%的数 ps[3] 3.5 Timer t := metrics.NewTimer() metrics.Register(&quot;bang&quot;, t) t.Time(func() { //do some thing }) t.Update(47) //获取方式同meter以及Histograms 4. 指标上报到open-falcon4.1 上报方式代码及使用方式见 go-metrics-falcon 实现数据上报open-falcon，只需要将所有数据取出，按open-falcon格式上报即可，这里有涉及到上报json的定义，具体如下． { &quot;endpoint&quot;: &quot;$endpoint&quot;, &quot;metric&quot;: &quot;$name&quot;, &quot;value&quot;: 2.2, &quot;step&quot;: 60, &quot;counterType&quot;: &quot;GAUGE&quot;, &quot;tags&quot;: &quot;project=$projectName,metricType=meter,valueType=ratemean&quot;, &quot;timestamp&quot;: 1524724608 } endpoint: 这一个一般是主机hostname，用于标注是哪台机器． metric: 指标名，由用户定义 value: 指标的值 step: 上报的时间周期 counterType: 上报的类型,这里open-falcon只支持GAUGE以及COUNTER,因此统一使用GAUGE. tags: 标签，用于却别指标，包含指标类型，值类型，项目名三项． timestamp: 指标上报的时间戳，单位秒． 4.2 效果如图，输入endpoint, 然后在counter部分输入项目名就可以过滤出该项目上报的所有指标．点击指标，进入查询该指标的大图． 同时我们可以对指标设置监控，具体见open-falcon文档．","categories":[],"tags":[]},{"title":"linux查看日志常用命令","slug":"linux查看日志常用命令","date":"2018-11-11T07:45:27.000Z","updated":"2018-11-20T06:07:32.000Z","comments":true,"path":"2018/11/11/linux查看日志常用命令/","link":"","permalink":"http://lqczzz.github.io/2018/11/11/linux查看日志常用命令/","excerpt":"","text":"命令必须掌握 cat grep awk tail head wc (word count) less sort[todo] uniq[todo] 不太常用但是有用 sed tac nl 详细更详细用法可以 man command 1. cat 功能： 查看一个文本所有信息（经常和grep结合） 黏合文件 用法： cat [-benstuv] [file …] 常用参数: 共7个参数，常用的是-n -n 带上行数 demo 合并文件 cat test1 test2 &gt; test3 (&gt; 表示覆盖写，创建的意思) cat test1 test2 &gt;&gt; test3 (&gt;&gt; 表示追加写) 带行数的查看文件 cat -n filename 2. grep 功能： 正则匹配的查找文件内容 用法： grep [-abcdDEFGHhIiJLlmnOopqRSsUVvwxZ] [-A num] [-B num] [-C[num]] [-e pattern] [-f file] [--binary-files=value] [--color[=when]] [--colour[=when]] [--context[=num]] [--label] [--line-buffered] [--null] [pattern] [file ...] 常用参数: -a –text #不要忽略二进制的数据。 -A&lt;显示行数&gt; –after-context=&lt;显示行数&gt; #除了显示符合范本样式的那一列之外，并显示该行之后的内容。 -b –byte-offset #在显示符合样式的那一行之前，标示出该行第一个字符的编号。 -B&lt;显示行数&gt; –before-context=&lt;显示行数&gt; #除了显示符合样式的那一行之外，并显示该行之前的内容。 -c –count #计算符合样式的列数。 -C&lt;显示行数&gt; –context=&lt;显示行数&gt;或-&lt;显示行数&gt; #除了显示符合样式的那一行之外，并显示该行之前后的内容。 -d &lt;动作&gt; –directories=&lt;动作&gt; #当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。 -e&lt;范本样式&gt; –regexp=&lt;范本样式&gt; #指定字符串做为查找文件内容的样式。 -E –extended-regexp #将样式为延伸的普通表示法来使用。 -F –fixed-regexp #将样式视为固定字符串的列表。 -G –basic-regexp #将样式视为普通的表示法来使用。 -h –no-filename #在显示符合样式的那一行之前，不标示该行所属的文件名称。 -H –with-filename #在显示符合样式的那一行之前，表示该行所属的文件名称。 -i –ignore-case #忽略字符大小写的差别。 -l –file-with-matches #列出文件内容符合指定的样式的文件名称。 -L –files-without-match #列出文件内容不符合指定的样式的文件名称。 -n –line-number #在显示符合样式的那一行之前，标示出该行的列数编号。 -q –quiet或–silent #不显示任何信息。 -r –recursive #此参数的效果和指定“-d recurse”参数相同。 -s –no-messages #不显示错误信息。 -v –revert-match #显示不包含匹配文本的所有行。 -V –version #显示版本信息。 -w –word-regexp #只显示全字符合的列。 -x –line-regexp #只显示全列符合的列。 -y #此参数的效果和指定“-i”参数相同。 正则匹配规则 grep的规则表达式: ^ #锚定行的开始 如：&apos;^grep&apos;匹配所有以grep开头的行。 $ #锚定行的结束 如：&apos;grep$&apos;匹配所有以grep结尾的行。 . #匹配一个非换行符的字符 如：&apos;gr.p&apos;匹配gr后接一个任意字符，然后是p。 * #匹配零个或多个先前字符 如：&apos;*grep&apos;匹配所有一个或多个空格后紧跟grep的行。 .* #一起用代表任意字符。 [] #匹配一个指定范围内的字符，如&apos;[Gg]rep&apos;匹配Grep和grep。 [^] #匹配一个不在指定范围内的字符，如：&apos;[^A-FH-Z]rep&apos;匹配不包含A-R和T-Z的一个字母开头，紧跟rep的行。 \\(..\\) #标记匹配字符，如&apos;\\(love\\)&apos;，love被标记为1。 \\&lt; #锚定单词的开始，如:&apos;\\&lt;grep&apos;匹配包含以grep开头的单词的行。 \\&gt; #锚定单词的结束，如&apos;grep\\&gt;&apos;匹配包含以grep结尾的单词的行。 x\\{m\\} #重复字符x，m次，如：&apos;0\\{5\\}&apos;匹配包含5个o的行。 x\\{m,\\} #重复字符x,至少m次，如：&apos;o\\{5,\\}&apos;匹配至少有5个o的行。 x\\{m,n\\} #重复字符x，至少m次，不多于n次，如：&apos;o\\{5,10\\}&apos;匹配5--10个o的行。 \\w #匹配文字和数字字符，也就是[A-Za-z0-9]，如：&apos;G\\w*p&apos;匹配以G后跟零个或多个文字或数字字符，然后是p。 \\W #\\w的反置形式，匹配一个或多个非单词字符，如点号句号等。 \\b #单词锁定符，如: &apos;\\bgrep\\b&apos;只匹配grep demo 查看进程 ps -ef|grep svn 统计进程数 ps -ef|grep svn -c 管道查看关键字的行 cat test.txt | grep -F keyword 管道查看关键字的行并且打印行号cat test.txt | grep -nf keyword 直接\b根据关键字查看行 grep keyword filename 多文件 grep keyword filename1 filename2 所有文件 grep keyword * 查看以**开头的行 cat test.txt |grep ^u 查看以**结尾的行 cat test.txt |grep hat$ 查看不以**开头的行 cat test.txt |grep ^[^u] 查看有**或者**的行cat test.txt |grep -E &quot;ed|at&quot; awk 功能： awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。 特别适合一行文本特别长的时候进行显示处理 用法： awk ‘{pattern + action}’ {filenames} 其中action支持多种操作，强大又复杂 常用参数: -F：分割符 demo 查看某一行的前面部分：cat filename | awk -F &#39;|&#39; &#39;{print $1, $2}&#39; tail/head 功能： tail 显示文件末尾/开始的内容 用法： tail [-F | -f | -r] [-q] [-b number | -c number | -n number] [file …] head [-n count | -c bytes] [file …] 常用参数: -f：循环读取 -n&lt;行数&gt;： 显示行数 demo 监控日志：tail -f filename 从第n行开始查看文件：tail -n +100 filename (必须有+) 查看前n行的内容：head -n 20 filename 查看n-m行之间的内容：cat -n info.log | tail -n +140 | head -n 2 wc 功能： wc – word, line, character, and byte count 用法： wc [-clmw] [file …] 常用参数: -c 统计字节数。 -l 统计行数。 -m 统计字符数。这个标志不能与 -c 标志一起使用。 -w 统计字数。一个字被定义为由空白、跳格或换行字符分隔的字符串 demo 统计行数: wc -l filename 统计当前目录下的文件数: ls -l | wc -l lessless 命令（分页查看文件内容）分页查看日志，但是中文有乱码less error.log直接定位到第100行less +100g xx.log定位到最后一行less +GG xx.log查找并高亮关键字less fis.log.2018-05-20 | grep 2018052019004984219071028 -A 5 --color=auto移动日志 G ：到日志最后 g ：到日志最前面 j/↑ ：向前移动一行 k/↓ ：向后移动一行 pgup ：向上翻页 pgdn ：向下翻页 sed查看n-m行之间的内容： sed -n &#39;5,10p&#39; filename tac和cat反着来的 nl加强版 cat -n,使用参考 man nl 常用组合 实时监控日志： tail -f 20 filename 显示一个文件的某几行 1. `cat -n info.log | tail -n +140 | head -n 2` 2. `sed -n &quot;10,20p&quot; filename` 统计行数： 1. wc -l filename 现在有一万多条记录，其中包含重复的记录，每条记录占一行，问如何从这些记录中找到数量排名前10的记录: sort data | uniq -c | sort -k 1 -n -r | head 10 1) sort data 表示对data文件中的内容进行排序。sort命令是对于每一行的内容根据字典序（ASCII码）进行排序，这样可以保证重复的记录时相邻的。2) sort data | uniq -c 这里，通过管道（|）将左边部分的命令的输出作为右边部分的输入。uniq -c 表示合并相邻的重复记录，并统计重复数。因为uniq -c 只会合并相邻的记录，所以在使用该命令之前需要先排序。3) sort data | uniq -c | sort -k 1 -n -r 经过uniq -c 处理之后的数据格式形如”2 data”，第一个字段是数字，表示重复的记录数；第二个字段为记录的内容。我们将对此内容进行排序。sort -k 1表示对于每行的第一个字段进行排序，这里即指代表重复记录数的那个字段。因为sort命令的默认排序是按照ASCII，这就会导致按从大到小进行排序时，数值2会排在数值11的前面，所以需要使用-n 参数指定sort命令按照数值大小进行排序。-r 表示逆序，即按照从大到小的顺序进行排序。4) sort data | uniq -c | sort -k 1 -n -r | head 10 head 命令表示选取文本的前x行。通过head 10 就可以得到排序结果中前十行的内容 来自blog","categories":[],"tags":[]},{"title":"模版模式在golang的使用","slug":"golang组合和继承","date":"2018-10-27T10:05:57.000Z","updated":"2018-10-27T11:12:20.000Z","comments":true,"path":"2018/10/27/golang组合和继承/","link":"","permalink":"http://lqczzz.github.io/2018/10/27/golang组合和继承/","excerpt":"","text":"从需求说起还是timeline（微博／朋友圈etc）的业务场景。timeline业务从\b步骤上考虑，无非就是\b几个步骤： 获取不同的数据队列（通常是meta信息) 根据一定的算法合并和截取数据 根据合并后的meta数据获取详细的信息（content信息) 返回 如果第一步直接获取meta信息和content信息，则信息太大，tcp耗时和内存消耗也很多 另外，timeline可能会分成很多类型： 用户未登录看到的 用户登录看到的 推荐列表 etc 这种场景最适合用模版模式实现了在java里面： public asbtract class BaseTimeline { public void Do() { this.doRetrieve() this.doMerge() this.doGetContent() } abstract void doRetrieve() abstract void doMerge() abstract void doGetContent() } class LoginedTimeline extends BaseTimeline { public void doRetrieve() {} public void doMerge() {} public void doGetContent() {} } class UnLoginedTimeline extends BaseTimeline { public void doRetrieve() {} public void doMerge() {} public void doGetContent() {} } // 场景类 public class Server { private BaseTimeline timeline public static void main([]string args) { if args[0] == &quot;&quot; { timeline = new LoginedTimeline() } else { timeline = new UnLoginedTimeline() } timeline.Do() } } 通过模版模式可以很方便的实现对timeline的扩展，新增不同的展示方式直接新增timeline\b类。在java servlet编程和图形界面开发(android view, html5 vue .etc)中是很常见的设计模式 可是golang的组合的方式没办法支持抽象方法 type ITimeline interface { doRetrieve() // 获取不同的队列 doMerge() // 合并 doGetContent() // 获取详情 Do() } type BaseTimeline struct{} func (bt *BaseTimeline) doRetrieve() { fmt.Println(&quot;base retrieve&quot;) } func (bt *BaseTimeline) doMerge() { fmt.Println(&quot;base merge&quot;) } func (bt *BaseTimeline) doGetContent() { fmt.Println(&quot;base content&quot;) } func (bt *BaseTimeline) Do() { bt.doRetrieve() bt.doMerge() bt.doGetContent() } type LoginedTimeline struct { BaseTimeline } func (bt *LoginedTimeline) doRetrieve() { fmt.Println(&quot;LoginedTimeline retrieve&quot;) } func (bt *LoginedTimeline) doMerge() { fmt.Println(&quot;LoginedTimeline merge&quot;) } func (bt *LoginedTimeline) doGetContent() { fmt.Println(&quot;LoginedTimeline content&quot;) } type UnLoginedTimeline struct { BaseTimeline } func (bt *UnLoginedTimeline) doRetrieve() { fmt.Println(&quot;UnLoginedTimeline retrieve&quot;) } func (bt *UnLoginedTimeline) doMerge() { fmt.Println(&quot;UnLoginedTimeline merge&quot;) } func (bt *UnLoginedTimeline) doGetContent() { fmt.Println(&quot;UnLoginedTimeline content&quot;) } // 使用 type GetTimelineRequest struct { UserID uint64 } func server(request, response interface{}) { // GetTimelineRequest is a struct var timeline ITimeline switch UserID := request.(*GetTimelineRequest).UserID; { case UserID != uint64(0): timeline = &amp;LoginedTimeline{} default: timeline = &amp;UnLoginedTimeline{} } timeline.Do() } func main() { req := &amp;GetTimelineRequest{} server(req, nil) } // 输出： // base retrieve // base merge // base content 原因是因为组合方式不支持方法覆盖可以把Do单独出来： type ITimeline interface { doRetrieve() // 获取不同的队列 doMerge() // 合并 doGetContent() // 获取详情 } type BaseTimeline struct{} func (bt *BaseTimeline) doRetrieve() { fmt.Println(&quot;base retrieve&quot;) } func (bt *BaseTimeline) doMerge() { fmt.Println(&quot;base merge&quot;) } func (bt *BaseTimeline) doGetContent() { fmt.Println(&quot;base content&quot;) } // !!! 这里Do不再是具有接收者的方法了，调用方式也会不一样 func Do(bt ITimeline) { bt.doRetrieve() bt.doMerge() bt.doGetContent() } type LoginedTimeline struct { BaseTimeline } func (bt *LoginedTimeline) doRetrieve() { fmt.Println(&quot;LoginedTimeline retrieve&quot;) } func (bt *LoginedTimeline) doMerge() { fmt.Println(&quot;LoginedTimeline merge&quot;) } func (bt *LoginedTimeline) doGetContent() { fmt.Println(&quot;LoginedTimeline content&quot;) } type UnLoginedTimeline struct { BaseTimeline } func (bt *UnLoginedTimeline) doRetrieve() { fmt.Println(&quot;UnLoginedTimeline retrieve&quot;) } func (bt *UnLoginedTimeline) doMerge() { fmt.Println(&quot;UnLoginedTimeline merge&quot;) } func (bt *UnLoginedTimeline) doGetContent() { fmt.Println(&quot;UnLoginedTimeline content&quot;) } // 使用 type GetTimelineRequest struct { UserID uint64 } func server(request, response interface{}) { // GetTimelineRequest is a struct var timeline ITimeline switch UserID := request.(*GetTimelineRequest).UserID; { case UserID != uint64(0): timeline = &amp;LoginedTimeline{} default: timeline = &amp;UnLoginedTimeline{} } // 这里的调用方式也就变化了 Do(timeline) } func main() { req := &amp;GetTimelineRequest{} server(req, nil) }","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"http://lqczzz.github.io/tags/golang/"}]},{"title":"break 和 continue","slug":"break-in-golang","date":"2018-10-26T10:49:42.000Z","updated":"2018-10-26T13:40:17.000Z","comments":true,"path":"2018/10/26/break-in-golang/","link":"","permalink":"http://lqczzz.github.io/2018/10/26/break-in-golang/","excerpt":"","text":"golang的break和continue挺好用的，和别的语言不太\b一样 breakgolang的break关键字for,switch,select会跳出三个关键字的包裹 A “break” statement terminates execution of the innermost “for”, “switch”, or “select” statement within the same function. —— 《The Go Programming Language Specification》 下面一段代码 for i := 0; i &lt; 6; i++ { switch i { case 2: break default: fmt.Println(i) } } // go run main.go： // 0 // 1 // 3 // 4 // 5 如果想跳出更上一层的for关键字，需要指定label forLoop: for i := 0; i &lt; 6; i++ { switch i { case 2: break forLoop default: fmt.Println(i) } } // go run main.go: // 0 // 1 continuecontinue也可以指定label forLoop: for i := 0; i &lt; 6; i++ { switch i { case 2: continue forLoop default: fmt.Println(i) } } // go run main.go // 0 // 1 // 3 // 4 // 5","categories":[],"tags":[{"name":"golang思考","slug":"golang思考","permalink":"http://lqczzz.github.io/tags/golang思考/"}]},{"title":"unix网络编程笔记-tcp编程基础","slug":"unix网络编程笔记-tcp编程基础","date":"2018-10-21T06:00:26.000Z","updated":"2018-10-24T15:24:33.000Z","comments":true,"path":"2018/10/21/unix网络编程笔记-tcp编程基础/","link":"","permalink":"http://lqczzz.github.io/2018/10/21/unix网络编程笔记-tcp编程基础/","excerpt":"","text":"\b关于《unix网络编程》unix网络编程这书分为两册： 一册讲socket编程，700多页，31章 二册讲进程之间的通信，400页，16章 看目录可以看出，最基础最核心的知识在： chapter1: 简介 chapter2: tcp／udp和stcp(这玩意不管) chapter3: 套接字编程简介 chapter4: 基本tcp套接字编程 chapter5: tcp客户／服务端程序实例 chapter30: 客户／服务程序设计范式 感觉这几章学完了就差不多够了，其他章节\b需要再读～ 阅读前提假设你对OSI七层模型有所了解 chapter0:简介从现代交换技术说起《现代交换技术》是通信专业的必修课，嗯嗯，好歹我也是通信专业的学生，就先把知识脉络拓展一下～ 现代交换技术的分类： 电路交换 分组交换 计算机网络的协议用的就是分组交换技术，我们发送的信息会像快递包裹一样一个个的传送到接收方。而电路交换很简单，就是每个通信实体都连接到交换机上，而交换机使用交换的方法，让实体之间可以很方便地通信，现在最广泛的应用就是电话网络了。从打电话也可以看出来，电路交换一定是： 面向连接；(分组交换则不一定，如udp协议) 同步时分复用； 信息传送无差错控制； chapter1:分组交换协议 PDU: 协议数据单元，即对等实体(处于同一层)之间的交换单元信息 SDU: 下一层承载上一层数据的单元，比如tcp层传输的tcp报文(报文头+报文体)数据在tcp层就是一个PDU，传给ip层之后，ip层认为它是SDU（ip层在tcp报文之外加入ip报文头，类似俄罗斯套娃） 不同协议之间的不同完全取决于协议头（废话～） tcp／ip简介 一般认为web服务器程序是长时间运行的程序，即所谓的守护程序 用户进程定义应用协议，tcp和ip协议的转换和包装在内核协议栈中，由操作系统提供支持 tcp是没有记录边界的字节流协议 tcp\b应用进程之间\u001c是没有长度限制的字节流，udp进程交换的数据长度不能超过udp发送缓冲区大小的单个记录(record) tcp\b协议：应用程序一次次输出操作写到socket的数据经过顺序分割，得到分节(segment)，\b数据量太大的时候，我们无法确保一次read到所有的数据，所以必须要把read编写在某个循环中 tcp没有边界,所以tcp服务需要自己实现，提供一个表示长度的协议头 ip报文的SDU最大是65535，所以tcp一次发送的报文大小不会超过64k 对于\b平常实用的conn.Write([]byte)，我们是不用考虑这些，操作系统会对这类阻塞写操作进行自动分片并且不用考虑缓冲区写满的情况 套接字编程是应用层进入传输层的接口 这样设计由两个理由： 应用层对通信细节很少关心，而底下四层对应用协议不关心，只关心如何通信 应用层常构成用户进程，地下四层作为操作系统和内核的机制，存在与内核态 socket可以绕过tcp和udp直接实用ipv4/ipv6，这种socket称为原始套接字(raw socket),很少用到，在整本书里面第28章介绍了它的两个用途： ping traceroute因此不打算深入了解了 netstat和ifconfig可以很方便的查看网络的细节 案例分析bug这里记录一个工作中遇到的bug： // 没有for循环读取数据 func request(conn net.Conn, buffer bytes.Buffer, command []byte) error { // 读协议头，得到body的长度 recvBuf := make([]byte, 4) resHead := binary.LittleEndian.Uint32(recvBuf) // \b指定\b读取数据的大小，读取数据，bug:读取不完整 var resBody bytes.Buffer recvBuf = make([]byte, resHead) length, err := conn.Read(recvBuf) if err != nil { return err } return nil } bug分析： 原因 原因1: \bsocket上的read和write(操作系统的系统调用)不同于通常的文件读写，可能的到的字节数比预期的\b要少，原因在于内核缓冲区可能数据不够(read)或者缓冲区已经满了(non block write),上面的主要问题是read的时候缓冲区的数据不够，在项目中，由于网络原因，当我们 var recvData = make([]byte, Size) conn.Read(recvData) \b\b这样获取数据，由于网络不稳定，可能缓冲区的数据足够，可能不够，所以出现了调用20次成功一次的情况既然如此,为什么go实现conn.Read()为什么不帮我们阻塞去等待数据的到来呢 很遗憾Read没有这样的能力，go也没有提供类似c的Readn这样的接口 If some data is available but not len(p) bytes, Read conventionally returns what is available instead of waiting for more.来自 go io包Read接口的注释 原因2: 不知道服务器端发送的逻辑(也不应该依赖它)，可能是 for { conn.Write() // 手动分片 } 也可能是： conn.Write([]整个数据) 解决套一层for循环 // 修改成for循环读取数据，bug解决 func request(conn net.Conn, buffer bytes.Buffer, command []byte) error { // 读协议头，得到body的长度 recvBuf := make([]byte, 4) resHead := binary.LittleEndian.Uint32(recvBuf) // \b指定\b读取数据的大小，读取数据，bug:读取不完整 var resBody bytes.Buffer recvBuf = make([]byte, resHead) for resBody.Len() &lt; int(resHead) { length, err := conn.Read(recvBuf) if err != nil { return err } resBody.Write(recvBuf[:length]) } return nil } chapter2:传输层：tcp/udp/sctp主要讲了UDP／TCP／SCTP三种协议，SCTP日常用的少，以后再了解，重点讲了TCP编程，部分笔记来自第三章(方便总结) TCP/UDP协议族 ipv4/ipv6对上层协议提供了分组递送的能力，不具有可靠性(丢包可能) tcp是面向连接的流式套接字(stream socket)，关心确认／超时／重传的细节 需要三次握手建立连接 源端数据发送需要对端确认，一段时间内(超时时间:RTT)收不到确认应答则重传，多次重传失败则终止传输 RTT(round-trip time)一次客户端和服务器端往返时间 流量控制：接收方可以告诉发送方下一次我能接受的数据量，防止接收方缓冲区溢出 tcp是全双工的 udp是一种无连接的数据包报套接字(datagram socket)： 不保证是否到达 不保证到达顺序 没有自动重传 没有超时概念 每个数据包都都有报文头标示长度等 三次握手和四次挥手三次握手 上图来自第五章，展示了基本的一个tcp客户端和服务端的socket系统调用函数的关系，具体每个系统调用的作用在下面总结。\b这里关心的是三次握手触发的时机:服务端调用了accept，客户端调用connect主动打开 四次挥手 主动关闭方(客户端)发送fin分节，意思是我该说的说完了，服务器收到立马回复说我收到了,然后这个分节放到服务端的缓冲区的末尾，等待应用程序处理 应用程序处理完了，服务端也需要发一个fin告诉客户端我也完事了 在服务端发送这两个分节的过程中，服务端仍然可以向客户端发送数据 缓冲队列没有数据，服务端也不需要发送数据的时候，服务端会\b合并发送ack m+1和fin n分节，这时候就是三次挥手了。 主动关闭方(客户端)响应了服务端的fin分节之后，会再等一段时间，进入time_wait状态， tcp是全双工的，任何一方都可以\b关闭，通常是客户端关闭 tcp状态转换 time_wait状态 可靠的实现全双工连接的终止： 如果最后一个ack n+1没有发送给服务端，服务端会重新发送FIN N，这种情况至少花费一次来回(&gt;=2MSL)，因此time_wait需要有至少2MSL的时间间隔 允许老的重复分节消逝，主要是防止新的连接如果用了同样的ip和端口，被认为和上一次是同一个连接 socket pairsocket pair即(src_ip, src_port, dest_ip, dest_port)唯一确认一个tcp连接 如上图，当两个客户端连接同一个socket的时候，无法通过服务端socket的ip和port唯一确认一个连接。详细原因看chapter4 chapter3:套接字编程简介 网际协议采用大端字节传递多字节数（网络字节序） 大端字节序：高位内存地址对应高序字节 小端字节序：低位内存地址对应高序字节 chapter4:基本tcp套接字编程1. socket函数// 执行网络io前的第一步：socket() #include&lt;sys/socket.h&gt; int socket(int family, int type, int protocol) family type protocol socket函数调用成功会返回一个\b套接字描述符(类似文件描述符),只要指定协议族和套接字类型。 套接字(socket)和套接字描述符(discriptor)是一对多的关系（一个socket可以有对应多个discriptor） 2. connect函数客户端调用connect函数建立tcp连接，调用connect之前不必调用bind，系统会确定源ip地址并且默认选择一个临时端口作为源端口。 int connect(int sockfd, const struct sockaddr *servaddr, socklen_t addrlen) connect触发三次握手的过程,\b这时候有几种结果： 成功 第一个SYN分节没有受到ACK，则重试，重试也失败了，返回ETIMEOUT错误 返回的分节不是ACK，是RST。返回ECONNREFUSED RST出现有三个条件： 目标主机收到SYN分节,但是没有监听这个端口的服务器进程 tcp想取消一个已有的连接 tcp收到的分节不属于这个连接 ICMP路由不可达错误，客户端会重试 3. bind函数int bind(int sockfd, const struct sockaddr *myaddr, socklen_t addrlen) bind函数用于给socket地址赋予一个协议地址(ip+port)服务器程序通常需要使用bind，客户端则由系统分配就好 bind函数常见返回错误是Address aready in use 4. listen函数int listen(int sockfd, int backlog) \u001csocket函数得到的套接字默认是主动套接字，即系统认为它以后是要去做connect发起连接的而listen函数的作用有二： 将主动转被动，告诉系统“我不该主动，我该接受指向这个套接字的请求” \bbacklog指定了内核为这个socket排队的最大连接个数(有的操作系统增加了一个模糊因子，backlog作为一个和最大连接数正相关的值)，内核有两个队列 三次握手的过程： 通常RTT平均在187ms 未完成队列满了对继续过来的请求分节丢弃不处理（因为客户端会重传） 5. accept函数int accept(int sockfd, struct sockaddr *cliaddr, socklen_t *addrlen) accept函数会从完成队列头push一个连接，由内核生成一个已连接套接字(connected socket)，一个服务进程通常持有一个listening socket（监听套接字）,n个connect socket（每个客户端一个） 并发服务器基本原理：基础：文件描述符和socket描述符有一个引用计数器，被引用一次则加一，没有引用才会被清理 chapter5:tcp客户／服务程序示例chapter30:客户／服务器程序设计范式 《unix网络编程卷一》《图解tcp/ip》","categories":[],"tags":[{"name":"tcp/ip","slug":"tcp-ip","permalink":"http://lqczzz.github.io/tags/tcp-ip/"}]},{"title":"优秀的博文记录","slug":"优秀的博文记录","date":"2018-10-18T07:46:41.000Z","updated":"2018-10-18T07:47:16.000Z","comments":true,"path":"2018/10/18/优秀的博文记录/","link":"","permalink":"http://lqczzz.github.io/2018/10/18/优秀的博文记录/","excerpt":"","text":"golang优化优化Go的模式","categories":[],"tags":[]},{"title":"从golang的fmt包入门手动内存管理","slug":"golang的fmt包入门手动内存管理","date":"2018-10-17T14:01:43.000Z","updated":"2018-10-17T15:05:48.000Z","comments":true,"path":"2018/10/17/golang的fmt包入门手动内存管理/","link":"","permalink":"http://lqczzz.github.io/2018/10/17/golang的fmt包入门手动内存管理/","excerpt":"","text":"矫情的话在做feed流开发的时候，我负责timeline的业务开发，刚开始设计的时候我以为也就是个业务代码开发，能有啥难度。结果开发完了之后，被leader疯狂吐槽。代码组织不好，这些都能通过对业务的深入理解，去重新设计，但是说到一个内存管理的问题，我是完全没想到的，以前没有接触过高并发场景，不知道在高并发场景下，依赖语言自身的gc会导致内存的频繁申请和回收。 痛定几周之后决定思痛，要参考学习优秀的代码于是我想，哪里会有优秀的涉及到内存管理的代码呢！ 官方库！！ 然后想，timeline涉及网络io，io才会有大量的内存分配和回收的场景！！ 直接看net包？太尼玛复杂了ok，看fmt包 fmt包源码摘要和笔记 来自fmt/print.go // Fprintf根据w的不同，调用w的write方法，很容易做到打印日志到不同地方 func Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error) { p := newPrinter() p.doPrintf(format, a) n, err = w.Write(p.buf) p.free() return } // Printf调用了Fprintf，打印的地方是os.Stdout func Printf(format string, a ...interface{}) (n int, err error) { return Fprintf(os.Stdout, format, a...) } func Sprintf(format string, a ...interface{}) string { p := newPrinter() p.doPrintf(format, a) s := string(p.buf) p.free() return s } 这里至少有三点可以学: 包本身就是模块化的一种方式，对外提供的函数不一定非得属于某个对象 接口作为参数的好处：封装变化 这里，变化指的是[]byte的去向，比如os.Stdout p := newPrinter()这里采用了临时对象池来实现内存的管理 看下去： // pp is used to store a printer&apos;s state and is reused with sync.Pool to avoid allocations. type pp struct { buf buffer // 省略 } var ppFree = sync.Pool{ New: func() interface{} { return new(pp) }, } // newPrinter allocates a new pp struct or grabs a cached one. func newPrinter() *pp { p := ppFree.Get().(*pp) p.panicking = false p.erroring = false p.fmt.init(&amp;p.buf) return p } // free saves used pp structs in ppFree; avoids an allocation per invocation. func (p *pp) free() { p.buf = p.buf[:0] // 清空slice p.arg = nil p.value = reflect.Value{} ppFree.Put(p) // 放回对象池里 } 一个sync.Pool对象就是一组临时对象的集合。Pool是协程安全的。Pool用于存储那些被分配了但是没有被使用，而未来可能会使用的值，以减小垃圾回收的压力。 fmt包总是需要使用一些[]byte之类的对象，golang建立了一个临时对象池，存放着这些对象，如果需要使用一个[]byte，就去Pool里面拿，如果拿不到就分配一份。这比起不停生成新的[]byte，用完了再等待gc回收来要高效得多 sync.Pool测试// 一个[]byte的对象池，每个对象为一个[]byte var bytePool = sync.Pool{ New: func() interface{} { b := make([]byte, 1024) return &amp;b }, } func main() { a := time.Now().Unix() // 不使用对象池 for i := 0; i &lt; 1000000000; i++ { obj := make([]byte, 1024) _ = obj } b := time.Now().Unix() // 使用对象池 for i := 0; i &lt; 1000000000; i++ { obj := bytePool.Get().(*[]byte) _ = obj bytePool.Put(obj) } c := time.Now().Unix() fmt.Println(&quot;without pool &quot;, b-a, &quot;s&quot;) fmt.Println(&quot;with pool &quot;, c-b, &quot;s&quot;) } 来自：go的临时对象池–sync.Pool 测试效果： // 数据量更大更明显 without pool 21 s with pool 16 s the end…","categories":[],"tags":[{"name":"timeline重构任重道远","slug":"timeline重构任重道远","permalink":"http://lqczzz.github.io/tags/timeline重构任重道远/"}]},{"title":"一次goroutine内存泄漏问题定位","slug":"一次goroutine内存泄漏问题定位","date":"2018-10-16T05:38:08.000Z","updated":"2018-10-21T05:57:30.000Z","comments":true,"path":"2018/10/16/一次goroutine内存泄漏问题定位/","link":"","permalink":"http://lqczzz.github.io/2018/10/16/一次goroutine内存泄漏问题定位/","excerpt":"","text":"定位过程问题： Dump goroutines: ps aux | grep &apos;content_svr&apos; #43 kill -USR2 43 比较两小时间的Diff：两小时前: $ grep &apos;cron/hashtag_suggestion&apos; /proc/43/fd/1 1 $ grep &apos;producer&apos; /proc/43/fd1 53 两小时后: $ grep &apos;cron/hashtag_suggestion&apos; /proc/43/fd/1 41 $ grep &apos;producer&apos; /proc/43/fd1 221 问题代码// 简化了业务逻辑 type Cron struct{ ch1 chan []int ch2 chan []int } func (cron *Cron)start() { timer := time.NewTicker(cron.taskDuration) for { select { case &lt;-timer.C: cron.doCron() } } } func (cron *Cron)doCron() { cron.step1() cron.step2() cron.step3() } func (cron *Cron)step1() { go func(){ cron.ch1 &lt;- []int{100} // 注意这里没有关闭ch1，导致下面的goroutine一直没有关闭 }() } func (cron *Cron)step2() { go func(){ for item := range cron.ch1 { _ = item cron.ch2 &lt;- []int{200} // 注意这里没有关闭ch2，导致下面的goroutine一直没有关闭 } }() } func (cron *Cron)step3() { go func(){ for item := range cron.ch2 { _ = item } }() } 纠正// 1. 每次创建goroutine时候创建channel // 2. 每次使用完channel，close channel，退出goroutine type Cron struct{ ch1 chan []int ch2 chan []int } const ( concurrency = 100 ) func (cron *Cron)start() { timer := time.NewTicker(cron.taskDuration) for { select { case &lt;-timer.C: cron.doCron() } } } func (cron *Cron)doCron() { cron.ch1 = make(chan []int, concurrency) // fixed cron.ch2 = make(chan []int, concurrency) // fixed cron.step1() cron.step2() cron.step3() } func (cron *Cron)step1() { go func(){ cron.ch1 &lt;- []int{100} close(ch1) // fixed }() } func (cron *Cron)step2() { go func(){ for item := range cron.ch1 { _ = item cron.ch2 &lt;- []int{200} close(ch2) // fixed } }() } func (cron *Cron)step3() { go func(){ for item := range cron.ch2 { _ = item } }() }","categories":[],"tags":[]},{"title":"elasticSearch学习笔记","slug":"elasticSearch学习笔记","date":"2018-10-13T14:29:32.000Z","updated":"2018-10-17T05:17:10.000Z","comments":true,"path":"2018/10/13/elasticSearch学习笔记/","link":"","permalink":"http://lqczzz.github.io/2018/10/13/elasticSearch学习笔记/","excerpt":"","text":"elasticSearch入门最近在项目中遇到了需要搜索引擎的场景，对用户输入进行自动推荐和补全，elasticSearch是\b开源的搜索引引擎，入门使用也很简单。 怎么入门： 类比入门：类比一个熟悉的知识点，知识迁移\b会更容易 简单的事例入门：动手进行简单的一个demo感受一下流程 入门1.安装es前置条件：mac环境(其他环境自行google)，brew工具安装好了，java环境安装好了 步骤： 安装es： brew install elasticsearch es服务端会被安装 安装kibana： brew install kibana kibana可以理解为图形化的es客户端 启动es：brew services start elasticsearch 启动kibana：brew services start kibana 安装es成功之后访问http://localhost:9200/可以获得es的状态信息安装kibana成功之后访问http://localhost:5601/app/kibana#/dev_tools/console?_g=()可以对es进行操作 2.自动补全// hashtag { id, name, score, // weight } mappings &amp; analysizerPUT feed_id { &quot;mappings&quot;: { &quot;hashtag&quot;: { &quot;properties&quot;: { &quot;name&quot;: { &quot;type&quot;: &quot;completion&quot; } } } } } 添加数据POST feed_id/hashtag { &quot;name&quot;: { &quot;input&quot;: [&quot;hashtag name&quot;], &quot;weight&quot;: 2 } } POST feed_id/hashtag/3 { &quot;name&quot;: { &quot;input&quot;: [&quot;hashtag name2&quot;], &quot;weight&quot;: 3 } } POST feed_id/hashtag/4 { &quot;name&quot;: { &quot;input&quot;: [&quot;ashtag name2&quot;], &quot;weight&quot;: 4 } } POST feed_id/hashtag/5 { &quot;name&quot;: { &quot;input&quot;: [&quot;shtag name2&quot;], &quot;weight&quot;: 5 } } POST feed_id/hashtag/6 { &quot;name&quot;: { &quot;input&quot;: [&quot;htag name2&quot;], &quot;weight&quot;: 6 } } POST feed_id/hashtag/7 { &quot;name&quot;: { &quot;input&quot;: [&quot;爱我中华&quot;], &quot;weight&quot;: 6 } } POST feed_id/hashtag/8 { &quot;name&quot;: { &quot;input&quot;: [&quot;爱你中华&quot;], &quot;weight&quot;: 6 } } POST feed_id/hashtag/9 { &quot;name&quot;: { &quot;input&quot;: [&quot;爱你&quot;], &quot;weight&quot;: 6 } } 查询数据POST feed_id/_search?pretty { &quot;suggest&quot;: { &quot;hashtag-suggest&quot;: { &quot;prefix&quot;: &quot;h&quot;, &quot;completion&quot;: { &quot;field&quot;: &quot;name&quot; } } } } 基本概念摘抄自elasticsearch-definitive-guide-cn 参考：","categories":[],"tags":[]},{"title":"golang并发学习笔记","slug":"golang并发","date":"2018-10-12T22:28:05.000Z","updated":"2018-10-14T16:03:46.000Z","comments":true,"path":"2018/10/13/golang并发/","link":"","permalink":"http://lqczzz.github.io/2018/10/13/golang并发/","excerpt":"","text":"golang的并发模型叫做CSP（communicating sequential process），称为通信顺序进程模型，模型由独立并发执行的实体组成（go块），模型之间的通信通过channel来实现。因此，golang的并发模型哲学是：万物皆通信！！golang的核心概念主要是： channel go块 channel channel可以单独创建，在进程之间传递 channel是线程安全队列，任何持有channel引用的任务(go块)都可以读写channel channel默认是无缓冲区的，也就是channel本身是同步的，一端写数据操作必然会阻塞直到channel的数据被别的地方读取 channel可以关闭，向关闭的channel读数据会读到的默认值，向关闭的channel写数据会导致panic！！ func main() { ch := make(chan int) go func() { ch &lt;- 20 close(ch) ch &lt;- 30 //panic: send on closed channel }() println(&lt;-ch) // 20 println(&lt;-ch) // 0(默认值) } 有缓冲区的channel，根据缓冲区已满时候的策略，可以分为 阻塞型：写入阻塞 弃用新值：新值写入被抛弃 移除旧值：太旧的数据被channel抛弃 channel和\b队列很像 在 golang里，channel可以用 for i := range channelName {}\b循环获取channel信息 goroutine线程模型的缺点java和c++的并发模型都是线程模型，它的好处是直接对硬件的抽象，大多数语言，包括python，它的线程模型都是操作系统线程，但是坏处是使用复杂。 但是线程模型有三个危害 竞态条件 死锁 内存可见性问题引用自《七周七并发编程模型》 public class Test { static boolean ready = false; // 竞态条件一：共享变量 static int data = 0 static Thread t1 = new Thread() { public void run() { data = 10; // 竞态条件二：会有并行实体(线程)修改变量 ready = true; } }; static Thread t2 = new Thread() { public void run() { if (ready) { // 竞态条件三：一个未处理完成另外一个处理可能会介入 System.out.Println(&quot;data is :&quot; + data) } else { System.out.Println(&quot;no data&quot;) } } }; public static void main(String[] args) throw InterruptedException{ t1.start(); t2.start(); t1.join(); t2.join(); } } 尽管线程模型问题很多，但是线程模型是其他模型的基础，比如nodejs的\b异步io模型，本质上也是基于线程池技术实现的，java的nio底层实现也是基于线程池。 线程池是多线程模型的改良，线程的启动和运行都有一定的开销，为了避免直接创建线程，才有了线程池，线程池方便了线程的复用，但是涉及线程通信的时候，如果线程被阻塞，那这个线程的资源永远都被占用者，线程池就显得鸡肋了。nodejs的决绝方法是限制程序员的代码风格，使之变成事件驱动的形式。 goroutine调度机制和状态机所谓事件驱动是指node.js会把所有的异步操作使用事件机制解决，有个线程在不断地循环检测事件队列。 node.js中所有的逻辑都是事件的回调函数，所以node.js始终在事件循环中，程序入口就是事件循环第一个事件的回调函数。事件的回调函数中可能会发出I/O请求或直接发射（ emit）事件，执行完毕后返回事件循环。事件循环会检查事件队列中有没有未处理的事件，直到程序结束，因此，node.js 是单线程，异步非阻塞 node的这种方式有几个问题： CPU密集型任务存在短板 无法利用CPU的多核 代码变得难以阅读 回调函数保存数据需要经常用到全局变量 golang本质上也是使用了事件驱动的机制，但是这个过程对我们是透明的，主要解决了第三个问题，原理是把每个go块(go func(){}())当层成了一个状态机，当go块从channel里读写，遇到阻塞的时候，go块进入暂停状态，让出线程控制权，代码可以继续进行的时候，状态扭转，go块继续运行(可能不在原来的线程上了) goroutine和线程 每个os线程有一个固定大小的栈内存（通常2MB） goroutine的栈空间大小不固定，开始通常是2KB，按需扩展，最大可达1GB go运行时候有自己的goroutine调度算法，称为m：n调度，m个goroutine运行在n个线程上 同是调度算法，为何go的调度算法如此优秀？ 其实不然，和操作系统线程调度器对比，主要不同在于： os内核调度上下文切换开销大，go调度器只需要调度一个go程序自己的goroutine，更容易hold住 os调度是硬件时钟中断触发的，goroutine调度的触发是channel读写阻塞或者time.Sleep()来实现的，因此不需要切换到内核态。 goroutine没有标识，线程是有自己的标识的，因此可以方便的实现\b一个线程局部变量(map[thread_symbol]object),在web服务器上，线程局部变量通常会被用来存储http请求信息。在goroutine上没有这种机制，鼓励更简单的编程风格。——《go程序设计语言》","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"http://lqczzz.github.io/tags/golang/"},{"name":"并发","slug":"并发","permalink":"http://lqczzz.github.io/tags/并发/"}]}]}